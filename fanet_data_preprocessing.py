import pandas as pd # for data manipulation 
import numpy as np
import networkx as nx # for drawing graphs
import matplotlib.pyplot as plt # for drawing graphs
import os, sys, glob, math
# for creating Bayesian Belief Networks (BBN)
from pybbn.graph.dag import Bbn
from pybbn.graph.edge import Edge, EdgeType
from pybbn.graph.jointree import EvidenceBuilder
from pybbn.graph.node import BbnNode
from pybbn.graph.variable import Variable
from pybbn.pptc.inferencecontroller import InferenceController

def rssi_to_np(rssi):
    # Function to convert rssi data from string (e.g. "435 pW") to exp (435e-12)
    rssi_num = np.zeros(rssi.shape)
    index = 0
    for r in rssi:
        num = r[0:-2]
        expn = r[-2:]
        # print(num)
        # print(expn)
        if expn == " W":
            # print(num)
            # print(index)
            rssi_num[index] = float(num)
        elif expn == "mW":
            rssi_num[index] = float(num) * 1e-3
        elif expn == "uW":
            rssi_num[index] = float(num) * 1e-6
        elif expn == "nW":
            rssi_num[index] = float(num) * 1e-9
        elif expn == "pW":
            rssi_num[index] = float(num) * 1e-12
        else:
            print(expn)
            raise ValueError("Unhandled unit prefix")
        index += 1
    return rssi_num

def compile_micro_sim_data(file_list):
    '''
    Function to compile data from the CSV files generated by each micro-simulation
    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)
    Output: concatenates the raw data to UL and DL dataframes
    '''
    uavs_rx_df = pd.DataFrame() 
    gcs_rx_df = pd.DataFrame()  
    gcs_tx_df = pd.DataFrame()  
    uavs_tx_df = pd.DataFrame()  
    gcs_mon_df = pd.DataFrame() 
    uavs_mon_df = pd.DataFrame()  
    gcs_pd_df = pd.DataFrame()  
    uavs_pd_df = pd.DataFrame() 

    uavs_rx_df_list = [] # List to store all df for UAVs Rx app
    uavs_tx_df_list = [] # List to store all df for UAVs Tx app
    uavs_mon_df_list = [] # List to store all df for UAVs monitor mode captures
    uavs_pd_df_list = [] # List to store all df for UAVs packet drop captures
    
    for file in file_list:
        try:
            if ('_GCS-' in file) and ('-Tx' in file):
                # DOWNLINK
                # This is the GCS Tx file, recording the sent packets from GCS
                gcs_tx_df = pd.read_csv(file)
            elif ('_GW-' in file) and ('-Rx' in file):
                # DOWNLINK
                # This is the gateway Rx file, let's get the information of packets received from GCS
                gw_rx_df = pd.read_csv(file)
                uavs_rx_df_list.append(gw_rx_df)
            elif ('_UAV-' in file) and ('-Rx' in file):
                # DOWNLINK
                # This is a UAV Rx file. To concatenate all such files into a single df
                uav_rx_df = pd.read_csv(file)
                # uav_cnc_data = uav_rx_df["CNCData" in uav_rx_df["Packet_Name"]] # Get the CNC Data received by this UAV
                # uav_cnc_reliable = uav_cnc_data[uav_cnc_data["Delay"] < delay_th] # Get the CNCData packets received reliably by this UAV (delay < 1ms)
                uavs_rx_df_list.append(uav_rx_df) # Append to list for concatenation later
            elif ('_GCS-' in file) and ('-Rx' in file):
                # UPLINK
                # This is a GCS Rx file, recording packets received from UAVs-
                gcs_rx_df = pd.read_csv(file)
            elif ('_GW-' in file) and ('-Tx' in file):
                # UPLINK
                # This is the gateway Tx file, recording packet transmissions to GCS from gateway
                gw_tx_df = pd.read_csv(file)
                uavs_tx_df_list.append(gw_tx_df) # Append to list for concatenation later
            elif ('_UAV-' in file) and ('-Tx' in file):
                # DOWNLINK
                # This is a UAV Rx file. To concatenate all such files into a single df
                uav_tx_df = pd.read_csv(file)
                uavs_tx_df_list.append(uav_tx_df) # Append to list for concatenation later
            elif ('_GCS-' in file) and ('Wlan' in file):
                # Monitor mode file for GCS
                gcs_mon_df = pd.read_csv(file)
                gcs_mon_df["Addr"] = "192.168.0.1"
            elif ('_GW-' in file) and ('Wlan' in file):
                # Monitor mode file for gateway
                gw_mon_df = pd.read_csv(file)
                gw_mon_df["Addr"] = "192.168.0.2"
                uavs_mon_df_list.append(gw_mon_df)
            elif ('_UAV-' in file) and ('Wlan' in file):
                # Monitor mode file for GCS
                uav_mon_df = pd.read_csv(file)
                uav_index = file.split("_")[-1].split("-")[1]
                uav_mon_df["Addr"] = "192.168.0.{}".format(int(uav_index) + 3)
                uavs_mon_df_list.append(uav_mon_df)
            elif ('_GCS-' in file) and ('PacketDrop' in file):
                # Packet Drop file for GCS
                gcs_pd_df = pd.read_csv(file)
            elif ('_GW-' in file) and ('PacketDrop' in file):
                # Packet Drop file for gateway
                gw_pd_df = pd.read_csv(file)
                uavs_pd_df_list.append(gw_pd_df)
            elif ('_UAV-' in file) and ('PacketDrop' in file):
                # Packet Drop file for GCS
                uav_pd_df = pd.read_csv(file)
                uav_index = file.split("_")[-1].split("-")[1]
                uavs_pd_df_list.append(uav_pd_df)
            else:
                # This file type is not handled, pass 
                pass
        except Exception as e:
            print(file)
            print(e)
        
    # Concatenate dataframes for UAVs
    if len(uavs_rx_df_list) > 0:
        uavs_rx_df = pd.concat(uavs_rx_df_list, ignore_index = True)
    if len(uavs_tx_df_list) > 0:
        uavs_tx_df = pd.concat(uavs_tx_df_list, ignore_index = True)
    if len(uavs_mon_df_list) > 0:
        uavs_mon_df = pd.concat(uavs_mon_df_list, ignore_index = True)
    if len(uavs_pd_df_list) > 0:
        uavs_pd_df = pd.concat(uavs_pd_df_list, ignore_index = True)

    # Alert if some important dataframes are missing for a particular case
    # Checking GCS dfs
    if len(gcs_tx_df.columns) == 0:
        print("GCS Tx file missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified
    if len(gcs_rx_df.columns) == 0:
        print("GCS Rx file missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified
    if len(gcs_pd_df.columns) == 0:
        print("GCS Packet Drop file missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified

    # Checking UAVs dfs
    if len(uavs_tx_df.columns) == 0:
        print("UAV Tx file(s) missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified
    if len(uavs_rx_df.columns) == 0:
        print("UAV Rx file(s) missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified
    if len(uavs_pd_df.columns) == 0:
        print("UAV Packet Drop file(s) missing")
        print(file_list[0]) # Print one file from file_list so that the scenario with this issue can be identified

    ul_pd_df = pd.concat([gcs_pd_df,gw_pd_df], ignore_index = True) # When analysing the uplink packet drops, some might be dropped between member UAV to gateway

    return uavs_rx_df, gcs_rx_df, gcs_tx_df, uavs_tx_df, gcs_mon_df, uavs_mon_df, ul_pd_df, uavs_pd_df

def process_dropped_packets(tx_df, rx_df, pd_df, scenario):
    '''
    This function is to fill in missing data in rx_df with data from mon_df for dropped packets that are not recorded in rx_df
    tx_df contains the list of all transmitted network packets (UL/DL)
    rx_df should only contain the captures of packets received successfully (regardless of delay)
    pd_df contains the packet drop recorded with reason, recorded on Rx side
    scenario is the name (str) of the current scenario being evaluated, for debugging purposes only
    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.

    VERSION 4: For each packet transmitted (in tx_df), get the number of tries and the packet drop reason(s) from pd_df. Update the data in rx_df.
    '''

    # First, let's delete the columns src_addr, src_port, dest_addr, dest_port from rx_df
    del rx_df["Src_Addr"]
    del rx_df["Src_Port"]
    del rx_df["Dest_Addr"]
    del rx_df["Dest_Port"]

    for index, row in tx_df.iterrows():
        packetName = row["Packet_Name"] + "-" + str(row["Packet_Seq"])

        # For each packet in tx_df, get the packet drops
        pkt_drops = pd_df.loc[(pd_df["Packet_Name"] == packetName)]
        if not pkt_drops.empty:
            drop_reasons = pkt_drops["Packet_Drop_Reason"].values
            # Count the occurences of each failure modes for a particular packet
            incorrect_rcvd = np.count_nonzero(drop_reasons == "INCORRECTLY_RECEIVED")
            arp_fail = np.count_nonzero(drop_reasons == "ADDRESS_RESOLUTION_FAILED") # TODO: Check whether this is stored on tx_pd_df or rx_pd_df
            queue_overflow = np.count_nonzero(drop_reasons == "QUEUE_OVERFLOW")
            hop_limit = np.count_nonzero(drop_reasons == "HOP_LIMIT_REACHED")
            interface_down = np.count_nonzero(drop_reasons == "INTERFACE_DOWN")
            other_drop = np.count_nonzero(drop_reasons == "OTHER_PACKET_DROP")
            num_drops = len(drop_reasons)

            # Update rx_df 
            if (packetName not in rx_df["Packet_Name"].values):
                # If not received, add the data of failed packet
                rx_time = max(pkt_drops["RxTime"].values)
                tx_time = min(pkt_drops["TxTime"].values)
                bytes = row["Bytes"]
                rssi = pkt_drops["RSSI"].mean()
                sinr = pkt_drops["SINR"].mean()
                u2g_sinr = pkt_drops["U2G_SINR"].mean()
                ber = pkt_drops["BER"].mean()
                u2g_ber = pkt_drops["U2G_BER"].mean()
                delay = max(pkt_drops["Delay"].values) # Taking the max so that value is from latest pkt
                queueing_time = pkt_drops["Queueing_Time"].values[0] # Queueing time should be the same between retries, just take first reading
                backoff_time = max(pkt_drops["Backoff_Time"].values) # Should probably take the total sum
                distance = max(pkt_drops["Distance"].values) # Taking the max so that value is from latest pkt
                u2g_distance = max(pkt_drops["U2G_Distance"].values) # Taking the max so that value is from latest pkt
                pkt_state = "FAILED" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)
                if (len(pkt_drops["U2U_SINR"].values) > 0): # There may not always be a U2U communication
                    u2u_sinr = pkt_drops["U2U_SINR"].mean()
                    u2u_ber = pkt_drops["U2U_BER"].mean()
                    hop_count = 2
                else:
                    hop_count = 1
                failed_pkt = pd.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'SINR': sinr,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,
                              'BER': ber,'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'Distance': distance,'U2G_Distance': u2g_distance,
                              'Incorrectly_Rcvd': incorrect_rcvd,'ARP_Fail': arp_fail,'Queue_Overflow': queue_overflow,'Hop_Limit_Reached': hop_limit,'Interface_Down': interface_down,'Other_Dropped': other_drop,'Number_Dropped': num_drops,
                              'Packet_State': pkt_state}])
                rx_df = pd.concat([rx_df,failed_pkt], ignore_index = True)
            else:
                # If packet successfully received, update the number of tries and the reason for failed attempt(s) for this particular packet
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Incorrectly_Rcvd"] = incorrect_rcvd
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "ARP_Fail"] = arp_fail
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Queue_Overflow"] = queue_overflow
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Hop_Limit_Reached"] = hop_limit
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Interface_Down"] = interface_down
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Other_Dropped"] = other_drop
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Number_Dropped"] = num_drops
                rx_df.loc[(rx_df["Packet_Name"] == packetName), "Packet_State"] = "RECEIVED"

        elif (packetName in rx_df["Packet_Name"].values):
            # The packet was received without any retries
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Incorrectly_Rcvd"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "ARP_Fail"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Queue_Overflow"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Hop_Limit_Reached"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Interface_Down"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Other_Dropped"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Number_Dropped"] = 0
            rx_df.loc[(rx_df["Packet_Name"] == packetName), "Packet_State"] = "RECEIVED"
        
        else:
            print("No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen".format(packetName))
            print(scenario)

    rx_df = rx_df.sort_values("RxTime")
    rx_df = rx_df.reset_index()
    return rx_df

def process_throughput(df, timeDiv):
    '''
    Function to calculate throughput data for a DataFrame
    timeDiv is the time division to use for calculating the throughput
    '''
    maxTime = math.ceil(float(df["RxTime"].max()))
    for i in range(math.ceil(maxTime / timeDiv)):
        df_in_range = df.loc[(df["RxTime"] >= (i*timeDiv)) & (df["RxTime"] < ((i+1)*timeDiv)) & (df["Packet_State"] == "RECEIVED")]
        totalBytes = df_in_range["Bytes"].sum()
        throughput = totalBytes / timeDiv
        df.loc[(df["RxTime"] >= (i*timeDiv)) & (df["RxTime"] < ((i+1)*timeDiv)), "Throughput"] = throughput
    return df

def process_sim_data(sim_root_path, delay_threshold):
    # Concatenates all UL & DL results from sim_root_path into a single df
    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + "/*GCS-Tx.csv")] # Get list of "unique" scenarios

    # Dataframes to store UL & DL raw data
    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','U2G_SINR','U2U_SINR','BER','U2G_BER','U2U_BER',
                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','Distance','U2G_Distance','Height','Inter_UAV_Distance',
                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','ARP_Fail','Queue_Overflow','Hop_Limit_Reached',
                                    'Interface_Down','Other_Dropped','Number_Dropped','Packet_State']) # Downlink dataframe
    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','U2G_SINR','U2U_SINR','BER','U2G_BER','U2U_BER',
                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','Distance','U2G_Distance','Height','Inter_UAV_Distance',
                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','ARP_Fail','Queue_Overflow','Hop_Limit_Reached',
                                    'Interface_Down','Other_Dropped','Number_Dropped','Packet_State']) # Uplink dataframe

    # For each scenario, extract the UL and DL raw data
    for scenario in scenario_list:
        scenario_files = glob.glob(sim_root_path + "/{}_*.csv".format(scenario)) # Get list of csv files belonging to this scenario
        scenario_params = scenario.split('_')
        num_member = int(scenario_params[0].split('-')[-1])
        inter_uav_distance = int(scenario_params[1].split('-')[-1])
        height = int(scenario_params[2].split('-')[-1])
        # swarm_hor_distance = int(scenario_params[3].split('-')[-1]) # Horizontal Swarm Distance
        # swarm_distance = math.sqrt(int(height)**2 + swarm_hor_distance**2)
        # packet_size = int(scenario_params[4].split('-')[-1])
        sending_interval = int(scenario_params[5].split('-')[-1])
        dl_data, ul_data, dl_tx_df, ul_tx_df, gcs_mon_df, uavs_mon_df, ul_pd_df, uavs_pd_df = compile_micro_sim_data(scenario_files)
        # Convert the RSSI data to np
        dl_data["RSSI"] = rssi_to_np(dl_data["RSSI"])
        ul_data["RSSI"] = rssi_to_np(ul_data["RSSI"])
        ul_pd_df["RSSI"] = rssi_to_np(ul_pd_df["RSSI"])
        uavs_pd_df["RSSI"] = rssi_to_np(uavs_pd_df["RSSI"])
        # gcs_mon_df["RSSI"] = rssi_to_np(gcs_mon_df["RSSI"])
        # uavs_mon_df["RSSI"] = rssi_to_np(uavs_mon_df["RSSI"])
        # Process the failed packets data into the main dataframe
        dl_data = process_dropped_packets(dl_tx_df, dl_data, uavs_pd_df, scenario)
        ul_data = process_dropped_packets(ul_tx_df, ul_data, ul_pd_df, scenario)
        if dl_data is not None:
            dl_data["Height"] = height
            dl_data["Inter_UAV_Distance"] = inter_uav_distance
            dl_data["Num_Members"] = num_member
            dl_data["Sending_Interval"] = sending_interval
            # Fill in reliability data
            dl_data["Delay_Exceeded"] = 0
            dl_data.loc[dl_data["Delay"] > delay_threshold, "Delay_Exceeded"] = 1
            dl_data["Reliable"] = 0
            dl_data.loc[(dl_data["Delay_Exceeded"] == 0) & (dl_data["Packet_State"] == "RECEIVED"), "Reliable"] = 1
            dl_data = process_throughput(dl_data, 1)
            dl_df = pd.concat([dl_df, dl_data], ignore_index=True)
        if ul_data is not None:
            ul_data["Height"] = height
            ul_data["Inter_UAV_Distance"] = inter_uav_distance
            ul_data["Num_Members"] = num_member
            ul_data["Sending_Interval"] = sending_interval
            # Fill in reliability data
            ul_data["Delay_Exceeded"] = 0
            ul_data.loc[ul_data["Delay"] > delay_threshold, "Delay_Exceeded"] = 1
            ul_data["Reliable"] = 0
            ul_data.loc[(ul_data["Delay_Exceeded"] == 0) & (ul_data["Packet_State"] == 'RECEIVED'), "Reliable"] = 1
            ul_data = process_throughput(ul_data, 1)
            ul_df = pd.concat([ul_df, ul_data], ignore_index=True)
    
    return dl_df, ul_df

if __name__ == "__main__":
    # Let's get the data
    sim_root_path = "/home/research-student/omnetpp_sim_results/Dataset_Test_no_ARP"
    delay_threshold = 1
    dl_df, ul_df = process_sim_data(sim_root_path, delay_threshold=delay_threshold)
    # Save DF to CSV
    dl_df.to_csv(os.path.join(sim_root_path,"FANET_downlink_raw.csv"), index=False)
    ul_df.to_csv(os.path.join(sim_root_path,"FANET_uplink_raw.csv"), index=False)