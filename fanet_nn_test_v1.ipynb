{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test FANET NN\n",
    "Date: 07/03/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 10:04:22.236275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 10:04:22.349877: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-10 10:04:22.354610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-10 10:04:22.354625: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-10 10:04:22.378126: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 10:04:22.986927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-10 10:04:22.986990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-10 10:04:22.986996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import glob, math, os\n",
    "from scipy import special\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def euclidean_dist(row):\n",
    "    # Function to calc euclidean distance on every df row \n",
    "    euc_dist = math.sqrt(row[\"U2G_Distance\"]**2 - row[\"Height\"]**2)\n",
    "    return euc_dist\n",
    "\n",
    "def q_func(x):\n",
    "    q = 0.5 - 0.5*special.erf(x / np.sqrt(2))\n",
    "    return q\n",
    "\n",
    "def friis_calc(P,freq,dist,ple):\n",
    "    '''\n",
    "    Friis path loss equation\n",
    "    P = Tx transmit power\n",
    "    freq = Signal frequency\n",
    "    dist = Transmission distance\n",
    "    ple = Path loss exponent\n",
    "    '''\n",
    "    propagation_speed = 299792458\n",
    "    l = propagation_speed / freq\n",
    "    h_pl = P * l**2 / (16*math.pi**2)\n",
    "    P_Rx = h_pl * dist**(-ple)\n",
    "    return P_Rx\n",
    "\n",
    "def plos_calc(h_dist, height_tx, height_rx, env='suburban'):\n",
    "    '''\n",
    "    % This function implements the LoS probability model from the paper\n",
    "    % \"Blockage Modeling for Inter-layer UAVs Communications in Urban\n",
    "    % Environments\" \n",
    "    % param h_dist    : horizontal distance between Tx and Rx (m)\n",
    "    % param height_tx : height of Tx\n",
    "    % param height_rx : height of Rx\n",
    "    '''\n",
    "    if env == 'suburban':\n",
    "        a1 = 0.1\n",
    "        a2 = 7.5e-4\n",
    "        a3 = 8\n",
    "    elif env == 'urban':\n",
    "        a1 = 0.3\n",
    "        a2 = 5e-4\n",
    "        a3 = 15\n",
    "    \n",
    "    delta_h = height_tx - height_rx\n",
    "    # pow_factor = 2 * h_dist * math.sqrt(a1*a2/math.pi) + a1 # NOTE: Use this pow_factor if assuming PPP building dist.\n",
    "    pow_factor = h_dist * math.sqrt(a1*a2) # NOTE: Use this pow_factor if assuming ITU-R assumptions.\n",
    "    if delta_h == 0:\n",
    "        p = (1 - math.exp((-(height_tx)**2) / (2*a3**2))) ** pow_factor\n",
    "    else:\n",
    "        if delta_h < 0:\n",
    "            h1 = height_rx\n",
    "            h2 = height_tx\n",
    "        else:\n",
    "            h1 = height_tx\n",
    "            h2 = height_rx\n",
    "        delta_h = abs(delta_h)\n",
    "        p = (1 - (math.sqrt(2*math.pi)*a3 / delta_h) * abs(q_func(h1/a3) - q_func(h2/a3))) ** pow_factor\n",
    "    return p\n",
    "\n",
    "def sinr_lognormal_approx(h_dist, height, env='suburban'):\n",
    "    '''\n",
    "    To approximate the SNR from signal considering multipath fading and shadowing\n",
    "    Assuming no interference due to CSMA, and fixed noise\n",
    "    Inputs:\n",
    "    h_dist = Horizontal Distance between Tx and Rx\n",
    "    height = Height difference between Tx and Rx\n",
    "    env = The operating environment (currently only suburban supported)\n",
    "    '''\n",
    "    # Signal properties\n",
    "    P_Tx_dBm = 20 # Transmit power of \n",
    "    P_Tx = 10**(P_Tx_dBm/10) / 1000\n",
    "    freq = 2.4e9 # Channel frequency (Hz)\n",
    "    noise_dBm = -86\n",
    "    noise = 10**(noise_dBm/10) / 1000\n",
    "    if env == \"suburban\":\n",
    "        # ENV Parameters Constants ----------------------------------\n",
    "        # n_min = 2\n",
    "        # n_max = 2.75\n",
    "        # K_dB_min = 7.8\n",
    "        # K_dB_max = 17.5\n",
    "        # K_min = 10**(K_dB_min/10)\n",
    "        # K_max = 10**(K_dB_max/10)\n",
    "        # alpha = 11.25 # Env parameters for logarithm std dev of shadowing \n",
    "        # beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        n_min = 2\n",
    "        n_max = 2.75\n",
    "        K_dB_min = 1.4922\n",
    "        K_dB_max = 12.2272\n",
    "        K_min = 10**(K_dB_min/10)\n",
    "        K_max = 10**(K_dB_max/10)\n",
    "        alpha = 11.1852 # Env parameters for logarithm std dev of shadowing \n",
    "        beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        # -----------------------------------------------------------\n",
    "    elif env == \"urban\":\n",
    "        n_min = 1.9\n",
    "        n_max = 2.7\n",
    "        K_dB_min = -5\n",
    "        K_dB_max = 15\n",
    "        K_min = 10**(K_dB_min/10)\n",
    "        K_max = 10**(K_dB_max/10)\n",
    "        alpha = 10.42 # Env parameters for logarithm std dev of shadowing \n",
    "        beta = 0.05 # Env parameters for logarithm std dev of shadowing \n",
    "    # Calculate fading parameters\n",
    "    PLoS = plos_calc(h_dist, 0, height, env=env)\n",
    "    theta_Rx = math.atan2(height, h_dist) * 180 / math.pi # Elevation angle in degrees\n",
    "    ple = (n_min - n_max) * PLoS + n_max # Path loss exponent\n",
    "    sigma_phi_dB = alpha*math.exp(-beta*theta_Rx)\n",
    "    sigma_phi = 10**(sigma_phi_dB/10) # Logarithmic std dev of shadowing\n",
    "    K = K_min * math.exp(math.log(K_max/K_min) * PLoS**2)\n",
    "    omega = 1 # Omega of NCS (Rician)\n",
    "    dist = math.sqrt(h_dist**2 + height**2)\n",
    "    P_Rx = friis_calc(P_Tx, freq, dist, ple)\n",
    "    # Approximate L-NCS RV (which is the SNR) as lognormal\n",
    "    eta = math.log(10) / 10\n",
    "    mu_phi = 10*math.log10(P_Rx)\n",
    "    E_phi = math.exp(eta*mu_phi + eta**2*sigma_phi**2/2) # Mean of shadowing RV\n",
    "    var_phi = math.exp(2*eta*mu_phi+eta**2*sigma_phi**2)*(math.exp(eta**2*sigma_phi**2)-1) # Variance of shadowing RV\n",
    "    E_chi = (special.gamma(1+1)/(1+K))*special.hyp1f1(-1,1,-K)*omega\n",
    "    var_chi = (special.gamma(1+2)/(1+K)**2)*special.hyp1f1(-2,1,-K)*omega**2 - E_chi**2\n",
    "    E_SNR = E_phi * E_chi / noise # Theoretical mean of SINR\n",
    "    var_SNR = ((var_phi+E_phi**2)*(var_chi+E_chi**2) - E_phi**2 * E_chi**2) / noise**2\n",
    "    std_dev_SNR = math.sqrt(var_SNR)\n",
    "    # sigma_ln = math.sqrt(math.log(var_SNR/E_SNR**2 + 1))\n",
    "    # mu_ln = math.log(E_SNR) - sigma_ln**2/2\n",
    "    return E_SNR, std_dev_SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122.743643457063 465.2159856885714\n"
     ]
    }
   ],
   "source": [
    "[m,s] = sinr_lognormal_approx(0,60)\n",
    "print(m,s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 15:37:11.820016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820138: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820365: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820439: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-02 15:37:11.820596: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-02 15:37:11.821031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2-2_21032023/model.010-2.0131.h5\", compile=False)\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2_hovering/model.001-0.9263.h5\", compile=False)\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2_hovering_sinr/model.001-0.9614.h5\", compile=False)\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v3_hovering/model.001-0.9333.h5\", compile=False)\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v3_hovering_sinr/model.001-0.9316.h5\", compile=False)\n",
    "model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2_hovering_novideo_sinr_ul/nn_v2_hovering_novideo_sinr_ul/model.006-1.5564.h5\", compile=False)\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2_hovering_novideo_sinr_dl/model.001-10.1139.h5\", compile=False)\n",
    "# model.compile(optimizer='adam', \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'reliability': 'binary_crossentropy',\n",
    "                    'incorrectly_received': 'categorical_crossentropy',\n",
    "                    'delay_exceeded': 'binary_crossentropy',\n",
    "                    'queue_overflow': 'binary_crossentropy'},\n",
    "              metrics={'reliability': 'accuracy',\n",
    "                    'incorrectly_received': 'accuracy',\n",
    "                    'delay_exceeded': 'accuracy',\n",
    "                    'queue_overflow': 'accuracy'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uplink\n",
    "model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v4_multimodulation_video_sinr_ul/model.004-0.1376.h5\", compile=False)\n",
    "# Downlink\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v4_multimodulation_novideo_nosinr_dl/model.005-0.2016.h5\", compile=False)\n",
    "# Video\n",
    "# model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v4_multimodulation_video_nosinr_vid/model.005-0.2745.h5\", compile=False)\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'packet_state': 'categorical_crossentropy'},\n",
    "              metrics={'packet_state': 'accuracy'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Taguchi Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "# test_data_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Stationary_Test_Dataset_NP10000_BPSK_6-5Mbps_downlink.h5\", \"Downlink\")\n",
    "test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Test_Dataset_NP10000_64QAM_65Mbps_Hovering_NoVideo_uplink.csv\")\n",
    "\n",
    "# Calculate mean and std dev of SINR\n",
    "test_data_df[['Mean_SINR',\"Std_Dev_SINR\"]]= test_data_df.apply(lambda row: sinr_lognormal_approx(row['Horizontal_Distance'],row['Height']),axis=1,result_type='expand')\n",
    "\n",
    "# Normalize inputs\n",
    "max_h_dist = 510\n",
    "max_height = 300\n",
    "max_num_members = 39\n",
    "max_bytes = 1500 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "max_mean_sinr = 521 # The max mean SINR calculated at (50,60) is 520.2907250903191\n",
    "max_std_dev_sinr = 252 # The max std dev SINR calculated at (50,60) is 251.44889082897834\n",
    "\n",
    "h_dists = test_data_df[\"Horizontal_Distance\"].values\n",
    "heights = test_data_df[\"Height\"].values\n",
    "num_members = test_data_df[\"Num_Members\"].values\n",
    "# pkt_sizes = test_data_df[\"Packet_Size\"].values\n",
    "sending_ints = test_data_df[\"Sending_Interval\"].values\n",
    "mean_sinr = test_data_df[\"Mean_SINR\"].values\n",
    "std_dev_sinr = test_data_df[\"Std_Dev_SINR\"].values\n",
    "\n",
    "norm_h_dist = [h_dist / max_h_dist for h_dist in h_dists]\n",
    "norm_height = [height / max_height for height in heights]\n",
    "norm_num_members = [num_member / max_num_members for num_member in num_members]\n",
    "# norm_pkt_size = [pkt_size / max_bytes for pkt_size in pkt_sizes]\n",
    "norm_sending_int = [sending_int / max_sending_int for sending_int in sending_ints]\n",
    "norm_mean_sinr = [m / max_mean_sinr for m in mean_sinr]\n",
    "norm_std_dev_sinr = [s / max_std_dev_sinr for s in std_dev_sinr]\n",
    "\n",
    "# For storing prediction results\n",
    "predicted_reliability = []\n",
    "predicted_incr_rcvd = [[],[],[],[],[],[],[],[]] # List of lists to store the prob of each incr rcvd probabilities\n",
    "predicted_delay_excd = []\n",
    "predicted_queue_overflow = []\n",
    "\n",
    "# Run inference\n",
    "# model_inputs = list(zip(norm_h_dist, norm_height, norm_num_members, norm_pkt_size, norm_sending_int))\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_num_members, norm_sending_int))\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Save the results to CSV\n",
    "test_data_df['Predicted_Reliability'] = [prob[1] for prob in prediction[0]]\n",
    "test_data_df['Predicted_Delay_Excd_Prob'] = [prob[1] for prob in prediction[2]]\n",
    "test_data_df['Predicted_Queue_Overflow_Prob'] = [prob[1] for prob in prediction[3]]\n",
    "test_data_df['Predicted_0_Incr_Rcvd'] = [prob[0] for prob in prediction[1]]\n",
    "test_data_df['Predicted_1_Incr_Rcvd'] = [prob[1] for prob in prediction[1]]\n",
    "test_data_df['Predicted_2_Incr_Rcvd'] = [prob[2] for prob in prediction[1]]\n",
    "test_data_df['Predicted_3_Incr_Rcvd'] = [prob[3] for prob in prediction[1]]\n",
    "test_data_df['Predicted_4_Incr_Rcvd'] = [prob[4] for prob in prediction[1]]\n",
    "test_data_df['Predicted_5_Incr_Rcvd'] = [prob[5] for prob in prediction[1]]\n",
    "test_data_df['Predicted_6_Incr_Rcvd'] = [prob[6] for prob in prediction[1]]\n",
    "test_data_df['Predicted_7_Incr_Rcvd'] = [prob[7] for prob in prediction[1]]\n",
    "\n",
    "test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Test_Dataset_NP10000_64QAM_65Mbps_Hovering_NoVideo_uplink_RESULTS_nn.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Taguchi Test Dataset (Single Multiclass Reliability and Failure Modes Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n",
      "Reliability - Accuracy: 0.9927083333333333, MAE: 0.0038538794746317663, MaxAE: 0.43060189493179324\n",
      "Failure Mode - Accuracy: 0.9895833333333334\n",
      "Queue Overflow - MeanAE: 0.005388583871195809, MaxAE: 0.1418640999889374\n",
      "Incorrectly Received - MeanAE: 0.002226519570099602, MaxAE: 0.00872767425775528\n",
      "Delay Exceeded - MeanAE: 0.005999698031298998, MaxAE: 0.41718262441635134\n"
     ]
    }
   ],
   "source": [
    "# Set minimum probability for failure mode to be considered\n",
    "MIN_FAILURE_PROB = 0.01\n",
    "\n",
    "# Load test dataset\n",
    "test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Uplink_Reliability.csv\")\n",
    "# test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_Reliability.csv\")\n",
    "# Comment the below if using old files\n",
    "test_data_df[\"Reliability\"] = test_data_df[\"Num_Reliable\"] / test_data_df[\"Num_Sent\"]\n",
    "test_data_df[\"Incorrectly_Rcvd_Prob\"] = test_data_df[\"Num_Incr_Rcvd\"] / test_data_df[\"Num_Sent\"]\n",
    "test_data_df[\"Queue_Overflow_Prob\"] = test_data_df[\"Num_Q_Overflow\"] / test_data_df[\"Num_Sent\"]\n",
    "test_data_df[\"Delay_Excd_Prob\"] = test_data_df[\"Num_Delay_Excd\"] / test_data_df[\"Num_Sent\"]\n",
    "\n",
    "# Calculate mean and std dev of SINR\n",
    "test_data_df[['Mean_SINR',\"Std_Dev_SINR\"]] = test_data_df.apply(lambda row: sinr_lognormal_approx(row['Horizontal_Distance'],row['Height'],\"suburban\"),axis=1,result_type='expand')\n",
    "test_data_df[\"Mean_SINR\"] = test_data_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "test_data_df[\"Std_Dev_SINR\"] = test_data_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "\n",
    "mean_sinr = test_data_df[\"Mean_SINR\"].values\n",
    "std_dev_sinr = test_data_df[\"Std_Dev_SINR\"].values\n",
    "\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = test_data_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = test_data_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# For storing prediction results\n",
    "predicted_reliability = []\n",
    "predicted_incr_rcvd = [] \n",
    "predicted_delay_excd = []\n",
    "predicted_queue_overflow = []\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Save the results to CSV\n",
    "test_data_df['Predicted_Reliability'] = [prob[0] for prob in prediction]\n",
    "test_data_df['Predicted_Queue_Overflow_Prob'] = [prob[1] for prob in prediction]\n",
    "test_data_df['Predicted_Incr_Rcvd_Prob'] = [prob[2] for prob in prediction]\n",
    "test_data_df['Predicted_Delay_Excd_Prob'] = [prob[3] for prob in prediction]\n",
    "\n",
    "test_data_df[\"Reliability_Class\"] = pd.cut(test_data_df[\"Reliability\"], bins=[-0.1,0.2,0.5,0.8,1], labels=[\"Low\", \"ModeratelyLow\", \"ModeratelyHigh\", \"High\"])\n",
    "test_data_df[\"Predicted_Reliability_Class\"] = pd.cut(test_data_df[\"Predicted_Reliability\"], bins=[-0.1,0.2,0.5,0.8,1], labels=[\"Low\", \"ModeratelyLow\", \"ModeratelyHigh\", \"High\"])\n",
    "test_data_df[\"Failure_Mode\"] = test_data_df[[\"Queue_Overflow_Prob\", \"Incorrectly_Rcvd_Prob\", \"Delay_Excd_Prob\"]].idxmax(axis=1)\n",
    "test_data_df[\"Predicted_Failure_Mode\"] = test_data_df[[\"Predicted_Queue_Overflow_Prob\", \"Predicted_Incr_Rcvd_Prob\", \"Predicted_Delay_Excd_Prob\"]].idxmax(axis=1)\n",
    "# Replace label for Failure Mode with \"None\" if none of the failure modes have a probability > 5%\n",
    "test_data_df.loc[(test_data_df[\"Queue_Overflow_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Incorrectly_Rcvd_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Delay_Excd_Prob\"] < MIN_FAILURE_PROB),[\"Failure_Mode\"]] = \"None\"\n",
    "test_data_df.loc[(test_data_df[\"Predicted_Queue_Overflow_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Predicted_Incr_Rcvd_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Predicted_Delay_Excd_Prob\"] < MIN_FAILURE_PROB),[\"Predicted_Failure_Mode\"]] = \"None\"\n",
    "\n",
    "# Compute the model accuracy and mean abs err\n",
    "failure_mode = test_data_df[\"Failure_Mode\"].replace({\"Queue_Overflow_Prob\":1, \"Incorrectly_Rcvd_Prob\":2, \"Delay_Excd_Prob\":3, \"None\":4})\n",
    "failure_mode_predicted = test_data_df[\"Predicted_Failure_Mode\"].replace({\"Predicted_Queue_Overflow_Prob\":1, \"Predicted_Incr_Rcvd_Prob\":2, \"Predicted_Delay_Excd_Prob\":3, \"None\":4})\n",
    "reliability_accuracy = accuracy_score(test_data_df[\"Reliability_Class\"], test_data_df[\"Predicted_Reliability_Class\"])\n",
    "failure_mode_accuracy = accuracy_score(failure_mode, failure_mode_predicted)\n",
    "reliability_mae = np.mean(abs(test_data_df['Reliability'].values - test_data_df['Predicted_Reliability'].values))\n",
    "queue_overflow_mae = np.mean(abs(test_data_df['Queue_Overflow_Prob'].values - test_data_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_mae = np.mean(abs(test_data_df['Incorrectly_Rcvd_Prob'].values - test_data_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_mae = np.mean(abs(test_data_df['Delay_Excd_Prob'].values - test_data_df['Predicted_Delay_Excd_Prob'].values))\n",
    "reliability_maxae = np.max(abs(test_data_df['Reliability'].values - test_data_df['Predicted_Reliability'].values))\n",
    "queue_overflow_maxae = np.max(abs(test_data_df['Queue_Overflow_Prob'].values - test_data_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_maxae = np.max(abs(test_data_df['Incorrectly_Rcvd_Prob'].values - test_data_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_maxae = np.max(abs(test_data_df['Delay_Excd_Prob'].values - test_data_df['Predicted_Delay_Excd_Prob'].values))\n",
    "\n",
    "# Print results\n",
    "print(\"Reliability - Accuracy: {}, MAE: {}, MaxAE: {}\".format(reliability_accuracy, reliability_mae, reliability_maxae))\n",
    "print(\"Failure Mode - Accuracy: {}\".format(failure_mode_accuracy))\n",
    "print(\"Queue Overflow - MeanAE: {}, MaxAE: {}\".format(queue_overflow_mae, queue_overflow_maxae))\n",
    "print(\"Incorrectly Received - MeanAE: {}, MaxAE: {}\".format(incr_rcvd_mae, incr_rcvd_maxae))\n",
    "print(\"Delay Exceeded - MeanAE: {}, MaxAE: {}\".format(delay_excd_mae, delay_excd_maxae))\n",
    "\n",
    "# Save results to file\n",
    "test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test_Dataset_1_Uplink_Reliability_NN_Results.csv\")\n",
    "# test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/NN_Downlink_Reliability_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004926743822818463"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.00566187559881395, 0.005497301386443336, 0.003621054483198103])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Taguchi Test Dataset (No SINR) (Single Multiclass Reliability and Failure Modes Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n",
      "Reliability - Accuracy: 0.9927083333333333, MAE: 0.002744380153625911, MaxAE: 0.49762199378013616\n",
      "Failure Mode - Accuracy: 0.9916666666666667\n",
      "Queue Overflow - MeanAE: 0.004665819713344343, MaxAE: 0.16435093121528627\n",
      "Incorrectly Received - MeanAE: 0.0007674163412448138, MaxAE: 0.003962640689872205\n",
      "Delay Exceeded - MeanAE: 0.006224850996109199, MaxAE: 0.4828524098396301\n"
     ]
    }
   ],
   "source": [
    "# Set minimum probability for failure mode to be considered\n",
    "MIN_FAILURE_PROB = 0.01\n",
    "\n",
    "# Load test dataset\n",
    "test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test/Multi_Modulation_Test_Cases_1_Uplink.csv\")\n",
    "\n",
    "# Get height and h_dist inputs\n",
    "h_dist = test_data_df[\"Horizontal_Distance\"].values\n",
    "height = test_data_df[\"Height\"].values\n",
    "\n",
    "# Normalize inputs\n",
    "max_height = 300\n",
    "min_height = 60\n",
    "max_h_dist = 1200\n",
    "min_h_dist = 0\n",
    "\n",
    "norm_h_dist = [2*(h_d-min_h_dist) / (max_h_dist-min_h_dist) - 1 for h_d in h_dist]\n",
    "norm_height = [2*(h-min_height) / (max_height-min_height) - 1 for h in height]\n",
    "norm_uav_send_int = test_data_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = test_data_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# For storing prediction results\n",
    "predicted_reliability = []\n",
    "predicted_incr_rcvd = [] \n",
    "predicted_delay_excd = []\n",
    "predicted_queue_overflow = []\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_h_dist, norm_height, norm_uav_send_int, norm_modulation))\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Save the results to CSV\n",
    "test_data_df['Predicted_Reliability'] = [prob[0] for prob in prediction]\n",
    "test_data_df['Predicted_Queue_Overflow_Prob'] = [prob[1] for prob in prediction]\n",
    "test_data_df['Predicted_Incr_Rcvd_Prob'] = [prob[2] for prob in prediction]\n",
    "test_data_df['Predicted_Delay_Excd_Prob'] = [prob[3] for prob in prediction]\n",
    "\n",
    "test_data_df[\"Reliability_Class\"] = pd.cut(test_data_df[\"Reliability\"], bins=[-0.1,0.2,0.5,0.8,1], labels=[\"Low\", \"ModeratelyLow\", \"ModeratelyHigh\", \"High\"])\n",
    "test_data_df[\"Predicted_Reliability_Class\"] = pd.cut(test_data_df[\"Predicted_Reliability\"], bins=[-0.1,0.2,0.5,0.8,1], labels=[\"Low\", \"ModeratelyLow\", \"ModeratelyHigh\", \"High\"])\n",
    "test_data_df[\"Failure_Mode\"] = test_data_df[[\"Queue_Overflow_Prob\", \"Incorrectly_Rcvd_Prob\", \"Delay_Excd_Prob\"]].idxmax(axis=1)\n",
    "test_data_df[\"Predicted_Failure_Mode\"] = test_data_df[[\"Predicted_Queue_Overflow_Prob\", \"Predicted_Incr_Rcvd_Prob\", \"Predicted_Delay_Excd_Prob\"]].idxmax(axis=1)\n",
    "# Replace label for Failure Mode with \"None\" if none of the failure modes have a probability > 5%\n",
    "test_data_df.loc[(test_data_df[\"Queue_Overflow_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Incorrectly_Rcvd_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Delay_Excd_Prob\"] < MIN_FAILURE_PROB),[\"Failure_Mode\"]] = \"None\"\n",
    "test_data_df.loc[(test_data_df[\"Predicted_Queue_Overflow_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Predicted_Incr_Rcvd_Prob\"] < MIN_FAILURE_PROB) & (test_data_df[\"Predicted_Delay_Excd_Prob\"] < MIN_FAILURE_PROB),[\"Predicted_Failure_Mode\"]] = \"None\"\n",
    "\n",
    "# Compute the model accuracy and mean abs err\n",
    "failure_mode = test_data_df[\"Failure_Mode\"].replace({\"Queue_Overflow_Prob\":1, \"Incorrectly_Rcvd_Prob\":2, \"Delay_Excd_Prob\":3, \"None\":4})\n",
    "failure_mode_predicted = test_data_df[\"Predicted_Failure_Mode\"].replace({\"Predicted_Queue_Overflow_Prob\":1, \"Predicted_Incr_Rcvd_Prob\":2, \"Predicted_Delay_Excd_Prob\":3, \"None\":4})\n",
    "reliability_accuracy = accuracy_score(test_data_df[\"Reliability_Class\"], test_data_df[\"Predicted_Reliability_Class\"])\n",
    "failure_mode_accuracy = accuracy_score(failure_mode, failure_mode_predicted)\n",
    "reliability_mae = np.mean(abs(test_data_df['Reliability'].values - test_data_df['Predicted_Reliability'].values))\n",
    "queue_overflow_mae = np.mean(abs(test_data_df['Queue_Overflow_Prob'].values - test_data_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_mae = np.mean(abs(test_data_df['Incorrectly_Rcvd_Prob'].values - test_data_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_mae = np.mean(abs(test_data_df['Delay_Excd_Prob'].values - test_data_df['Predicted_Delay_Excd_Prob'].values))\n",
    "reliability_maxae = np.max(abs(test_data_df['Reliability'].values - test_data_df['Predicted_Reliability'].values))\n",
    "queue_overflow_maxae = np.max(abs(test_data_df['Queue_Overflow_Prob'].values - test_data_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_maxae = np.max(abs(test_data_df['Incorrectly_Rcvd_Prob'].values - test_data_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_maxae = np.max(abs(test_data_df['Delay_Excd_Prob'].values - test_data_df['Predicted_Delay_Excd_Prob'].values))\n",
    "\n",
    "# Print results\n",
    "print(\"Reliability - Accuracy: {}, MAE: {}, MaxAE: {}\".format(reliability_accuracy, reliability_mae, reliability_maxae))\n",
    "print(\"Failure Mode - Accuracy: {}\".format(failure_mode_accuracy))\n",
    "print(\"Queue Overflow - MeanAE: {}, MaxAE: {}\".format(queue_overflow_mae, queue_overflow_maxae))\n",
    "print(\"Incorrectly Received - MeanAE: {}, MaxAE: {}\".format(incr_rcvd_mae, incr_rcvd_maxae))\n",
    "print(\"Delay Exceeded - MeanAE: {}, MaxAE: {}\".format(delay_excd_mae, delay_excd_maxae))\n",
    "\n",
    "# Save results to file\n",
    "test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test/Multi_Modulation_Test_Cases_1_Uplink_NN_NoSINR_RESULTS.csv\")\n",
    "\n",
    "# Get the results at the \"drop\" only\n",
    "test_data_drop_df = test_data_df.loc[(test_data_df[\"Reliability\"] < 0.99) & (test_data_df[\"Reliability\"] > 0.01)]\n",
    "    # Compute the model accuracy and mean abs err\n",
    "failure_mode = test_data_drop_df[\"Failure_Mode\"].replace({\"Queue_Overflow_Prob\":1, \"Incorrectly_Rcvd_Prob\":2, \"Delay_Excd_Prob\":3, \"None\":4})\n",
    "failure_mode_predicted = test_data_drop_df[\"Predicted_Failure_Mode\"].replace({\"Predicted_Queue_Overflow_Prob\":1, \"Predicted_Incr_Rcvd_Prob\":2, \"Predicted_Delay_Excd_Prob\":3, \"None\":4})\n",
    "reliability_accuracy = accuracy_score(test_data_drop_df[\"Reliability_Class\"], test_data_drop_df[\"Predicted_Reliability_Class\"])\n",
    "failure_mode_accuracy = accuracy_score(failure_mode, failure_mode_predicted)\n",
    "reliability_mae = np.mean(abs(test_data_drop_df['Reliability'].values - test_data_drop_df['Predicted_Reliability'].values))\n",
    "queue_overflow_mae = np.mean(abs(test_data_drop_df['Queue_Overflow_Prob'].values - test_data_drop_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_mae = np.mean(abs(test_data_drop_df['Incorrectly_Rcvd_Prob'].values - test_data_drop_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_mae = np.mean(abs(test_data_drop_df['Delay_Excd_Prob'].values - test_data_drop_df['Predicted_Delay_Excd_Prob'].values))\n",
    "reliability_maxae = np.max(abs(test_data_drop_df['Reliability'].values - test_data_drop_df['Predicted_Reliability'].values))\n",
    "queue_overflow_maxae = np.max(abs(test_data_drop_df['Queue_Overflow_Prob'].values - test_data_drop_df['Predicted_Queue_Overflow_Prob'].values))\n",
    "incr_rcvd_maxae = np.max(abs(test_data_drop_df['Incorrectly_Rcvd_Prob'].values - test_data_drop_df['Predicted_Incr_Rcvd_Prob'].values))\n",
    "delay_excd_maxae = np.max(abs(test_data_drop_df['Delay_Excd_Prob'].values - test_data_drop_df['Predicted_Delay_Excd_Prob'].values))\n",
    "print(\"RESULTS AT DROP REGION =====================================\")\n",
    "print(\"Reliability - Accuracy: {}, MAE: {}, MaxAE: {}\".format(reliability_accuracy, reliability_mae, reliability_maxae))\n",
    "print(\"Failure Mode - Accuracy: {}\".format(failure_mode_accuracy))\n",
    "print(\"Queue Overflow - MeanAE: {}, MaxAE: {}\".format(queue_overflow_mae, queue_overflow_maxae))\n",
    "print(\"Incorrectly Received - MeanAE: {}, MaxAE: {}\".format(incr_rcvd_mae, incr_rcvd_maxae))\n",
    "print(\"Delay Exceeded - MeanAE: {}, MaxAE: {}\".format(delay_excd_mae, delay_excd_maxae))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for specific experiment no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "[0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.9999953, 0.9997854, 0.99973774, 0.9927658, 0.35241845, 0.10420601, 0.0017122723, 2.3735553e-05, 1.0709967e-06, 7.4764095e-08, 3.426935e-08, 1.8313905e-08, 1.5328803e-08, 3.7511794e-09, 1.007431e-09, 5.522583e-10, 3.1600253e-10, 1.91892e-10, 1.2267251e-10, 8.191211e-11, 5.1374297e-11, 3.3649573e-11, 2.2897871e-11, 1.6116471e-11, 1.1688064e-11, 3.3484007e-11, 1.2179403e-10, 3.05861e-10, 6.8554873e-10, 1.392557e-09, 2.5971767e-09, 4.49703e-09, 7.082125e-09, 1.0354178e-08, 1.4484203e-08, 1.9491704e-08, 2.0031996e-08, 2.0026189e-08, 2.0023096e-08, 2.0022332e-08, 2.0023592e-08, 2.002661e-08, 2.0031042e-08, 1.9356996e-08]\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "# h_dists = [50, 100, 125, 150, 175, 200, 225, 250, 300, 350, 400, 450, 500] # In m\n",
    "# h_dists = [150, 175, 200, 225, 250, 300, 350, 400, 450, 500] # In m\n",
    "# h_dists = [50, 75, 100, 112.5, 125, 137.5, 150, 162.5, 175, 187.5, 200, 212.5, 225, 237.5, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500] # In m\n",
    "# h_dists = [75, 112.5, 137.5, 162.5, 187.5, 212.5, 237.5, 275, 325, 375, 425, 475] # In m\n",
    "# h_dists = [50, 100, 112.5, 125, 137.5, 150, 162.5, 175, 187.5, 200, 212.5, 225, 237.5, 250, 300, 350, 400, 450, 500] # In m\n",
    "h_dists = np.linspace(20,500,num=49,endpoint=True)\n",
    "# h_dist = 30\n",
    "height = 70 # In m\n",
    "# heights = np.linspace(60,300,num=25,endpoint=True)\n",
    "# u2g_dist = [math.sqrt(h_dist**2 + height**2) for h_dist in h_dists]\n",
    "num_members = 7\n",
    "pkt_size = 50 # In bytes\n",
    "sending_int = 10 # In ms\n",
    "snr_moments = [sinr_lognormal_approx(h_dist, height) for h_dist in h_dists]\n",
    "# snr_moments = [sinr_lognormal_approx(h_dist, height) for height in heights]\n",
    "mean_snr = [x[0] for x in snr_moments]\n",
    "std_dev_snr = [x[1] for x in snr_moments]\n",
    "\n",
    "# max_h_dist = 550\n",
    "max_h_dist = 500\n",
    "max_height = 300\n",
    "max_num_members = 39\n",
    "# max_num_members = 7\n",
    "max_bytes = 1500 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "# max_mean_sinr = 6193 # The max mean SINR calculated at (0,24) is 668.1670595316114\n",
    "# max_std_dev_sinr = 2780 # The max std dev SINR calculated at (0,24) is 578.6543714478831\n",
    "max_mean_sinr = 521 # The max mean SINR calculated at (0,24) is 520.2907250903191\n",
    "max_std_dev_sinr = 252 # The max std dev SINR calculated at (0,24) is 251.44889082897834\n",
    "\n",
    "# norm_h_dist = [h_dist / max_h_dist for h_dist in h_dists]\n",
    "# norm_height = height / max_height\n",
    "norm_num_members = num_members / max_num_members\n",
    "norm_pkt_size = pkt_size / max_bytes\n",
    "norm_sending_int = sending_int / max_sending_int\n",
    "norm_mean_snr = [m / max_mean_sinr for m in mean_snr]\n",
    "norm_std_dev_snr = [s / max_std_dev_sinr for s in std_dev_snr]\n",
    "\n",
    "model_inputs = list(zip(norm_mean_snr, norm_std_dev_snr, repeat(norm_num_members), repeat(norm_sending_int)))\n",
    "# model_inputs = list(zip(norm_mean_snr, norm_std_dev_snr, repeat(norm_num_members), repeat(norm_pkt_size), repeat(norm_sending_int)))\n",
    "# model_inputs = list(zip(norm_h_dist, repeat(norm_height), repeat(norm_num_members), repeat(norm_pkt_size), repeat(norm_sending_int)))\n",
    "# model_input = [norm_h_dist,norm_height,norm_num_members,norm_pkt_size,norm_sending_int]\n",
    "\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "print([p[1] for p in prediction[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for single case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[array([[4.8760677e-04, 9.9951243e-01]], dtype=float32), array([[0.49350592, 0.2441833 , 0.13018824, 0.07528864, 0.03120731,\n",
      "        0.01573893, 0.0084472 , 0.0014404 ]], dtype=float32), array([[9.9970812e-01, 2.9182597e-04]], dtype=float32), array([[1.0000000e+00, 2.2164258e-20]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "h_dist = 149.966715057041 # In m\n",
    "height = 24 # In m\n",
    "num_members = 15\n",
    "pkt_size = 360 # In bytes\n",
    "sending_int = 520 # In ms\n",
    "\n",
    "max_h_dist = 550\n",
    "max_height = 120\n",
    "max_num_members = 39\n",
    "max_bytes = 1145 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "\n",
    "norm_h_dist = h_dist / max_h_dist\n",
    "norm_height = height / max_height\n",
    "norm_num_members = num_members / max_num_members\n",
    "norm_pkt_size = pkt_size / max_bytes\n",
    "norm_sending_int = sending_int / max_sending_int\n",
    "\n",
    "model_inputs = [norm_h_dist, norm_height, norm_num_members, norm_pkt_size, norm_sending_int]\n",
    "# model_input = [norm_h_dist,norm_height,norm_num_members,norm_pkt_size,norm_sending_int]\n",
    "\n",
    "prediction = model.predict([model_inputs])\n",
    "print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "# kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (len(X_train_all))\n",
    "# bias_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (len(X_train_all))\n",
    "\n",
    "inputs = Input(shape=(5,))\n",
    "base = tfp.layers.DenseFlipout(50, activation='relu')(inputs)\n",
    "base = tfp.layers.DenseFlipout(25, activation='relu')(base)\n",
    "base = tfp.layers.DenseFlipout(10, activation='relu')(base)\n",
    "reliability_hl = tfp.layers.DenseFlipout(10, activation='relu')(base)\n",
    "incr_rcvd_out_hl = tfp.layers.DenseFlipout(10, activation='relu')(base)\n",
    "delay_excd_hl = tfp.layers.DenseFlipout(10, activation='relu')(base)\n",
    "queue_overflow_hl = tfp.layers.DenseFlipout(10, activation='relu')(base)\n",
    "reliability_out = tfp.layers.DenseFlipout(2, activation='softmax', name='reliability')(reliability_hl)\n",
    "incr_rcvd_out = tfp.layers.DenseFlipout(8, activation='softmax', name='incorrectly_received')(incr_rcvd_out_hl)\n",
    "delay_excd_out = tfp.layers.DenseFlipout(2, activation='softmax', name='delay_exceeded')(delay_excd_hl)\n",
    "queue_overflow_out = tfp.layers.DenseFlipout(2, activation='softmax', name='queue_overflow')(queue_overflow_hl)\n",
    "model = Model(inputs=inputs, outputs = [reliability_out, incr_rcvd_out, delay_excd_out, queue_overflow_out])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'reliability': 'binary_crossentropy',\n",
    "                    'incorrectly_received': 'categorical_crossentropy',\n",
    "                    'delay_exceeded': 'binary_crossentropy',\n",
    "                    'queue_overflow': 'binary_crossentropy'},\n",
    "              metrics={'reliability': 'accuracy',\n",
    "                    'incorrectly_received': 'accuracy',\n",
    "                    'delay_exceeded': 'accuracy',\n",
    "                    'queue_overflow': 'accuracy'},)\n",
    "\n",
    "model.load_weights(\"/home/research-student/omnet-fanet/nn_checkpoints/bnn_v2_hovering_novideo_sinr/model.030-0.5846.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for specific experiment no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 820ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0.9999999403953552, 0.9999996423721313, 0.999481737613678, 0.015482890419661999, 6.9508882916125e-06, 1.7113026160586742e-06, 6.088038162488374e-07, 3.168134696807101e-07, 1.918535019740375e-07, 1.4957397809212125e-07, 8.649522698078727e-08, 6.263967122777103e-08, 4.356937211014156e-08, 2.0562852753869265e-08, 2.3365576140577105e-08, 3.338783116646482e-08, 3.976461826482591e-08, 4.147893051253959e-08, 2.061490889104789e-08]\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "# h_dists = [50, 100, 125, 150, 175, 200, 225, 250, 300, 350, 400, 450, 500] # In m\n",
    "# h_dists = [150, 175, 200, 225, 250, 300, 350, 400, 450, 500] # In m\n",
    "# h_dists = [50, 75, 100, 112.5, 125, 137.5, 150, 162.5, 175, 187.5, 200, 212.5, 225, 237.5, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500] # In m\n",
    "# h_dists = [75, 112.5, 137.5, 162.5, 187.5, 212.5, 237.5, 275, 325, 375, 425, 475] # In m\n",
    "# h_dists = [50, 100, 112.5, 125, 137.5, 150, 162.5, 175, 187.5, 200, 212.5, 225, 237.5, 250, 300, 350, 400, 450, 500] # In m\n",
    "h_dist = np.linspace(20,500,num=49,endpoint=True)\n",
    "height = 60 # In m\n",
    "u2g_dist = [math.sqrt(h_dist**2 + height**2) for h_dist in h_dists]\n",
    "num_members = 7\n",
    "pkt_size = 50 # In bytes\n",
    "sending_int = 10 # In ms\n",
    "snr_moments = [sinr_lognormal_approx(h_dist, height) for h_dist in h_dists]\n",
    "mean_snr = [x[0] for x in snr_moments]\n",
    "std_dev_snr = [x[1] for x in snr_moments]\n",
    "\n",
    "# max_h_dist = 550\n",
    "max_h_dist = 500\n",
    "max_height = 300\n",
    "max_num_members = 39\n",
    "# max_num_members = 7\n",
    "max_bytes = 1500 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "# max_mean_sinr = 6193 # The max mean SINR calculated at (0,24) is 668.1670595316114\n",
    "# max_std_dev_sinr = 2780 # The max std dev SINR calculated at (0,24) is 578.6543714478831\n",
    "max_mean_sinr = 521 # The max mean SINR calculated at (50,60) is 520.2907250903191\n",
    "max_std_dev_sinr = 252 # The max std dev SINR calculated at (50,60) is 251.44889082897834\n",
    "\n",
    "norm_h_dist = [h_dist / max_h_dist for h_dist in h_dists]\n",
    "norm_height = height / max_height\n",
    "norm_num_members = num_members / max_num_members\n",
    "norm_pkt_size = pkt_size / max_bytes\n",
    "norm_sending_int = sending_int / max_sending_int\n",
    "norm_mean_snr = [m / max_mean_sinr for m in mean_snr]\n",
    "norm_std_dev_snr = [s / max_std_dev_sinr for s in std_dev_snr]\n",
    "\n",
    "model_inputs = list(zip(norm_mean_snr, norm_std_dev_snr, repeat(norm_num_members), repeat(norm_pkt_size), repeat(norm_sending_int)))\n",
    "# model_inputs = list(zip(norm_h_dist, repeat(norm_height), repeat(norm_num_members), repeat(norm_pkt_size), repeat(norm_sending_int)))\n",
    "# model_input = [norm_h_dist,norm_height,norm_num_members,norm_pkt_size,norm_sending_int]\n",
    "\n",
    "\n",
    "prediction = []\n",
    "for i in range(100):\n",
    "    prediction.append([p[1] for p in model.predict(model_inputs)[0]])\n",
    "prediction = np.array(prediction).mean(axis=0)\n",
    "# print([p[1] for p in prediction[0]])\n",
    "print(prediction.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2-20032023/final_model.h5\", compile=False)\n",
    "# model.compile(optimizer='adam', \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'reliability': 'binary_crossentropy',\n",
    "                    'incorrectly_received': 'categorical_crossentropy',\n",
    "                    'delay_exceeded': 'binary_crossentropy',\n",
    "                    'queue_overflow': 'binary_crossentropy'},\n",
    "              metrics={'reliability': 'accuracy',\n",
    "                    'incorrectly_received': 'accuracy',\n",
    "                    'delay_exceeded': 'accuracy',\n",
    "                    'queue_overflow': 'accuracy'},)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Taguchi Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_data_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Stationary_Test_Dataset_NP10000_BPSK_6-5Mbps_downlink.h5\", \"Downlink\")\n",
    "\n",
    "# Normalize inputs\n",
    "max_h_dist = 550\n",
    "max_height = 120\n",
    "max_num_members = 39\n",
    "max_bytes = 1145 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "\n",
    "h_dists = test_data_df[\"Horizontal_Distance\"].values\n",
    "heights = test_data_df[\"Height\"].values\n",
    "num_members = test_data_df[\"Num_Members\"].values\n",
    "pkt_sizes = test_data_df[\"Packet_Size\"].values\n",
    "sending_ints = test_data_df[\"Sending_Interval\"].values\n",
    "\n",
    "norm_h_dist = [h_dist / max_h_dist for h_dist in h_dists]\n",
    "norm_height = [height / max_height for height in heights]\n",
    "norm_num_members = [num_member / max_num_members for num_member in num_members]\n",
    "norm_pkt_size = [pkt_size / max_bytes for pkt_size in pkt_sizes]\n",
    "norm_sending_int = [sending_int / max_sending_int for sending_int in sending_ints]\n",
    "\n",
    "# For storing prediction results\n",
    "predicted_reliability = []\n",
    "predicted_incr_rcvd = [[],[],[],[],[],[],[],[]] # List of lists to store the prob of each incr rcvd probabilities\n",
    "predicted_delay_excd = []\n",
    "predicted_queue_overflow = []\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_h_dist, norm_height, norm_num_members, norm_pkt_size, norm_sending_int))\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Save the results to CSV\n",
    "test_data_df['Predicted_Reliability'] = [prob[1] for prob in prediction[0]]\n",
    "test_data_df['Predicted_Delay_Excd_Prob'] = [prob[1] for prob in prediction[2]]\n",
    "test_data_df['Predicted_Queue_Overflow_Prob'] = [prob[1] for prob in prediction[3]]\n",
    "test_data_df['Predicted_0_Incr_Rcvd'] = [prob[0] for prob in prediction[1]]\n",
    "test_data_df['Predicted_1_Incr_Rcvd'] = [prob[1] for prob in prediction[1]]\n",
    "test_data_df['Predicted_2_Incr_Rcvd'] = [prob[2] for prob in prediction[1]]\n",
    "test_data_df['Predicted_3_Incr_Rcvd'] = [prob[3] for prob in prediction[1]]\n",
    "test_data_df['Predicted_4_Incr_Rcvd'] = [prob[4] for prob in prediction[1]]\n",
    "test_data_df['Predicted_5_Incr_Rcvd'] = [prob[5] for prob in prediction[1]]\n",
    "test_data_df['Predicted_6_Incr_Rcvd'] = [prob[6] for prob in prediction[1]]\n",
    "test_data_df['Predicted_7_Incr_Rcvd'] = [prob[7] for prob in prediction[1]]\n",
    "\n",
    "test_data_df.to_csv(\"Stationary_Test_Dataset_NP10000_BPSK_6-5Mbps_downlink_RESULTS_nnv2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2-2 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 14:51:19.033354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 14:51:19.163811: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-21 14:51:19.168666: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:19.168682: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-21 14:51:19.191290: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-21 14:51:19.646947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:19.647006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:19.647012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-21 14:51:20.390485: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-21 14:51:20.390726: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-21 14:51:20.390949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v2-2_21032023/model.010-2.0131.h5\", compile=False)\n",
    "# model.compile(optimizer='adam', \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'reliability': 'binary_crossentropy',\n",
    "                    'incorrectly_received': 'categorical_crossentropy',\n",
    "                    'delay_exceeded': 'binary_crossentropy',\n",
    "                    'queue_overflow': 'binary_crossentropy'},\n",
    "              metrics={'reliability': 'accuracy',\n",
    "                    'incorrectly_received': 'accuracy',\n",
    "                    'delay_exceeded': 'accuracy',\n",
    "                    'queue_overflow': 'accuracy'},)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using Taguchi Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_data_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Stationary_Test_Dataset_NP10000_BPSK_6-5Mbps_downlink.h5\", \"Downlink\")\n",
    "\n",
    "# Normalize inputs\n",
    "max_h_dist = 550\n",
    "max_height = 120\n",
    "max_num_members = 39\n",
    "max_bytes = 1145 # Should be 1144, but put 1145 just in case\n",
    "max_sending_int = 1000 # In ms\n",
    "\n",
    "h_dists = test_data_df[\"Horizontal_Distance\"].values\n",
    "heights = test_data_df[\"Height\"].values\n",
    "num_members = test_data_df[\"Num_Members\"].values\n",
    "pkt_sizes = test_data_df[\"Packet_Size\"].values\n",
    "sending_ints = test_data_df[\"Sending_Interval\"].values\n",
    "\n",
    "norm_h_dist = [h_dist / max_h_dist for h_dist in h_dists]\n",
    "norm_height = [height / max_height for height in heights]\n",
    "norm_num_members = [num_member / max_num_members for num_member in num_members]\n",
    "norm_pkt_size = [pkt_size / max_bytes for pkt_size in pkt_sizes]\n",
    "norm_sending_int = [sending_int / max_sending_int for sending_int in sending_ints]\n",
    "\n",
    "# For storing prediction results\n",
    "predicted_reliability = []\n",
    "predicted_incr_rcvd = [[],[],[],[],[],[],[],[]] # List of lists to store the prob of each incr rcvd probabilities\n",
    "predicted_delay_excd = []\n",
    "predicted_queue_overflow = []\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_h_dist, norm_height, norm_num_members, norm_pkt_size, norm_sending_int))\n",
    "prediction = model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Save the results to CSV\n",
    "test_data_df['Predicted_Reliability'] = [prob[1] for prob in prediction[0]]\n",
    "test_data_df['Predicted_Delay_Excd_Prob'] = [prob[1] for prob in prediction[2]]\n",
    "test_data_df['Predicted_Queue_Overflow_Prob'] = [prob[1] for prob in prediction[3]]\n",
    "test_data_df['Predicted_0_Incr_Rcvd'] = [prob[0] for prob in prediction[1]]\n",
    "test_data_df['Predicted_1_Incr_Rcvd'] = [prob[1] for prob in prediction[1]]\n",
    "test_data_df['Predicted_2_Incr_Rcvd'] = [prob[2] for prob in prediction[1]]\n",
    "test_data_df['Predicted_3_Incr_Rcvd'] = [prob[3] for prob in prediction[1]]\n",
    "test_data_df['Predicted_4_Incr_Rcvd'] = [prob[4] for prob in prediction[1]]\n",
    "test_data_df['Predicted_5_Incr_Rcvd'] = [prob[5] for prob in prediction[1]]\n",
    "test_data_df['Predicted_6_Incr_Rcvd'] = [prob[6] for prob in prediction[1]]\n",
    "test_data_df['Predicted_7_Incr_Rcvd'] = [prob[7] for prob in prediction[1]]\n",
    "\n",
    "test_data_df.to_csv(\"Stationary_Test_Dataset_NP10000_BPSK_6-5Mbps_downlink_RESULTS_nn_V2-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_64QAM_65Mbps_Hovering/Dataset_NP10000_64QAM_65Mbps_Hovering_8UAVs_processed_downlink.h5\", key=\"8_UAVs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "autoencoder = keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/ae_multimodulation_novideo_sinr_ul/final_model.h5\", compile=False)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics='mse')\n",
    "# Get the encoder part of the autoencoder\n",
    "encoder_layer = autoencoder.get_layer('latent')\n",
    "encoder = Model(inputs=autoencoder.input, outputs=encoder_layer.output)\n",
    "\n",
    "out = encoder.predict([[1,0.2,0.3,0.4],[0.5,0.6,0.7,0.8]])\n",
    "out = np.concatenate((out, encoder.predict([[1,0.2,0.3,0.4],[0.5,0.6,0.7,0.8]])), axis=0)\n",
    "\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Concatenate\n",
    "import numpy as np\n",
    "\n",
    "autoencoder = keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/ae_multimodulation_novideo_sinr_ul/final_model.h5\", compile=False)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics='mse')\n",
    "# Get the encoder part of the autoencoder\n",
    "encoder_input = autoencoder.get_layer('encoder')\n",
    "encoder_layer = autoencoder.get_layer('latent')\n",
    "# Freeze the encoder part\n",
    "encoder_input.trainable = False\n",
    "encoder_layer.trainable = False\n",
    "# Create hierarchical model\n",
    "haenn = keras.Sequential(\n",
    "    [\n",
    "        Input(shape=(4,)),\n",
    "        encoder_input,\n",
    "        encoder_layer,\n",
    "        Dense(25, activation='relu', name='classifier_1'),\n",
    "        BatchNormalization(name='batch_norm_1'), \n",
    "        Dense(10, activation='relu', name='classifier_2'),\n",
    "        BatchNormalization(name='batch_norm_2'), \n",
    "        Dense(1, activation='linear', name='indicator')\n",
    "    ]\n",
    ")\n",
    "\n",
    "haenn.compile(optimizer='adam', \n",
    "              loss={'indicator': 'mae'},\n",
    "              metrics={'indicator': 'accuracy'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Throughput NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 11:59:26.055496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055875: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-02 11:59:26.055922: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-02 11:59:26.056230: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step\n",
      "Throughput - MAE: 102.56724347976599, MaxAE: 7214.190617217042\n"
     ]
    }
   ],
   "source": [
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "              loss={'throughput': 'mse'},\n",
    "              metrics={'throughput': 'accuracy'})\n",
    "\n",
    "# Set the link type IMPORTANT!!!\n",
    "link_type = 'downlink'\n",
    "\n",
    "# Load test dataset\n",
    "test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_MeanThroughput.csv\")\n",
    "# test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_MeanThroughput.csv\")\n",
    "\n",
    "# Calculate mean and std dev of SINR\n",
    "test_data_df[['Mean_SINR',\"Std_Dev_SINR\"]] = test_data_df.apply(lambda row: sinr_lognormal_approx(row['Horizontal_Distance'],row['Height']),axis=1,result_type='expand')\n",
    "test_data_df[\"Mean_SINR_dB\"] = test_data_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "test_data_df[\"Std_Dev_SINR_dB\"] = test_data_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "\n",
    "mean_sinr = test_data_df[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = test_data_df[\"Std_Dev_SINR_dB\"].values\n",
    "\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = test_data_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = test_data_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"uplink\":\n",
    "    # max_throughput = 10*math.log10(500000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"downlink\":\n",
    "    # max_throughput = 10*math.log10(20000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"video\":\n",
    "    # max_throughput = 10*math.log10(250000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "# (10*math.log10(x)-min_throughput)/(max_throughput-min_throughput)\n",
    "# test_data_df['Predicted_Throughput'] = [10**((prob[0]*(max_throughput-min_throughput)+min_throughput)/10) for prob in prediction]\n",
    "test_data_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "\n",
    "throughput_mae = np.mean(abs(test_data_df['MeanThroughput'].values - test_data_df['Predicted_Throughput'].values))\n",
    "throughput_max_ae = np.max(abs(test_data_df['MeanThroughput'].values - test_data_df['Predicted_Throughput'].values))\n",
    "\n",
    "# Print results\n",
    "print(\"Throughput - MAE: {}, MaxAE: {}\".format(throughput_mae, throughput_max_ae))\n",
    "\n",
    "# test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Multi_Modulation_Test_Cases_Uplink_NN_Throughput_RESULTS.csv\")\n",
    "# test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Video_Multi_Modulation_Test_Cases_1_Downlink_Throughput_NN_RESULTS.csv\")\n",
    "test_data_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Throughput_NN_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "[16297.720670700073, 16318.011283874512, 16379.837989807129, 16355.843544006348, 16280.628442764282, 16196.19369506836, 16178.302764892578, 16223.556995391846, 16242.589950561523, 16028.822660446167, 12230.572700500488, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "# throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_multimodulation_video_sinr_ul/model.005-0.0007.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "              loss={'throughput': 'mse'},\n",
    "              metrics={'throughput': 'accuracy'})\n",
    "\n",
    "# Set the link type IMPORTANT!!!\n",
    "link_type = 'downlink'\n",
    "\n",
    "# Load test dataset\n",
    "test_data_df = pd.DataFrame({\"Horizontal_Distance\": [i*20 for i in range(15)],\n",
    "                             \"Height\": [60 for i in range(15)],\n",
    "                             \"Modulation\": [\"QAM16\" for i in range(15)],\n",
    "                             \"UAV_Sending_Interval\": [20 for i in range(15)]})\n",
    "# test_data_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_MeanThroughput.csv\")\n",
    "\n",
    "# Calculate mean and std dev of SINR\n",
    "test_data_df[['Mean_SINR',\"Std_Dev_SINR\"]] = test_data_df.apply(lambda row: sinr_lognormal_approx(row['Horizontal_Distance'],row['Height']),axis=1,result_type='expand')\n",
    "test_data_df[\"Mean_SINR_dB\"] = test_data_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "test_data_df[\"Std_Dev_SINR_dB\"] = test_data_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "\n",
    "mean_sinr = test_data_df[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = test_data_df[\"Std_Dev_SINR_dB\"].values\n",
    "\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = test_data_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = test_data_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "# print(prediction)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"uplink\":\n",
    "    # max_throughput = 10*math.log10(500000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"downlink\":\n",
    "    # max_throughput = 10*math.log10(20000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"video\":\n",
    "    # max_throughput = 10*math.log10(250000) \n",
    "    # min_throughput = 10*math.log10(1) # We make the min throughput to be 1 so that log(min_throughput) does not go to -inf\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "# (10*math.log10(x)-min_throughput)/(max_throughput-min_throughput)\n",
    "# test_data_df['Predicted_Throughput'] = [10**((prob[0]*(max_throughput-min_throughput)+min_throughput)/10) for prob in prediction]\n",
    "predicted_throughput = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "print(predicted_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Anomality Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Anomaly Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set link type\n",
    "link_type = 'downlink' # 'uplink', 'downlink', 'video'\n",
    "\n",
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "              loss={'throughput': 'mse'},\n",
    "              metrics={'throughput': 'accuracy'})\n",
    "\n",
    "# Load base case reliability df\n",
    "base_case_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_Reliability.csv\")\n",
    "base_case_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "base_case_df[\"Reliability\"] = base_case_df[\"Num_Reliable\"] / base_case_df[\"Num_Sent\"]\n",
    "\n",
    "# Load anomaly dataset\n",
    "anomaly_reliability_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Anomaly_Type1_4UAV_Moderate/TestCase8_Anomaly_Type1_4UAV_Moderate_Downlink_Reliability.csv\")\n",
    "anomaly_throughput_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Anomaly_Type1_4UAV_Moderate/TestCase8_Anomaly_Type1_4UAV_Moderate_Downlink_MeanThroughput.csv\")\n",
    "anomaly_reliability_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "anomaly_throughput_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "anomaly_reliability_df[\"Reliability\"] = anomaly_reliability_df[\"Num_Reliable\"] / anomaly_reliability_df[\"Num_Sent\"]\n",
    "\n",
    "# Make sure the horizontal distances, height, UAV send int and modulation between base case and anomaly are the same\n",
    "base_case_scenario = base_case_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "anomaly_reliability_scenario = anomaly_reliability_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "anomaly_throughput_scenario = anomaly_throughput_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "assert base_case_scenario.equals(anomaly_reliability_scenario), \"Inputs of Base Case and Anomaly Reliability DFs Does Not Match!\"\n",
    "assert anomaly_throughput_scenario.equals(anomaly_reliability_scenario), \"Inputs of Anomaly Reliability and Anomaly Throughput DFs Does Not Match!\"\n",
    "\n",
    "# Process input data\n",
    "base_case_df[\"Mean_SINR_dB\"] = base_case_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "base_case_df[\"Std_Dev_SINR_dB\"] = base_case_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "mean_sinr = base_case_df[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = base_case_df[\"Std_Dev_SINR_dB\"].values\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = base_case_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = base_case_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"uplink\":\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"downlink\":\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"video\":\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "\n",
    "# If using mean throughput from simulation to test, UNCOMMENT below ---------------------------------------------------\n",
    "anomaly_throughput_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "anomaly_throughput_df[\"Abs_Err_Throughput\"] = abs(anomaly_throughput_df['MeanThroughput'].values - anomaly_throughput_df['Predicted_Throughput'].values)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # If using throughput samples from simulation to test, UNCOMMENT below ------------------------------------------------\n",
    "# base_case_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "# def find_throughput(h_dist, height, df):\n",
    "#     # Using h_dist and height, find the value of \"Predicted_Throughput\" in df\n",
    "#     return df.loc[(df[\"Horizontal_Distance\"] == h_dist) & (df[\"Height\"] == height)][\"Predicted_Throughput\"].values[0]\n",
    "# anomaly_throughput_df[\"Predicted_Throughput\"] = anomaly_throughput_df.apply(lambda x: find_throughput(x['Horizontal_Distance'], x['Height'], base_case_df), axis=1)\n",
    "# anomaly_throughput_df[\"Abs_Err_Throughput\"] = abs(anomaly_throughput_df['Throughput'].values - anomaly_throughput_df['Predicted_Throughput'].values)\n",
    "# # ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Ground truth for anomaly (compare difference between base and anomalous reliability based on a threshold)\n",
    "RELIABILITY_DIFF_TH = 0.02 # Threshold for considering anomalous reliability \n",
    "anomaly_reliability_df[\"Abs_Err_Reliability\"] = abs(anomaly_reliability_df[\"Reliability\"].values - base_case_df[\"Reliability\"].values)\n",
    "anomaly_reliability_df[\"Anomaly\"] = anomaly_reliability_df[\"Abs_Err_Reliability\"] > RELIABILITY_DIFF_TH\n",
    "\n",
    "# Detecting for anomaly using predicted throughput\n",
    "# Method 1, using mean and std dev of abs err in throughput prediction --------------------------------------------------\n",
    "MAE_THROUGHPUT = 225 # Mean of abs err for predicted throughput\n",
    "SAE_THROUGHPUT = 550 # Std Dev of abs err for predicted throughput\n",
    "THROUGHPUT_DIFF_TH = MAE_THROUGHPUT + 2*SAE_THROUGHPUT # Threshold for predicting anomalous reliability \n",
    "anomaly_reliability_df[\"Predicted_Anomaly\"] = anomaly_throughput_df[\"Abs_Err_Throughput\"] > THROUGHPUT_DIFF_TH\n",
    "\n",
    "anomaly_reliability_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Anomaly_Type1_4UAV_Moderate/TestCase8_Anomaly_Type1_4UAV_Moderate_Downlink_AnomalyDetection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Anomaly Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 20:44:50.791443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791790: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-02 20:44:50.791851: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-02 20:44:50.792216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Mean Abs Err Corrected Reliability:  0.006029188358247717\n",
      "Anomaly Accuracy Score:  0.9453551912568307\n",
      "Anomaly Sensitivity Score:  0.7857142857142857\n",
      "Anomaly Specificity Score:  0.9831081081081081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2df05c35e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set link type\n",
    "link_type = 'Downlink' # 'Uplink', 'Downlink', 'Video'\n",
    "\n",
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "            loss={'throughput': 'mse'},\n",
    "            metrics={'throughput': 'accuracy'})\n",
    "\n",
    "reliability_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/nn_v4_multimodulation_video_sinr_dl/model.001-0.2191.h5\", compile=False)\n",
    "reliability_model.compile(optimizer='adam', \n",
    "              loss={'packet_state': 'categorical_crossentropy'},\n",
    "              metrics={'packet_state': 'accuracy'})\n",
    "\n",
    "# Load base case reliability df\n",
    "base_case_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_Reliability.csv\")\n",
    "base_case_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "base_case_df[\"Reliability\"] = base_case_df[\"Num_Reliable\"] / base_case_df[\"Num_Sent\"]\n",
    "\n",
    "# Process input data\n",
    "base_case_df[\"Mean_SINR_dB\"] = base_case_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "base_case_df[\"Std_Dev_SINR_dB\"] = base_case_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "mean_sinr = base_case_df[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = base_case_df[\"Std_Dev_SINR_dB\"].values\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = base_case_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = base_case_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "# Get base case predicted throughput\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "throughput_prediction = throughput_model.predict(model_inputs)\n",
    "reliability_prediction = reliability_model.predict(model_inputs)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"Uplink\":\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"Downlink\":\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"Video\":\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "\n",
    "base_case_scenario = base_case_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "\n",
    "anomaly_types = [\"Type1\", \"Type2\"]\n",
    "num_uavs = [1,2,4]\n",
    "anomaly_dists = [\"Near\", \"Moderate\", \"Far\"]\n",
    "\n",
    "anomaly_df_list = []\n",
    "for anomaly_type in anomaly_types:\n",
    "    for num_uav in num_uavs:\n",
    "        for anomaly_dist in anomaly_dists:\n",
    "            # Load anomaly dataset\n",
    "            anomaly_root_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Anomaly_{}_{}UAV_{}\".format(anomaly_type, num_uav, anomaly_dist)\n",
    "            anomaly_reliability_df = pd.read_csv(os.path.join(anomaly_root_path, \"TestCase8_Anomaly_{}_{}UAV_{}_{}_Reliability.csv\".format(anomaly_type, num_uav, anomaly_dist, link_type)))\n",
    "            anomaly_throughput_df = pd.read_csv(os.path.join(anomaly_root_path, \"TestCase8_Anomaly_{}_{}UAV_{}_{}_MeanThroughput.csv\".format(anomaly_type, num_uav, anomaly_dist, link_type)))\n",
    "            anomaly_reliability_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "            anomaly_throughput_df.sort_values(by=[\"Horizontal_Distance\"], inplace=True) # Sort just in case. Each case should only be one scenario\n",
    "            anomaly_reliability_df[\"Reliability\"] = anomaly_reliability_df[\"Num_Reliable\"] / anomaly_reliability_df[\"Num_Sent\"]\n",
    "            anomaly_reliability_df[\"Base_Case_Reliability\"] = base_case_df[\"Reliability\"]\n",
    "            anomaly_reliability_df[\"Predicted_Reliability\"] = [prob[0] for prob in reliability_prediction]\n",
    "\n",
    "            # Make sure the horizontal distances, height, UAV send int and modulation between base case and anomaly are the same\n",
    "            anomaly_reliability_scenario = anomaly_reliability_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "            anomaly_throughput_scenario = anomaly_throughput_df[[\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\"]]\n",
    "            assert base_case_scenario.equals(anomaly_reliability_scenario), \"Inputs of Base Case and Anomaly Reliability DFs Does Not Match!\"\n",
    "            assert anomaly_throughput_scenario.equals(anomaly_reliability_scenario), \"Inputs of Anomaly Reliability and Anomaly Throughput DFs Does Not Match!\"\n",
    "\n",
    "            # If using mean throughput from simulation to test, UNCOMMENT below ---------------------------------------------------\n",
    "            anomaly_reliability_df['Mean_Throughput'] = anomaly_throughput_df['MeanThroughput'].values\n",
    "            anomaly_reliability_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in throughput_prediction]\n",
    "            anomaly_reliability_df[\"Abs_Err_Throughput\"] = abs(anomaly_throughput_df['MeanThroughput'].values - anomaly_reliability_df['Predicted_Throughput'].values)\n",
    "            # ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            # # If using throughput samples from simulation to test, UNCOMMENT below ------------------------------------------------\n",
    "            # base_case_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "            # def find_throughput(h_dist, height, df):\n",
    "            #     # Using h_dist and height, find the value of \"Predicted_Throughput\" in df\n",
    "            #     return df.loc[(df[\"Horizontal_Distance\"] == h_dist) & (df[\"Height\"] == height)][\"Predicted_Throughput\"].values[0]\n",
    "            # anomaly_throughput_df[\"Predicted_Throughput\"] = anomaly_throughput_df.apply(lambda x: find_throughput(x['Horizontal_Distance'], x['Height'], base_case_df), axis=1)\n",
    "            # anomaly_throughput_df[\"Abs_Err_Throughput\"] = abs(anomaly_throughput_df['Throughput'].values - anomaly_throughput_df['Predicted_Throughput'].values)\n",
    "            # # ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Ground truth for anomaly (compare difference between base and anomalous reliability based on a threshold)\n",
    "            RELIABILITY_DIFF_TH = 0.02 # Threshold for considering anomalous reliability \n",
    "            anomaly_reliability_df[\"Abs_Diff_Reliability\"] = abs(anomaly_reliability_df[\"Reliability\"].values - base_case_df[\"Reliability\"].values)\n",
    "            anomaly_reliability_df[\"Anomaly\"] = anomaly_reliability_df[\"Abs_Diff_Reliability\"] > RELIABILITY_DIFF_TH\n",
    "\n",
    "            # Detecting for anomaly using predicted throughput\n",
    "            # Method 1, using mean and std dev of abs err in throughput prediction --------------------------------------------------\n",
    "            THROUGHPUT_DIFF_TH = 995 # Threshold for predicting anomalous reliability \n",
    "            anomaly_reliability_df[\"Predicted_Anomaly\"] = anomaly_reliability_df[\"Abs_Err_Throughput\"] > THROUGHPUT_DIFF_TH\n",
    "\n",
    "            # Record the anomaly test case details\n",
    "            anomaly_reliability_df[\"Type\"] = anomaly_type\n",
    "            anomaly_reliability_df[\"Num_Interferer_UAV\"] = num_uav\n",
    "            anomaly_reliability_df[\"Interferer_Distance\"] = anomaly_dist\n",
    "            anomaly_df_list.append(anomaly_reliability_df)\n",
    "\n",
    "anomaly_df = pd.concat(anomaly_df_list)\n",
    "# Get corrected reliability\n",
    "anomaly_df[\"Corrected_Reliability\"] = anomaly_df[\"Mean_Throughput\"] / anomaly_df[\"Predicted_Throughput\"] * anomaly_df[\"Predicted_Reliability\"]\n",
    "anomaly_df.loc[anomaly_df[\"Predicted_Throughput\"]==0, \"Corrected_Reliability\"] = 0\n",
    "anomaly_df[\"Abs_Err_Corrected_Reliability\"] = abs(anomaly_df[\"Reliability\"].values - anomaly_df[\"Corrected_Reliability\"].values)\n",
    "print(\"Mean Abs Err Corrected Reliability: \", anomaly_df[\"Abs_Err_Corrected_Reliability\"].mean())\n",
    "\n",
    "# Save results to CSV\n",
    "anomaly_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Downlink_AnomalyDetection.csv\")\n",
    "\n",
    "# Get anomaly detection accuracy and confusion matrix\n",
    "cm = confusion_matrix(anomaly_df[\"Anomaly\"], anomaly_df[\"Predicted_Anomaly\"])\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Anomaly Accuracy Score: \", ACC[1])\n",
    "print(\"Anomaly Sensitivity Score: \", TPR[1])\n",
    "print(\"Anomaly Specificity Score: \", TNR[1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array([\"No Anomaly\", \"Anomaly\"]))\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Base Case Throughput (for False Positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8c74534040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set link type\n",
    "link_type = 'downlink' # 'uplink', 'downlink', 'video'\n",
    "\n",
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "              loss={'throughput': 'mse'},\n",
    "              metrics={'throughput': 'accuracy'})\n",
    "\n",
    "# Load base case reliability df\n",
    "base_case_throughput_df = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_MeanThroughput.csv\")\n",
    "\n",
    "# Process input data\n",
    "base_case_throughput_df[\"Mean_SINR_dB\"] = base_case_throughput_df[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "base_case_throughput_df[\"Std_Dev_SINR_dB\"] = base_case_throughput_df[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "mean_sinr = base_case_throughput_df[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = base_case_throughput_df[\"Std_Dev_SINR_dB\"].values\n",
    "base_case_throughput_df.drop([\"Mean_SINR_dB\", \"Std_Dev_SINR_dB\"], axis=1)\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = base_case_df[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = base_case_df[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"uplink\":\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"downlink\":\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"video\":\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "\n",
    "base_case_throughput_df['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "base_case_throughput_df[\"Abs_Err_Throughput\"] = abs(base_case_throughput_df['MeanThroughput'].values - base_case_throughput_df['Predicted_Throughput'].values)\n",
    "\n",
    "# Detecting for anomaly using predicted throughput\n",
    "# Method 1, using mean and std dev of abs err in throughput prediction --------------------------------------------------\n",
    "MAE_THROUGHPUT = 225 # Mean of abs err for predicted throughput\n",
    "SAE_THROUGHPUT = 550 # Std Dev of abs err for predicted throughput\n",
    "THROUGHPUT_DIFF_TH = MAE_THROUGHPUT + 2*SAE_THROUGHPUT # Threshold for predicting anomalous reliability \n",
    "base_case_throughput_df[\"Predicted_Anomaly\"] = base_case_throughput_df[\"Abs_Err_Throughput\"] > THROUGHPUT_DIFF_TH\n",
    "\n",
    "base_case_throughput_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Anomaly/TestCase8_Base_Case/TestCase8_Base_Case_Downlink_PredictedThroughput.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Holdout Dataset (To calculate threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mean throughput\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 16:18:20.441893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.441967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442229: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-02 16:18:20.442239: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-02 16:18:20.442531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_troughput_train_holdout_dataset(dataset_details_csv, holdout_split=0.2):\n",
    "    df_dtypes = {\"Horizontal_Distance\": np.float32, \"Height\": np.int16,\t\"U2G_Distance\": np.int32, \"UAV_Sending_Interval\": np.int16, \"Mean_SINR\": np.float32, \"Std_Dev_SINR\": np.float32,\n",
    "                 \"Modulation\": 'string', \"Num_Sent\": np.int32, \"Num_Reliable\": np.int32, \"Num_Delay_Excd\": np.int32, \"Num_Incr_Rcvd\": np.int32, \"Num_Q_Overflow\": np.int32}\n",
    "    dataset_details = pd.read_csv(dataset_details_csv, \n",
    "                                  usecols = [\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\", \"Throughput\", \"Num_Count\"],\n",
    "                                  dtype=df_dtypes)\n",
    "    \n",
    "    # For each scenario, get the throughput data and split it to train and holdout \n",
    "    scenarios = dataset_details[['Mean_SINR','Std_Dev_SINR','Modulation','UAV_Sending_Interval']].drop_duplicates()\n",
    "    df_train_list = []\n",
    "    df_holdout_list = []\n",
    "    for scenario in scenarios.itertuples():\n",
    "        scenario_df = dataset_details.loc[(dataset_details[\"Modulation\"] == scenario.Modulation) & (dataset_details[\"UAV_Sending_Interval\"] == scenario.UAV_Sending_Interval) & \n",
    "                          (dataset_details[\"Mean_SINR\"] == scenario.Mean_SINR) & (dataset_details[\"Std_Dev_SINR\"] == scenario.Std_Dev_SINR)]\n",
    "        df_list = []\n",
    "        for row in scenario_df.itertuples():\n",
    "            throughput_data = {\"Mean_SINR\": row.Mean_SINR, \"Std_Dev_SINR\": row.Std_Dev_SINR, \"UAV_Sending_Interval\": row.UAV_Sending_Interval, \"Modulation\": row.Modulation, \"Throughput\": row.Throughput}\n",
    "            # If Num_Count is one, just append the row to df_list\n",
    "            if row.Num_Count == 1:\n",
    "                df_list.append(throughput_data)\n",
    "            else:\n",
    "                df_list = df_list + [throughput_data.copy() for i in range(row.Num_Count)]\n",
    "        df = pd.DataFrame(df_list)\n",
    "        train, holdout = train_test_split(df, test_size=holdout_split, random_state=40, shuffle=True)\n",
    "        df_train_list.append(train)\n",
    "        df_holdout_list.append(holdout)\n",
    "    df_train = pd.concat(df_train_list)\n",
    "    df_holdout = pd.concat(df_holdout_list)\n",
    "    return df_train, df_holdout\n",
    "\n",
    "def process_mean_throughput(df):\n",
    "    '''\n",
    "    Calculate the mean throughput for each scenario\n",
    "    Modified for this test script usage\n",
    "    '''\n",
    "    scenarios = df[['Mean_SINR','Std_Dev_SINR','Modulation','UAV_Sending_Interval']].drop_duplicates()\n",
    "    output_df_list = []\n",
    "    for row in scenarios.itertuples():\n",
    "        scenario = df.loc[(df[\"Modulation\"] == row.Modulation) & (df[\"UAV_Sending_Interval\"] == row.UAV_Sending_Interval) & \n",
    "                          (df[\"Mean_SINR\"] == row.Mean_SINR) & (df[\"Std_Dev_SINR\"] == row.Std_Dev_SINR)]\n",
    "        mean_throughput = scenario.Throughput.mean()\n",
    "        output_df_list.append({\"UAV_Sending_Interval\": row.UAV_Sending_Interval, \"Modulation\": row.Modulation, \"Mean_SINR\": row.Mean_SINR, \"Std_Dev_SINR\": row.Std_Dev_SINR, \"MeanThroughput\": mean_throughput})\n",
    "    return pd.DataFrame(output_df_list)\n",
    "\n",
    "# Load dataset =================================================\n",
    "print(\"Loading dataset\")\n",
    "DATASET_PATH = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video\"\n",
    "df_bpsk_train, df_bpsk_holdout = generate_troughput_train_holdout_dataset(os.path.join(DATASET_PATH, \"BPSK/BPSK_Downlink_Throughput.csv\"), holdout_split=0.2)\n",
    "df_qpsk_train, df_qpsk_holdout = generate_troughput_train_holdout_dataset(os.path.join(DATASET_PATH, \"QPSK/QPSK_Downlink_Throughput.csv\"), holdout_split=0.2)\n",
    "df_qam16_train, df_qam16_holdout = generate_troughput_train_holdout_dataset(os.path.join(DATASET_PATH, \"QAM16/QAM16_Downlink_Throughput.csv\"), holdout_split=0.2)\n",
    "df_qam64_train, df_qam64_holdout = generate_troughput_train_holdout_dataset(os.path.join(DATASET_PATH, \"QAM64/QAM64_Downlink_Throughput.csv\"), holdout_split=0.2)\n",
    "df_holdout = pd.concat([df_bpsk_holdout, df_qpsk_holdout, df_qam16_holdout, df_qam64_holdout])\n",
    "print(\"Processing mean throughput\")\n",
    "df_holdout = process_mean_throughput(df_holdout)\n",
    "\n",
    "# Set link type\n",
    "link_type = 'downlink' # 'uplink', 'downlink', 'video'\n",
    "\n",
    "# Load throughput prediction model\n",
    "throughput_model = tf.keras.models.load_model(\"/home/research-student/omnet-fanet/nn_checkpoints/throughput_predict_nn_v4_video_sinr_dl/model.020-0.0020.h5\", compile=False)\n",
    "throughput_model.compile(optimizer='adam', \n",
    "              loss={'throughput': 'mse'},\n",
    "              metrics={'throughput': 'accuracy'})\n",
    "\n",
    "# Process input data\n",
    "df_holdout[\"Mean_SINR_dB\"] = df_holdout[\"Mean_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "df_holdout[\"Std_Dev_SINR_dB\"] = df_holdout[\"Std_Dev_SINR\"].apply(lambda x: 10*math.log10(x))\n",
    "mean_sinr = df_holdout[\"Mean_SINR_dB\"].values\n",
    "std_dev_sinr = df_holdout[\"Std_Dev_SINR_dB\"].values\n",
    "df_holdout.drop([\"Mean_SINR_dB\", \"Std_Dev_SINR_dB\"], axis=1, inplace=True)\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = df_holdout[\"UAV_Sending_Interval\"].replace({10:-1, 20:-0.5, 40:0, 100:0.5, 1000:1}).values\n",
    "norm_modulation = df_holdout[\"Modulation\"].replace({\"BPSK\":1, \"QPSK\":0.3333, \"QAM16\":-0.3333, \"QAM64\":-1}).values\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "\n",
    "# Convert output to throughput in bps\n",
    "if link_type == \"uplink\":\n",
    "    max_throughput = 500000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"downlink\":\n",
    "    max_throughput = 20000\n",
    "    min_throughput = 0\n",
    "elif link_type == \"video\":\n",
    "    max_throughput = 250000 \n",
    "    min_throughput = 0\n",
    "\n",
    "df_holdout['Predicted_Throughput'] = [prob[0]*(max_throughput-min_throughput)+min_throughput for prob in prediction]\n",
    "df_holdout[\"Abs_Err_Throughput\"] = abs(df_holdout['MeanThroughput'].values - df_holdout['Predicted_Throughput'].values)\n",
    "df_holdout.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Holdout_Dataset_Downlink_PredictedThroughput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "mean_sinr = [700, 918]\n",
    "std_dev_sinr = [300, 402]\n",
    "# Normalize inputs\n",
    "max_mean_sinr = 10*math.log10(1123) # The max mean SINR calculated at (0,60) is 1122.743643457063 (linear)\n",
    "max_std_dev_sinr = 10*math.log10(466) # The max std dev SINR calculated at (0,60) is 465.2159856885714 (linear)\n",
    "min_mean_sinr = 10*math.log10(0.2) # The min mean SINR calculated at (1200,60) is 0.2251212887895188 (linear)\n",
    "min_std_dev_sinr = 10*math.log10(0.7) # The min std dev SINR calculated at (1200,300) is 0.7160093126585219 (linear)\n",
    "norm_mean_sinr = [2*(m-min_mean_sinr) / (max_mean_sinr-min_mean_sinr) - 1 for m in mean_sinr]\n",
    "norm_std_dev_sinr = [2*(s-min_std_dev_sinr) / (max_std_dev_sinr-min_std_dev_sinr) - 1 for s in std_dev_sinr]\n",
    "norm_uav_send_int = [-1, -1]\n",
    "norm_modulation = [1,1]\n",
    "\n",
    "# Run inference\n",
    "model_inputs = list(zip(norm_mean_sinr, norm_std_dev_sinr, norm_uav_send_int, norm_modulation))\n",
    "prediction = throughput_model.predict(model_inputs)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
