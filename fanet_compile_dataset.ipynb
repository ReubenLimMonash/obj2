{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import glob, math\n",
    "import cudf \n",
    "from tqdm import tqdm\n",
    "from scipy import special\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def h_dist_calc(row):\n",
    "    # Function to calc euclidean distance on every df row \n",
    "    h_dist = math.sqrt(row[\"U2G_Distance\"]**2 - row[\"Height\"]**2)\n",
    "    return h_dist\n",
    "\n",
    "def q_func(x):\n",
    "    q = 0.5 - 0.5*special.erf(x / np.sqrt(2))\n",
    "    return q\n",
    "\n",
    "def friis_calc(P,freq,dist,ple):\n",
    "    '''\n",
    "    Friis path loss equation\n",
    "    P = Tx transmit power\n",
    "    freq = Signal frequency\n",
    "    dist = Transmission distance\n",
    "    ple = Path loss exponent\n",
    "    '''\n",
    "    propagation_speed = 299792458\n",
    "    l = propagation_speed / freq\n",
    "    h_pl = P * l**2 / (16*math.pi**2)\n",
    "    P_Rx = h_pl * dist**(-ple)\n",
    "    return P_Rx\n",
    "\n",
    "def plos_calc(h_dist, height_tx, height_rx, env='suburban'):\n",
    "    '''\n",
    "    % This function implements the LoS probability model from the paper\n",
    "    % \"Blockage Modeling for Inter-layer UAVs Communications in Urban\n",
    "    % Environments\" \n",
    "    % param h_dist    : horizontal distance between Tx and Rx (m)\n",
    "    % param height_tx : height of Tx\n",
    "    % param height_rx : height of Rx\n",
    "    '''\n",
    "    if env == 'suburban':\n",
    "        a1 = 0.1\n",
    "        a2 = 7.5e-4\n",
    "        a3 = 8\n",
    "    \n",
    "    delta_h = height_tx - height_rx\n",
    "    # pow_factor = 2 * h_dist * math.sqrt(a1*a2/math.pi) + a1 # NOTE: Use this pow_factor if assuming PPP building dist.\n",
    "    pow_factor = h_dist * math.sqrt(a1*a2) # NOTE: Use this pow_factor if assuming ITU-R assumptions.\n",
    "    if delta_h == 0:\n",
    "        p = (1 - math.exp((-(height_tx)**2) / (2*a3**2))) ** pow_factor\n",
    "    else:\n",
    "        if delta_h < 0:\n",
    "            h1 = height_rx\n",
    "            h2 = height_tx\n",
    "        else:\n",
    "            h1 = height_tx\n",
    "            h2 = height_rx\n",
    "        delta_h = abs(delta_h)\n",
    "        p = (1 - (math.sqrt(2*math.pi)*a3 / delta_h) * abs(q_func(h1/a3) - q_func(h2/a3))) ** pow_factor\n",
    "    return p\n",
    "\n",
    "def sinr_lognormal_approx(h_dist, height, env='suburban'):\n",
    "    '''\n",
    "    To approximate the SNR from signal considering multipath fading and shadowing\n",
    "    Assuming no interference due to CSMA, and fixed noise\n",
    "    Inputs:\n",
    "    h_dist = Horizontal Distance between Tx and Rx\n",
    "    height = Height difference between Tx and Rx\n",
    "    env = The operating environment (currently only suburban supported)\n",
    "    '''\n",
    "    # Signal properties\n",
    "    P_Tx_dBm = 20 # Transmit power of \n",
    "    P_Tx = 10**(P_Tx_dBm/10) / 1000\n",
    "    freq = 2.4e9 # Channel frequency (Hz)\n",
    "    noise_dBm = -86\n",
    "    noise = 10**(noise_dBm/10) / 1000\n",
    "    if env == \"suburban\":\n",
    "        # ENV Parameters Constants ----------------------------------\n",
    "        # n_min = 2\n",
    "        # n_max = 2.75\n",
    "        # K_dB_min = 7.8\n",
    "        # K_dB_max = 17.5\n",
    "        # K_min = 10**(K_dB_min/10)\n",
    "        # K_max = 10**(K_dB_max/10)\n",
    "        # alpha = 11.25 # Env parameters for logarithm std dev of shadowing \n",
    "        # beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        n_min = 2\n",
    "        n_max = 2.75\n",
    "        K_dB_min = 1.4922\n",
    "        K_dB_max = 12.2272\n",
    "        K_min = 10**(K_dB_min/10)\n",
    "        K_max = 10**(K_dB_max/10)\n",
    "        alpha = 11.1852 # Env parameters for logarithm std dev of shadowing \n",
    "        beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        # -----------------------------------------------------------\n",
    "    # Calculate fading parameters\n",
    "    PLoS = plos_calc(h_dist, 0, height, env='suburban')\n",
    "    theta_Rx = math.atan2(height, h_dist) * 180 / math.pi # Elevation angle in degrees\n",
    "    ple = (n_min - n_max) * PLoS + n_max # Path loss exponent\n",
    "    sigma_phi_dB = alpha*math.exp(-beta*theta_Rx)\n",
    "    sigma_phi = 10**(sigma_phi_dB/10) # Logarithmic std dev of shadowing\n",
    "    K = K_min * math.exp(math.log(K_max/K_min) * PLoS**2)\n",
    "    omega = 1 # Omega of NCS (Rician)\n",
    "    dist = math.sqrt(h_dist**2 + height**2)\n",
    "    P_Rx = friis_calc(P_Tx, freq, dist, ple)\n",
    "    # Approximate L-NCS RV (which is the SNR) as lognormal\n",
    "    eta = math.log(10) / 10\n",
    "    mu_phi = 10*math.log10(P_Rx)\n",
    "    E_phi = math.exp(eta*mu_phi + eta**2*sigma_phi**2/2) # Mean of shadowing RV\n",
    "    var_phi = math.exp(2*eta*mu_phi+eta**2*sigma_phi**2)*(math.exp(eta**2*sigma_phi**2)-1) # Variance of shadowing RV\n",
    "    E_chi = (special.gamma(1+1)/(1+K))*special.hyp1f1(-1,1,-K)*omega\n",
    "    var_chi = (special.gamma(1+2)/(1+K)**2)*special.hyp1f1(-2,1,-K)*omega**2 - E_chi**2\n",
    "    E_SNR = E_phi * E_chi / noise # Theoretical mean of SINR\n",
    "    var_SNR = ((var_phi+E_phi**2)*(var_chi+E_chi**2) - E_phi**2 * E_chi**2) / noise**2\n",
    "    std_dev_SNR = math.sqrt(var_SNR)\n",
    "    # sigma_ln = math.sqrt(math.log(var_SNR/E_SNR**2 + 1))\n",
    "    # mu_ln = math.log(E_SNR) - sigma_ln**2/2\n",
    "    return E_SNR, std_dev_SNR\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile FANET dataset from processed CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Date: 18/04/2023\n",
    "# Modified for new traffic model\n",
    "# num_UAVs = 8\n",
    "# processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_64QAM_65Mbps_Hovering_NoVideo/{}UAVs_Exp1_processed\".format(num_UAVs)\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Incorrectly_Received\", \"Queue_Overflow\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    ul_df_list.append(df.to_pandas())\n",
    "ul_df = pd.concat(ul_df_list, ignore_index=True)\n",
    "# ul_df[\"Packet_State\"] = ul_df[\"Packet_State\"].astype('object')\n",
    "# ul_df.to_hdf(processed_data_path + \"_uplink.h5\", key='{}_UAVs'.format(num_UAVs), format='table')\n",
    "ul_df.to_csv(processed_data_path + \"_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Incorrectly_Received\", \"Queue_Overflow\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    dl_df_list.append(df.to_pandas())\n",
    "dl_df = pd.concat(dl_df_list, ignore_index=True)\n",
    "# dl_df[\"Packet_State\"] = dl_df[\"Packet_State\"].astype('object')\n",
    "# dl_df.to_hdf(processed_data_path + \"_downlink.h5\", key='{}_UAVs'.format(num_UAVs), format='table')\n",
    "dl_df.to_csv(processed_data_path + \"_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train and \"Hold Out\" (No Video Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 07/06/2023\n",
    "# Split the training dataset into train and hold out, useful for calibration. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "HOLDOUT_SPLIT = 0.2\n",
    "MAX_NUM_PACKETS = 100000 # The maximum number of packets from each scenario\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/BPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "ul_df_hold_out_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > MAX_NUM_PACKETS:\n",
    "        df = df.head(MAX_NUM_PACKETS)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    ul_df_train_list.append(df_train.to_pandas())\n",
    "    ul_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_train_uplink.csv\")\n",
    "ul_df_hold_out = pd.concat(ul_df_hold_out_list, ignore_index=True)\n",
    "ul_df_hold_out.to_csv(processed_data_path + \"_holdout_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > MAX_NUM_PACKETS:\n",
    "        df = df.head(MAX_NUM_PACKETS)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    dl_df_train_list.append(df_train.to_pandas())\n",
    "    dl_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_train_downlink.csv\")\n",
    "dl_df_hold_out = pd.concat(dl_df_hold_out_list, ignore_index=True)\n",
    "dl_df_hold_out.to_csv(processed_data_path + \"_holdout_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train and \"Hold Out\" (Video Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 07/06/2023\n",
    "# Split the training dataset into train and hold out, useful for calibration. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "HOLDOUT_SPLIT = 0.2\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/BPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "ul_df_hold_out_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    ul_df_train_list.append(df_train.to_pandas())\n",
    "    ul_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_train_uplink.csv\")\n",
    "ul_df_hold_out = pd.concat(ul_df_hold_out_list, ignore_index=True)\n",
    "ul_df_hold_out.to_csv(processed_data_path + \"_holdout_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    dl_df_train_list.append(df_train.to_pandas())\n",
    "    dl_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_train_downlink.csv\")\n",
    "dl_df_hold_out = pd.concat(dl_df_hold_out_list, ignore_index=True)\n",
    "dl_df_hold_out.to_csv(processed_data_path + \"_holdout_downlink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "video_df_train_list = []\n",
    "video_df_hold_out_list = []\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    video_df_train_list.append(df_train.to_pandas())\n",
    "    video_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "video_df_train = pd.concat(video_df_train_list, ignore_index=True)\n",
    "video_df_train.to_csv(processed_data_path + \"_train_video.csv\")\n",
    "video_df_hold_out = pd.concat(video_df_hold_out_list, ignore_index=True)\n",
    "video_df_hold_out.to_csv(processed_data_path + \"_holdout_video.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Reliability Results for each Taguchi Hovering Test Cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/BPSK_Range_Test_processed\" \n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/\"\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "    # u2g_dist = df[\"U2G_Distance\"].mean()\n",
    "    height = df[\"Height\"].values[0]\n",
    "    num_members = df[\"Num_Members\"].values[0]\n",
    "    sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    # packet_size = df[\"Bytes\"].mean()\n",
    "    # u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "    incr_rcvd_probs = np.zeros(8).tolist()\n",
    "    for i in range(8):\n",
    "        if (i in incr_rcvd_counts):\n",
    "            incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "    num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval,\n",
    "                 \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                 \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                 \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "save_filename = \"BPSK_Range_Test_downlink\"\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/64QAM_Range_Test_processed\" \n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/\"\n",
    "# Process and save downlink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_Distance', 'Height', \"Num_Members\", \"UAV_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "    u2g_dist = df[\"U2G_Distance\"].mean()\n",
    "    height = df[\"Height\"].values[0]\n",
    "    num_members = df[\"Num_Members\"].values[0]\n",
    "    sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    # packet_size = df[\"Bytes\"].mean()\n",
    "    u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "    incr_rcvd_probs = np.zeros(8).tolist()\n",
    "    for i in range(8):\n",
    "        if (i in incr_rcvd_counts):\n",
    "            incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "    num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval,\n",
    "                 \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                 \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                 \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "save_filename = \"64QAM_Range_Test_uplink\"\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"{}.csv\".format(save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_df.to_csv(save_path + \"Hovering_Train_partial_Dataset_NP10000_64QAM_65Mbps_downlink.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Reliability Results for each Taguchi Test Cases v2 (with different modulations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (Multiple Folders for Different Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_paths = [\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/BPSK_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QPSK_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QAM16_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QAM64_Test\"]\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "for processed_data_path in processed_data_paths:\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in processed_data_path:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in processed_data_path:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM16\" in processed_data_path:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM64\" in processed_data_path:\n",
    "        modulation = \"QAM64\"\n",
    "\n",
    "    uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "    for csv_file in tqdm(uplink_csvs):\n",
    "        df = pd.read_csv(csv_file, \n",
    "                        usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "        df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "        u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "        height = df[\"Height\"].values[0]\n",
    "        uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "        throughput = df[\"Throughput\"].mean()\n",
    "        num_packets = len(df)\n",
    "        num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "        num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "        num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "        num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "        reliability = num_reliable / num_packets\n",
    "        incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "        queue_overflow_prob = num_queue_overflow / num_packets\n",
    "        delay_excd_prob = num_delay_excd / num_packets\n",
    "        test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                    \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "        ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_100000_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_100000_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_100000_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_100000_Downlink\"\n",
    "dl_df_list = []\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_Video\"\n",
    "vid_df_list = []\n",
    "# Process and save uplink DF \n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    vid_df_list.append(test_case)\n",
    "vid_df = pd.DataFrame(vid_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "vid_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (Case Studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Case_Studies_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo\"\n",
    "save_filename = \"Case_Studies_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Throughput Dataset from Processed CSV Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 03/07/2023\n",
    "# Compile the throughput training dataset, using only unique rows. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/BPSK_processed\"\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    ul_df_train_list.append(df.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_throughput_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    dl_df_train_list.append(df.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_throughput_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Video (From processed CSV files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 03/07/2023\n",
    "# Compile the throughput training dataset, using only unique rows. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/QAM64_processed\"\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    ul_df_train_list.append(df.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_throughput_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    dl_df_train_list.append(df.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_throughput_downlink.csv\")\n",
    "\n",
    "# Process and save video DF\n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "vid_df_train_list = []\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    vid_df_train_list.append(df.to_pandas())\n",
    "vid_df_train = pd.concat(vid_df_train_list, ignore_index=True)\n",
    "vid_df_train.to_csv(processed_data_path + \"_throughput_video.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine individual case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 0.04\n",
    "csv_file = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_64QAM_65Mbps_Hovering/8UAVs_processed/NumMember-7_InterUAVDistance-5_Height-24_Distance-625_PacketSize-920_SendingRate-808_downlink.csv\"\n",
    "df = pd.read_csv(csv_file, \n",
    "                usecols = ['U2G_Distance', 'Height', \"Num_Members\", \"Mean_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "df[\"U2G_Distance\"].fillna(method=\"bfill\", inplace=True) \n",
    "u2g_dist = df[\"U2G_Distance\"].values[0]\n",
    "height = df[\"Height\"].values[0]\n",
    "num_members = df[\"Num_Members\"].values[0]\n",
    "sending_interval = df[\"Mean_Sending_Interval\"].values[0]\n",
    "packet_size = df[\"Bytes\"].values[0]\n",
    "u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "num_packets = len(df)\n",
    "num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "reliability = num_reliable / num_packets\n",
    "incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "incr_rcvd_probs = np.zeros(8).tolist()\n",
    "for i in range(8):\n",
    "    if (i in incr_rcvd_counts):\n",
    "        incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "delay_excd_prob = num_delay_excd / num_packets\n",
    "num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "queue_overflow_prob = num_queue_overflow / num_packets\n",
    "test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval, \"Packet_Size\": packet_size,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare No. of Packets for Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "NUM_PACKETS = 100000\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Test_Dataset_1_uplink_{}_packets\".format(NUM_PACKETS)\n",
    "dl_df_list = []\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    if len(df.index) > NUM_PACKETS:\n",
    "        df = df.head(NUM_PACKETS)\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_100000 = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_uplink_100000_packets.csv\")\n",
    "test_df_10000 = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_uplink_50000_packets.csv\")\n",
    "\n",
    "abs_err_rel = abs(test_df_100000[\"Reliability\"] - test_df_10000[\"Reliability\"])\n",
    "max_abs_err_rel = max(abs_err_rel)\n",
    "idx_max_abs_err_rel = abs_err_rel.idxmax()\n",
    "abs_err_incr_rcvd = abs(test_df_100000[\"Incorrectly_Rcvd_Prob\"] - test_df_10000[\"Incorrectly_Rcvd_Prob\"])\n",
    "max_abs_err_incr_rcvd = max(abs_err_incr_rcvd)\n",
    "idx_max_abs_err_incr_rcvd = abs_err_incr_rcvd.idxmax()\n",
    "abs_err_queue_overflow = abs(test_df_100000[\"Queue_Overflow_Prob\"] - test_df_10000[\"Queue_Overflow_Prob\"])\n",
    "max_abs_err_queue_overflow = max(abs_err_queue_overflow)\n",
    "idx_max_abs_err_queue_overflow = abs_err_queue_overflow.idxmax()\n",
    "abs_err_delay_excd = abs(test_df_100000[\"Delay_Excd_Prob\"] - test_df_10000[\"Delay_Excd_Prob\"])\n",
    "max_abs_err_delay_excd = max(abs_err_delay_excd)\n",
    "idx_max_abs_err_delay_excd = abs_err_delay_excd.idxmax()\n",
    "\n",
    "print(max_abs_err_rel)\n",
    "print(max_abs_err_incr_rcvd)\n",
    "print(max_abs_err_queue_overflow)\n",
    "print(max_abs_err_delay_excd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_troughput_train_holdout_dataset(dataset_details_csv, holdout_split=0.2):\n",
    "    df_dtypes = {\"Horizontal_Distance\": np.float32, \"Height\": np.int16,\t\"U2G_Distance\": np.int32, \"UAV_Sending_Interval\": np.int16, \"Mean_SINR\": np.float32, \"Std_Dev_SINR\": np.float32,\n",
    "                 \"Modulation\": 'string', \"Num_Sent\": np.int32, \"Num_Reliable\": np.int32, \"Num_Delay_Excd\": np.int32, \"Num_Incr_Rcvd\": np.int32, \"Num_Q_Overflow\": np.int32}\n",
    "    dataset_details = pd.read_csv(dataset_details_csv, \n",
    "                                  usecols = [\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\", \"Throughput\", \"Num_Count\"],\n",
    "                                  dtype=df_dtypes)\n",
    "    \n",
    "    # For each scenario, get the throughput data and split it to train and holdout \n",
    "    scenarios = dataset_details[['Mean_SINR','Std_Dev_SINR','Modulation','UAV_Sending_Interval']].drop_duplicates()\n",
    "    df_train_list = []\n",
    "    df_holdout_list = []\n",
    "    for scenario in tqdm(scenarios.itertuples()):\n",
    "        scenario_df = dataset_details.loc[(dataset_details[\"Modulation\"] == scenario.Modulation) & (dataset_details[\"UAV_Sending_Interval\"] == scenario.UAV_Sending_Interval) & \n",
    "                          (dataset_details[\"Mean_SINR\"] == scenario.Mean_SINR) & (dataset_details[\"Std_Dev_SINR\"] == scenario.Std_Dev_SINR)]\n",
    "        df_list = []\n",
    "        for row in scenario_df.itertuples():\n",
    "            throughput_data = {\"Mean_SINR\": row.Mean_SINR, \"Std_Dev_SINR\": row.Std_Dev_SINR, \"UAV_Sending_Interval\": row.UAV_Sending_Interval, \"Modulation\": row.Modulation, \"Throughput\": row.Throughput}\n",
    "            # If Num_Count is one, just append the row to df_list\n",
    "            if row.Num_Count == 1:\n",
    "                df_list.append(throughput_data)\n",
    "            else:\n",
    "                df_list = df_list + [throughput_data.copy() for i in range(row.Num_Count)]\n",
    "        df = pd.DataFrame(df_list)\n",
    "        train, holdout = train_test_split(df, test_size=holdout_split, random_state=40, shuffle=True)\n",
    "        df_train_list.append(train)\n",
    "        df_holdout_list.append(holdout)\n",
    "    df_train = pd.concat(df_train_list)\n",
    "    df_holdout = pd.concat(df_holdout_list)\n",
    "    return df_train, df_holdout\n",
    "\n",
    "df_train, df_holdout = generate_troughput_train_holdout_dataset(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Throughput.csv\",\n",
    "                                                                holdout_split=0.2)\n",
    "df_train.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Throughput_train.csv\")\n",
    "df_holdout.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Throughput_holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reliability_train_holdout_dataset(dataset_details_csv, holdout_split=0.2):\n",
    "    df_dtypes = {\"Horizontal_Distance\": np.float32, \"Height\": np.int16,\t\"U2G_Distance\": np.int32, \"UAV_Sending_Interval\": np.int16, \"Mean_SINR\": np.float32, \"Std_Dev_SINR\": np.float32,\n",
    "                 \"Modulation\": 'string', \"Num_Sent\": np.int32, \"Num_Reliable\": np.int32, \"Num_Delay_Excd\": np.int32, \"Num_Incr_Rcvd\": np.int32, \"Num_Q_Overflow\": np.int32}\n",
    "    dataset_details = pd.read_csv(dataset_details_csv, \n",
    "                                  usecols = [\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\", \"Num_Sent\", \"Num_Reliable\", \"Num_Delay_Excd\",\n",
    "                                             \"Num_Incr_Rcvd\", \"Num_Q_Overflow\"],\n",
    "                                  dtype=df_dtypes)\n",
    "    df_train_list = []\n",
    "    df_holdout_list= []\n",
    "    for row in tqdm(dataset_details.itertuples()):\n",
    "        mean_sinr = row.Mean_SINR\n",
    "        std_dev_sinr = row.Std_Dev_SINR\n",
    "        uav_send_int = row.UAV_Sending_Interval\n",
    "        modulation = row.Modulation\n",
    "        num_reliable = row.Num_Reliable\n",
    "        num_delay_excd = row.Num_Delay_Excd\n",
    "        num_incr_rcvd = row.Num_Incr_Rcvd\n",
    "        num_q_overflow = row.Num_Q_Overflow\n",
    "        reliable_packets = {\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Reliable\"}\n",
    "        delay_excd_packets = {\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Delay_Exceeded\"}\n",
    "        q_overflow_packets = {\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"QUEUE_OVERFLOW\"}\n",
    "        incr_rcvd_packets = {\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"RETRY_LIMIT_REACHED\"}\n",
    "        df_train_list = df_train_list + [reliable_packets.copy() for i in range(math.ceil(num_reliable*(1-holdout_split)))]\n",
    "        df_holdout_list = df_holdout_list + [reliable_packets.copy() for i in range(math.floor(num_reliable*(holdout_split)))]\n",
    "        df_train_list = df_train_list + [delay_excd_packets.copy() for i in range(math.ceil(num_delay_excd*(1-holdout_split)))]\n",
    "        df_holdout_list = df_holdout_list + [delay_excd_packets.copy() for i in range(math.floor(num_delay_excd*(holdout_split)))]\n",
    "        df_train_list = df_train_list + [incr_rcvd_packets.copy() for i in range(math.ceil(num_incr_rcvd*(1-holdout_split)))]\n",
    "        df_holdout_list = df_holdout_list + [incr_rcvd_packets.copy() for i in range(math.floor(num_incr_rcvd*(holdout_split)))]\n",
    "        df_train_list = df_train_list + [q_overflow_packets.copy() for i in range(math.ceil(num_q_overflow*(1-holdout_split)))]\n",
    "        df_holdout_list = df_holdout_list + [q_overflow_packets.copy() for i in range(math.floor(num_q_overflow*(holdout_split)))]\n",
    "\n",
    "    df_train = pd.DataFrame(df_train_list)\n",
    "    df_holdout = pd.DataFrame(df_holdout_list)\n",
    "    return df_train, df_holdout\n",
    "\n",
    "df_train, df_holdout = generate_reliability_train_holdout_dataset(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability.csv\",\n",
    "                                                                holdout_split=0.2)\n",
    "df_train.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability_train.csv\")\n",
    "df_holdout.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability_holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "960it [00:13, 70.66it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_reliability_train_holdout_dataset(dataset_details_csv, holdout_split=0.2):\n",
    "    df_dtypes = {\"Horizontal_Distance\": np.float32, \"Height\": np.int16,\t\"U2G_Distance\": np.int32, \"UAV_Sending_Interval\": np.int16, \"Mean_SINR\": np.float32, \"Std_Dev_SINR\": np.float32,\n",
    "                 \"Modulation\": 'string', \"Num_Sent\": np.int32, \"Num_Reliable\": np.int32, \"Num_Delay_Excd\": np.int32, \"Num_Incr_Rcvd\": np.int32, \"Num_Q_Overflow\": np.int32}\n",
    "    dataset_details = pd.read_csv(dataset_details_csv, \n",
    "                                  usecols = [\"Mean_SINR\", \"Std_Dev_SINR\", \"UAV_Sending_Interval\", \"Modulation\", \"Num_Sent\", \"Num_Reliable\", \"Num_Delay_Excd\",\n",
    "                                             \"Num_Incr_Rcvd\", \"Num_Q_Overflow\"],\n",
    "                                  dtype=df_dtypes)\n",
    "    df_train_list = []\n",
    "    df_holdout_list = []\n",
    "    for row in tqdm(dataset_details.itertuples()):\n",
    "        mean_sinr = row.Mean_SINR\n",
    "        std_dev_sinr = row.Std_Dev_SINR\n",
    "        uav_send_int = row.UAV_Sending_Interval\n",
    "        modulation = row.Modulation\n",
    "        num_reliable = row.Num_Reliable\n",
    "        num_delay_excd = row.Num_Delay_Excd\n",
    "        num_incr_rcvd = row.Num_Incr_Rcvd\n",
    "        num_q_overflow = row.Num_Q_Overflow\n",
    "\n",
    "        if num_reliable > 1:\n",
    "            reliable_packets = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Reliable\"}, index=[0])\n",
    "            reliable_packets = reliable_packets.loc[reliable_packets.index.repeat(num_reliable)]\n",
    "            reliable_packets_train, reliable_packets_holdout = train_test_split(reliable_packets, test_size=holdout_split, random_state=40, shuffle=False)\n",
    "        elif num_reliable == 1:\n",
    "            reliable_packets_train = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Reliable\"}, index=[0])\n",
    "            reliable_packets_holdout = pd.DataFrame({})\n",
    "        else:\n",
    "            reliable_packets_train = pd.DataFrame({})\n",
    "            reliable_packets_holdout = pd.DataFrame({})\n",
    "\n",
    "        if num_delay_excd > 1:\n",
    "            delay_excd_packets = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Delay_Exceeded\"}, index=[0])\n",
    "            delay_excd_packets = delay_excd_packets.loc[delay_excd_packets.index.repeat(num_delay_excd)]\n",
    "            delay_excd_packets_train, delay_excd_packets_holdout = train_test_split(delay_excd_packets, test_size=holdout_split, random_state=40, shuffle=False)\n",
    "        elif num_delay_excd == 1:\n",
    "            delay_excd_packets_train = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"Delay_Exceeded\"}, index=[0])\n",
    "            delay_excd_packets_holdout = pd.DataFrame({})\n",
    "        else:\n",
    "            delay_excd_packets_train = pd.DataFrame({})\n",
    "            delay_excd_packets_holdout = pd.DataFrame({})\n",
    "\n",
    "        if num_q_overflow > 1:\n",
    "            q_overflow_packets = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"QUEUE_OVERFLOW\"}, index=[0])\n",
    "            q_overflow_packets = q_overflow_packets.loc[q_overflow_packets.index.repeat(num_q_overflow)]\n",
    "            q_overflow_packets_train, q_overflow_packets_holdout = train_test_split(q_overflow_packets, test_size=holdout_split, random_state=40, shuffle=False)\n",
    "        elif num_q_overflow == 1:\n",
    "            q_overflow_packets_train = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"QUEUE_OVERFLOW\"}, index=[0])\n",
    "            q_overflow_packets_holdout = pd.DataFrame({})\n",
    "        else:\n",
    "            q_overflow_packets_train = pd.DataFrame({})\n",
    "            q_overflow_packets_holdout = pd.DataFrame({})\n",
    "\n",
    "        if num_incr_rcvd > 1:\n",
    "            incr_rcvd_packets = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"RETRY_LIMIT_REACHED\"}, index=[0])\n",
    "            incr_rcvd_packets = incr_rcvd_packets.loc[incr_rcvd_packets.index.repeat(num_incr_rcvd)]\n",
    "            incr_rcvd_packets_train, incr_rcvd_packets_holdout = train_test_split(incr_rcvd_packets, test_size=holdout_split, random_state=40, shuffle=False)\n",
    "        elif num_incr_rcvd == 1:\n",
    "            incr_rcvd_packets_train = pd.DataFrame({\"Mean_SINR\": mean_sinr, \"Std_Dev_SINR\": std_dev_sinr, \"UAV_Sending_Interval\": uav_send_int, \"Modulation\": modulation, \"Packet_State\": \"RETRY_LIMIT_REACHED\"}, index=[0])\n",
    "            incr_rcvd_packets_holdout = pd.DataFrame({})\n",
    "        else:\n",
    "            incr_rcvd_packets_train = pd.DataFrame({})\n",
    "            incr_rcvd_packets_holdout = pd.DataFrame({})\n",
    "        df_train_list.append(pd.concat([reliable_packets_train, delay_excd_packets_train, q_overflow_packets_train, incr_rcvd_packets_train]))\n",
    "        df_holdout_list.append(pd.concat([reliable_packets_holdout, delay_excd_packets_holdout, q_overflow_packets_holdout, incr_rcvd_packets_holdout]))\n",
    "\n",
    "    df_train = pd.concat(df_train_list)\n",
    "    df_holdout = pd.concat(df_holdout_list)\n",
    "    return df_train, df_holdout\n",
    "\n",
    "df_train, df_holdout = generate_reliability_train_holdout_dataset(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability.csv\",\n",
    "                                                                holdout_split=0.2)\n",
    "df_train.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability_train.csv\")\n",
    "df_holdout.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP100000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_Downlink_Reliability_holdout.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b91d162001b74e2486487353b6410b0f764056372f730fbe993a2ad06d40082"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
