{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import glob, math\n",
    "import cudf \n",
    "from tqdm import tqdm\n",
    "from scipy import special\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def h_dist_calc(row):\n",
    "    # Function to calc euclidean distance on every df row \n",
    "    h_dist = math.sqrt(row[\"U2G_Distance\"]**2 - row[\"Height\"]**2)\n",
    "    return h_dist\n",
    "\n",
    "def q_func(x):\n",
    "    q = 0.5 - 0.5*special.erf(x / np.sqrt(2))\n",
    "    return q\n",
    "\n",
    "def friis_calc(P,freq,dist,ple):\n",
    "    '''\n",
    "    Friis path loss equation\n",
    "    P = Tx transmit power\n",
    "    freq = Signal frequency\n",
    "    dist = Transmission distance\n",
    "    ple = Path loss exponent\n",
    "    '''\n",
    "    propagation_speed = 299792458\n",
    "    l = propagation_speed / freq\n",
    "    h_pl = P * l**2 / (16*math.pi**2)\n",
    "    P_Rx = h_pl * dist**(-ple)\n",
    "    return P_Rx\n",
    "\n",
    "def plos_calc(h_dist, height_tx, height_rx, env='suburban'):\n",
    "    '''\n",
    "    % This function implements the LoS probability model from the paper\n",
    "    % \"Blockage Modeling for Inter-layer UAVs Communications in Urban\n",
    "    % Environments\" \n",
    "    % param h_dist    : horizontal distance between Tx and Rx (m)\n",
    "    % param height_tx : height of Tx\n",
    "    % param height_rx : height of Rx\n",
    "    '''\n",
    "    if env == 'suburban':\n",
    "        a1 = 0.1\n",
    "        a2 = 7.5e-4\n",
    "        a3 = 8\n",
    "    \n",
    "    delta_h = height_tx - height_rx\n",
    "    # pow_factor = 2 * h_dist * math.sqrt(a1*a2/math.pi) + a1 # NOTE: Use this pow_factor if assuming PPP building dist.\n",
    "    pow_factor = h_dist * math.sqrt(a1*a2) # NOTE: Use this pow_factor if assuming ITU-R assumptions.\n",
    "    if delta_h == 0:\n",
    "        p = (1 - math.exp((-(height_tx)**2) / (2*a3**2))) ** pow_factor\n",
    "    else:\n",
    "        if delta_h < 0:\n",
    "            h1 = height_rx\n",
    "            h2 = height_tx\n",
    "        else:\n",
    "            h1 = height_tx\n",
    "            h2 = height_rx\n",
    "        delta_h = abs(delta_h)\n",
    "        p = (1 - (math.sqrt(2*math.pi)*a3 / delta_h) * abs(q_func(h1/a3) - q_func(h2/a3))) ** pow_factor\n",
    "    return p\n",
    "\n",
    "def sinr_lognormal_approx(h_dist, height, env='suburban'):\n",
    "    '''\n",
    "    To approximate the SNR from signal considering multipath fading and shadowing\n",
    "    Assuming no interference due to CSMA, and fixed noise\n",
    "    Inputs:\n",
    "    h_dist = Horizontal Distance between Tx and Rx\n",
    "    height = Height difference between Tx and Rx\n",
    "    env = The operating environment (currently only suburban supported)\n",
    "    '''\n",
    "    # Signal properties\n",
    "    P_Tx_dBm = 20 # Transmit power of \n",
    "    P_Tx = 10**(P_Tx_dBm/10) / 1000\n",
    "    freq = 2.4e9 # Channel frequency (Hz)\n",
    "    noise_dBm = -86\n",
    "    noise = 10**(noise_dBm/10) / 1000\n",
    "    if env == \"suburban\":\n",
    "        # ENV Parameters Constants ----------------------------------\n",
    "        # n_min = 2\n",
    "        # n_max = 2.75\n",
    "        # K_dB_min = 7.8\n",
    "        # K_dB_max = 17.5\n",
    "        # K_min = 10**(K_dB_min/10)\n",
    "        # K_max = 10**(K_dB_max/10)\n",
    "        # alpha = 11.25 # Env parameters for logarithm std dev of shadowing \n",
    "        # beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        n_min = 2\n",
    "        n_max = 2.75\n",
    "        K_dB_min = 1.4922\n",
    "        K_dB_max = 12.2272\n",
    "        K_min = 10**(K_dB_min/10)\n",
    "        K_max = 10**(K_dB_max/10)\n",
    "        alpha = 11.1852 # Env parameters for logarithm std dev of shadowing \n",
    "        beta = 0.06 # Env parameters for logarithm std dev of shadowing \n",
    "        # -----------------------------------------------------------\n",
    "    # Calculate fading parameters\n",
    "    PLoS = plos_calc(h_dist, 0, height, env='suburban')\n",
    "    theta_Rx = math.atan2(height, h_dist) * 180 / math.pi # Elevation angle in degrees\n",
    "    ple = (n_min - n_max) * PLoS + n_max # Path loss exponent\n",
    "    sigma_phi_dB = alpha*math.exp(-beta*theta_Rx)\n",
    "    sigma_phi = 10**(sigma_phi_dB/10) # Logarithmic std dev of shadowing\n",
    "    K = K_min * math.exp(math.log(K_max/K_min) * PLoS**2)\n",
    "    omega = 1 # Omega of NCS (Rician)\n",
    "    dist = math.sqrt(h_dist**2 + height**2)\n",
    "    P_Rx = friis_calc(P_Tx, freq, dist, ple)\n",
    "    # Approximate L-NCS RV (which is the SNR) as lognormal\n",
    "    eta = math.log(10) / 10\n",
    "    mu_phi = 10*math.log10(P_Rx)\n",
    "    E_phi = math.exp(eta*mu_phi + eta**2*sigma_phi**2/2) # Mean of shadowing RV\n",
    "    var_phi = math.exp(2*eta*mu_phi+eta**2*sigma_phi**2)*(math.exp(eta**2*sigma_phi**2)-1) # Variance of shadowing RV\n",
    "    E_chi = (special.gamma(1+1)/(1+K))*special.hyp1f1(-1,1,-K)*omega\n",
    "    var_chi = (special.gamma(1+2)/(1+K)**2)*special.hyp1f1(-2,1,-K)*omega**2 - E_chi**2\n",
    "    E_SNR = E_phi * E_chi / noise # Theoretical mean of SINR\n",
    "    var_SNR = ((var_phi+E_phi**2)*(var_chi+E_chi**2) - E_phi**2 * E_chi**2) / noise**2\n",
    "    std_dev_SNR = math.sqrt(var_SNR)\n",
    "    # sigma_ln = math.sqrt(math.log(var_SNR/E_SNR**2 + 1))\n",
    "    # mu_ln = math.log(E_SNR) - sigma_ln**2/2\n",
    "    return E_SNR, std_dev_SNR\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile FANET dataset from processed CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:27<00:00, 40.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Modified Date: 18/04/2023\n",
    "# Modified for new traffic model\n",
    "# num_UAVs = 8\n",
    "# processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_64QAM_65Mbps_Hovering_NoVideo/{}UAVs_Exp1_processed\".format(num_UAVs)\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Incorrectly_Received\", \"Queue_Overflow\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    ul_df_list.append(df.to_pandas())\n",
    "ul_df = pd.concat(ul_df_list, ignore_index=True)\n",
    "# ul_df[\"Packet_State\"] = ul_df[\"Packet_State\"].astype('object')\n",
    "# ul_df.to_hdf(processed_data_path + \"_uplink.h5\", key='{}_UAVs'.format(num_UAVs), format='table')\n",
    "ul_df.to_csv(processed_data_path + \"_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Incorrectly_Received\", \"Queue_Overflow\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    dl_df_list.append(df.to_pandas())\n",
    "dl_df = pd.concat(dl_df_list, ignore_index=True)\n",
    "# dl_df[\"Packet_State\"] = dl_df[\"Packet_State\"].astype('object')\n",
    "# dl_df.to_hdf(processed_data_path + \"_downlink.h5\", key='{}_UAVs'.format(num_UAVs), format='table')\n",
    "dl_df.to_csv(processed_data_path + \"_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train and \"Hold Out\" (No Video Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2745/2745 [03:03<00:00, 14.94it/s]\n",
      "100%|██████████| 2745/2745 [11:06<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Date: 07/06/2023\n",
    "# Split the training dataset into train and hold out, useful for calibration. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "HOLDOUT_SPLIT = 0.2\n",
    "MAX_NUM_PACKETS = 100000 # The maximum number of packets from each scenario\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "ul_df_hold_out_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > MAX_NUM_PACKETS:\n",
    "        df = df.head(MAX_NUM_PACKETS)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    ul_df_train_list.append(df_train.to_pandas())\n",
    "    ul_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_train_uplink.csv\")\n",
    "ul_df_hold_out = pd.concat(ul_df_hold_out_list, ignore_index=True)\n",
    "ul_df_hold_out.to_csv(processed_data_path + \"_holdout_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > MAX_NUM_PACKETS:\n",
    "        df = df.head(MAX_NUM_PACKETS)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    dl_df_train_list.append(df_train.to_pandas())\n",
    "    dl_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_train_downlink.csv\")\n",
    "dl_df_hold_out = pd.concat(dl_df_hold_out_list, ignore_index=True)\n",
    "dl_df_hold_out.to_csv(processed_data_path + \"_holdout_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train and \"Hold Out\" (Video Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2745/2745 [08:26<00:00,  5.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Date: 07/06/2023\n",
    "# Split the training dataset into train and hold out, useful for calibration. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "HOLDOUT_SPLIT = 0.2\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/BPSK_processed\"\n",
    "# pkt_state_cat = cudf.CategoricalDtype(categories=['Reliable', 'Delay_Exceeded', 'RETRY_LIMIT_REACHED', 'QUEUE_OVERFLOW', 'FAILED', 'INTERFACE_DOWN'])\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "ul_df_hold_out_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    ul_df_train_list.append(df_train.to_pandas())\n",
    "    ul_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_train_uplink.csv\")\n",
    "ul_df_hold_out = pd.concat(ul_df_hold_out_list, ignore_index=True)\n",
    "ul_df_hold_out.to_csv(processed_data_path + \"_holdout_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    dl_df_train_list.append(df_train.to_pandas())\n",
    "    dl_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_train_downlink.csv\")\n",
    "dl_df_hold_out = pd.concat(dl_df_hold_out_list, ignore_index=True)\n",
    "dl_df_hold_out.to_csv(processed_data_path + \"_holdout_downlink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "video_df_train_list = []\n",
    "video_df_hold_out_list = []\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['Packet_Name','U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\", \"Bytes\", \"U2G_SINR\", \"U2G_BER\", \n",
    "                               \"Delay\", \"Throughput\", \"Packet_State\", \"Retry_Count\", \"Mean_SINR\", \"Std_Dev_SINR\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's cap the number of rows for each scenario at 100,000 packets for DL\n",
    "    if len(df.index) > 100000:\n",
    "        df = df.head(100000)\n",
    "    df_train, df_hold_out = train_test_split(df, test_size=HOLDOUT_SPLIT, random_state=40, shuffle=False)\n",
    "    video_df_train_list.append(df_train.to_pandas())\n",
    "    video_df_hold_out_list.append(df_hold_out.to_pandas())\n",
    "video_df_train = pd.concat(video_df_train_list, ignore_index=True)\n",
    "video_df_train.to_csv(processed_data_path + \"_train_video.csv\")\n",
    "video_df_hold_out = pd.concat(video_df_hold_out_list, ignore_index=True)\n",
    "video_df_hold_out.to_csv(processed_data_path + \"_holdout_video.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Reliability Results for each Taguchi Hovering Test Cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:19<00:00, 20.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/BPSK_Range_Test_processed\" \n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/\"\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"Num_Members\", \"UAV_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "    # u2g_dist = df[\"U2G_Distance\"].mean()\n",
    "    height = df[\"Height\"].values[0]\n",
    "    num_members = df[\"Num_Members\"].values[0]\n",
    "    sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    # packet_size = df[\"Bytes\"].mean()\n",
    "    # u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "    incr_rcvd_probs = np.zeros(8).tolist()\n",
    "    for i in range(8):\n",
    "        if (i in incr_rcvd_counts):\n",
    "            incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "    num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval,\n",
    "                 \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                 \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                 \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "save_filename = \"BPSK_Range_Test_downlink\"\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:09<00:00, 32.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/64QAM_Range_Test_processed\" \n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/\"\n",
    "# Process and save downlink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_Distance', 'Height', \"Num_Members\", \"UAV_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "    u2g_dist = df[\"U2G_Distance\"].mean()\n",
    "    height = df[\"Height\"].values[0]\n",
    "    num_members = df[\"Num_Members\"].values[0]\n",
    "    sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    # packet_size = df[\"Bytes\"].mean()\n",
    "    u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "    incr_rcvd_probs = np.zeros(8).tolist()\n",
    "    for i in range(8):\n",
    "        if (i in incr_rcvd_counts):\n",
    "            incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "    num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval,\n",
    "                 \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                 \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                 \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "save_filename = \"64QAM_Range_Test_uplink\"\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"{}.csv\".format(save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_df.to_csv(save_path + \"Hovering_Train_partial_Dataset_NP10000_64QAM_65Mbps_downlink.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Reliability Results for each Taguchi Test Cases v2 (with different modulations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (Multiple Folders for Different Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 43.22it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 43.41it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 43.77it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 45.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_paths = [\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/BPSK_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QPSK_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QAM16_Test\",\n",
    "                        \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/QAM64_Test\"]\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "for processed_data_path in processed_data_paths:\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in processed_data_path:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in processed_data_path:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM16\" in processed_data_path:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM64\" in processed_data_path:\n",
    "        modulation = \"QAM64\"\n",
    "\n",
    "    uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "    for csv_file in tqdm(uplink_csvs):\n",
    "        df = pd.read_csv(csv_file, \n",
    "                        usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "        df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "        u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "        height = df[\"Height\"].values[0]\n",
    "        uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "        throughput = df[\"Throughput\"].mean()\n",
    "        num_packets = len(df)\n",
    "        num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "        num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "        num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "        num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "        reliability = num_reliable / num_packets\n",
    "        incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "        queue_overflow_prob = num_queue_overflow / num_packets\n",
    "        delay_excd_prob = num_delay_excd / num_packets\n",
    "        test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                    \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "        ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research-student/anaconda3/envs/rapids-22.12/lib/python3.8/site-packages/cudf/utils/utils.py:217: FutureWarning: The cudf.set_allocator function is deprecated and will be removed in a future release. Please use rmm.reinitialize (https://docs.rapids.ai/api/rmm/stable/api.html#rmm.reinitialize) instead. Note that `cudf.set_allocator(allocator=\"managed\")` is equivalent to `rmm.reinitialize(managed_memory=True)`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 53/53 [00:21<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_100000_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_100000_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:01<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_100000_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_100000_Downlink\"\n",
    "dl_df_list = []\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video (One folder for all Modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [05:46<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test/Test_Dataset_1_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/Test\"\n",
    "save_filename = \"Multi_Modulation_Test_Cases_1_Video\"\n",
    "vid_df_list = []\n",
    "# Process and save uplink DF \n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    vid_df_list.append(test_case)\n",
    "vid_df = pd.DataFrame(vid_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "vid_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uplink (Case Studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:28<00:00, 17.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 1\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Case_Studies_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo\"\n",
    "save_filename = \"Case_Studies_Uplink\"\n",
    "ul_df_list = []\n",
    "# Process and save uplink DF \n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = pd.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    ul_df_list.append(test_case)\n",
    "ul_df = pd.DataFrame(ul_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "ul_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Throughput Dataset from Processed CSV Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2745/2745 [01:27<00:00, 31.51it/s]\n",
      "100%|██████████| 2745/2745 [06:52<00:00,  6.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Date: 03/07/2023\n",
    "# Compile the throughput training dataset, using only unique rows. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/BPSK_processed\"\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    ul_df_train_list.append(df.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_throughput_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "dl_df_hold_out_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    dl_df_train_list.append(df.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_throughput_downlink.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Video (From processed CSV files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 03/07/2023\n",
    "# Compile the throughput training dataset, using only unique rows. IMPORTANT: We split the dataset for each scenario first before concatenating\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_Video/QAM64_processed\"\n",
    "df_dtypes = {\"TxTime\": np.float32, \"U2G_Distance\": np.float32, \"Height\": np.int16,\t\"Num_Members\": np.int16, \"UAV_Sending_Interval\": np.int16, \"Bytes\": np.int16, \n",
    "            \"U2G_SINR\": np.float32, \"U2G_BER\": np.float32, \"Delay\": np.float32, \"Throughput\": np.float32, \"Queueing_Time\": np.float32, \"Packet_State\": 'string', \n",
    "            \"Retry_Count\": np.int8, \"Incorrectly_Received\": np.int8, \"Queue_Overflow\": np.int8, \"Packet_Name\": 'string'}\n",
    "\n",
    "# Process and save uplink DF\n",
    "uplink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "ul_df_train_list = []\n",
    "for csv_file in tqdm(uplink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    ul_df_train_list.append(df.to_pandas())\n",
    "ul_df_train = pd.concat(ul_df_train_list, ignore_index=True)\n",
    "ul_df_train.to_csv(processed_data_path + \"_throughput_uplink.csv\")\n",
    "\n",
    "# Process and save downlink DF\n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_downlink.csv\")\n",
    "dl_df_train_list = []\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    dl_df_train_list.append(df.to_pandas())\n",
    "dl_df_train = pd.concat(dl_df_train_list, ignore_index=True)\n",
    "dl_df_train.to_csv(processed_data_path + \"_throughput_downlink.csv\")\n",
    "\n",
    "# Process and save video DF\n",
    "video_csvs = glob.glob(processed_data_path + \"/*_video.csv\")\n",
    "vid_df_train_list = []\n",
    "for csv_file in tqdm(video_csvs):\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = [\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"],\n",
    "                    dtype=df_dtypes)\n",
    "    # df[\"U2G_H_Dist\"] = df.apply(h_dist_calc, axis=1)\n",
    "    # df[['Mean_SINR',\"Std_Dev_SINR\"]]= df.apply(lambda row: sinr_lognormal_approx(row['U2G_H_Dist'],row['Height']),axis=1,result_type='expand')\n",
    "    # Filter out rows where mean / std dev of sinr is NaN\n",
    "    df = df[df['Mean_SINR'].notna()]\n",
    "    df = df[df['Std_Dev_SINR'].notna()]\n",
    "    # Let's remove duplicated throughput data rows\n",
    "    df.drop_duplicates(subset=[\"UAV_Sending_Interval\", \"Mean_SINR\", \"Std_Dev_SINR\", \"Throughput\"], inplace=True, ignore_index=True)\n",
    "    vid_df_train_list.append(df.to_pandas())\n",
    "vid_df_train = pd.concat(vid_df_train_list, ignore_index=True)\n",
    "vid_df_train.to_csv(processed_data_path + \"_throughput_video.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine individual case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay_threshold = 0.04\n",
    "csv_file = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_64QAM_65Mbps_Hovering/8UAVs_processed/NumMember-7_InterUAVDistance-5_Height-24_Distance-625_PacketSize-920_SendingRate-808_downlink.csv\"\n",
    "df = pd.read_csv(csv_file, \n",
    "                usecols = ['U2G_Distance', 'Height', \"Num_Members\", \"Mean_Sending_Interval\",\"Bytes\", \"Delay\", \"Packet_State\", \"Incorrectly_Received\", \"Queue_Overflow\"])\n",
    "df[\"U2G_Distance\"].fillna(method=\"bfill\", inplace=True) \n",
    "u2g_dist = df[\"U2G_Distance\"].values[0]\n",
    "height = df[\"Height\"].values[0]\n",
    "num_members = df[\"Num_Members\"].values[0]\n",
    "sending_interval = df[\"Mean_Sending_Interval\"].values[0]\n",
    "packet_size = df[\"Bytes\"].values[0]\n",
    "u2g_h_dist = math.sqrt(u2g_dist**2 - height**2)\n",
    "num_packets = len(df)\n",
    "num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "reliability = num_reliable / num_packets\n",
    "incr_rcvd_counts = df['Incorrectly_Received'].value_counts()\n",
    "incr_rcvd_probs = np.zeros(8).tolist()\n",
    "for i in range(8):\n",
    "    if (i in incr_rcvd_counts):\n",
    "        incr_rcvd_probs[i] = incr_rcvd_counts[i]/num_packets\n",
    "num_delay_excd = len(df.loc[df[\"Delay\"] > delay_threshold])\n",
    "delay_excd_prob = num_delay_excd / num_packets\n",
    "num_queue_overflow = len(df.loc[df[\"Queue_Overflow\"] > 0])\n",
    "queue_overflow_prob = num_queue_overflow / num_packets\n",
    "test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Num_Members\": num_members, \"Sending_Interval\": sending_interval, \"Packet_Size\": packet_size,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob,\n",
    "                \"0_Incr_Rcvd\": incr_rcvd_probs[0], \"1_Incr_Rcvd\": incr_rcvd_probs[1], \"2_Incr_Rcvd\": incr_rcvd_probs[2], \"3_Incr_Rcvd\": incr_rcvd_probs[3],\n",
    "                \"4_Incr_Rcvd\": incr_rcvd_probs[4], \"5_Incr_Rcvd\": incr_rcvd_probs[5], \"6_Incr_Rcvd\": incr_rcvd_probs[6], \"7_Incr_Rcvd\": incr_rcvd_probs[7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Horizontal_Distance': 125.01715882229927,\n",
       " 'Height': 24,\n",
       " 'Num_Members': 7,\n",
       " 'Sending_Interval': 904,\n",
       " 'Packet_Size': 972,\n",
       " 'Reliability': 0.27374525094981006,\n",
       " 'Delay_Excd_Prob': 0.6038792241551689,\n",
       " 'Queue_Overflow_Prob': 0.0,\n",
       " '0_Incr_Rcvd': 0.11137772445510898,\n",
       " '1_Incr_Rcvd': 0.10667866426714658,\n",
       " '2_Incr_Rcvd': 0.09368126374725055,\n",
       " '3_Incr_Rcvd': 0.07728454309138172,\n",
       " '4_Incr_Rcvd': 0.06898620275944811,\n",
       " '5_Incr_Rcvd': 0.0613877224555089,\n",
       " '6_Incr_Rcvd': 0.07368526294741051,\n",
       " '7_Incr_Rcvd': 0.40691861627674464}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare No. of Packets for Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/960 [00:00<00:42, 22.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:42<00:00, 22.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from tqdm import tqdm\n",
    "import cudf \n",
    "\n",
    "cudf.set_allocator(\"managed\")\n",
    "NUM_PACKETS = 100000\n",
    "processed_data_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_processed\"\n",
    "save_path = \"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test\"\n",
    "save_filename = \"Test_Dataset_1_uplink_{}_packets\".format(NUM_PACKETS)\n",
    "dl_df_list = []\n",
    "# Process and save downlink DF \n",
    "downlink_csvs = glob.glob(processed_data_path + \"/*_uplink.csv\")\n",
    "for csv_file in tqdm(downlink_csvs):\n",
    "    # Get modulation\n",
    "    if \"BPSK\" in csv_file:\n",
    "        modulation = \"BPSK\"\n",
    "    elif \"QPSK\" in csv_file:\n",
    "        modulation = \"QPSK\"\n",
    "    elif \"QAM-16\" in csv_file:\n",
    "        modulation = \"QAM16\"\n",
    "    elif \"QAM-64\" in csv_file:\n",
    "        modulation = \"QAM64\"\n",
    "    df = cudf.read_csv(csv_file, \n",
    "                    usecols = ['U2G_H_Dist', 'Height', \"UAV_Sending_Interval\",\"Delay\", \"Packet_State\", \"Throughput\"])\n",
    "    df = df.loc[df[\"Packet_State\"].isin([\"Reliable\", \"Delay_Exceeded\", \"RETRY_LIMIT_REACHED\", \"QUEUE_OVERFLOW\"])] # Filter out unknown FAIL\n",
    "    if len(df.index) > NUM_PACKETS:\n",
    "        df = df.head(NUM_PACKETS)\n",
    "    u2g_h_dist = df[\"U2G_H_Dist\"].values[0]\n",
    "    height = df[\"Height\"].values[0]\n",
    "    uav_sending_interval = df[\"UAV_Sending_Interval\"].values[0]\n",
    "    throughput = df[\"Throughput\"].mean()\n",
    "    num_packets = len(df)\n",
    "    num_reliable = len(df.loc[df[\"Packet_State\"] == \"Reliable\"])\n",
    "    num_incr_rcvd = len(df.loc[df[\"Packet_State\"] == \"RETRY_LIMIT_REACHED\"])\n",
    "    num_queue_overflow = len(df.loc[df[\"Packet_State\"] == \"QUEUE_OVERFLOW\"])\n",
    "    num_delay_excd = len(df.loc[df[\"Packet_State\"] == \"Delay_Exceeded\"])\n",
    "    reliability = num_reliable / num_packets\n",
    "    incr_rcvd_prob = num_incr_rcvd / num_packets\n",
    "    queue_overflow_prob = num_queue_overflow / num_packets\n",
    "    delay_excd_prob = num_delay_excd / num_packets\n",
    "    test_case = {\"Horizontal_Distance\": u2g_h_dist, \"Height\": height, \"Modulation\": modulation, \"UAV_Sending_Interval\": uav_sending_interval, \"Throughput\": throughput,\n",
    "                \"Reliability\": reliability, \"Delay_Excd_Prob\": delay_excd_prob, \"Queue_Overflow_Prob\": queue_overflow_prob, \"Incorrectly_Rcvd_Prob\": incr_rcvd_prob}\n",
    "    dl_df_list.append(test_case)\n",
    "dl_df = pd.DataFrame(dl_df_list)\n",
    "# dl_df.to_hdf(save_path + \"{}.h5\".format(save_filename), key='Downlink')\n",
    "dl_df.to_csv(save_path + \"/{}.csv\".format(save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_df_100000 = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_uplink_100000_packets.csv\")\n",
    "test_df_10000 = pd.read_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_MultiModulation_Hovering_NoVideo/Test/Test_Dataset_1_uplink_50000_packets.csv\")\n",
    "\n",
    "abs_err_rel = abs(test_df_100000[\"Reliability\"] - test_df_10000[\"Reliability\"])\n",
    "max_abs_err_rel = max(abs_err_rel)\n",
    "idx_max_abs_err_rel = abs_err_rel.idxmax()\n",
    "abs_err_incr_rcvd = abs(test_df_100000[\"Incorrectly_Rcvd_Prob\"] - test_df_10000[\"Incorrectly_Rcvd_Prob\"])\n",
    "max_abs_err_incr_rcvd = max(abs_err_incr_rcvd)\n",
    "idx_max_abs_err_incr_rcvd = abs_err_incr_rcvd.idxmax()\n",
    "abs_err_queue_overflow = abs(test_df_100000[\"Queue_Overflow_Prob\"] - test_df_10000[\"Queue_Overflow_Prob\"])\n",
    "max_abs_err_queue_overflow = max(abs_err_queue_overflow)\n",
    "idx_max_abs_err_queue_overflow = abs_err_queue_overflow.idxmax()\n",
    "abs_err_delay_excd = abs(test_df_100000[\"Delay_Excd_Prob\"] - test_df_10000[\"Delay_Excd_Prob\"])\n",
    "max_abs_err_delay_excd = max(abs_err_delay_excd)\n",
    "idx_max_abs_err_delay_excd = abs_err_delay_excd.idxmax()\n",
    "\n",
    "print(max_abs_err_rel)\n",
    "print(max_abs_err_incr_rcvd)\n",
    "print(max_abs_err_queue_overflow)\n",
    "print(max_abs_err_delay_excd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b91d162001b74e2486487353b6410b0f764056372f730fbe993a2ad06d40082"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
