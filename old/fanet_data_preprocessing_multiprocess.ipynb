{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import networkx as nx # for drawing graphs\n",
    "# import matplotlib.pyplot as plt # for drawing graphs\n",
    "import os, sys, glob, math\n",
    "import time\n",
    "from multiprocessing.pool import Pool\n",
    "from itertools import repeat\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "\n",
    "def rssi_to_np(rssi):\n",
    "    # Function to convert rssi data from string (e.g. \"435 pW\") to exp (435e-12)\n",
    "    rssi_num = np.zeros(rssi.shape)\n",
    "    index = 0\n",
    "    for r in rssi:\n",
    "        num = r[0:-2]\n",
    "        expn = r[-2:]\n",
    "        # print(num)\n",
    "        # print(expn)\n",
    "        if expn == \" W\":\n",
    "            # print(num)\n",
    "            # print(index)\n",
    "            rssi_num[index] = float(num)\n",
    "        elif expn == \"mW\":\n",
    "            rssi_num[index] = float(num) * 1e-3\n",
    "        elif expn == \"uW\":\n",
    "            rssi_num[index] = float(num) * 1e-6\n",
    "        elif expn == \"nW\":\n",
    "            rssi_num[index] = float(num) * 1e-9\n",
    "        elif expn == \"pW\":\n",
    "            rssi_num[index] = float(num) * 1e-12\n",
    "        else:\n",
    "            print(expn)\n",
    "            raise ValueError(\"Unhandled unit prefix\")\n",
    "        index += 1\n",
    "    return rssi_num\n",
    "\n",
    "def compile_micro_sim_data_v2(file_list):\n",
    "    '''\n",
    "    Function to compile data from the CSV files generated by each micro-simulation\n",
    "    Update: To specifically return the rx_df, tx_df, mon_df and pd_df in lists, so that specific dfs can be accessed (instead of aggregating UAV dfs)\n",
    "    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)\n",
    "    Output: concatenates the raw data to UL and DL dataframes\n",
    "    '''\n",
    "\n",
    "    # Let's get the GCS dfs ===============================================================\n",
    "    gcs_rx_file = [file for file in file_list if (('_GCS-' in file) and ('-Rx' in file))]\n",
    "    gcs_tx_file = [file for file in file_list if (('_GCS-' in file) and ('-Tx' in file))]\n",
    "    gcs_mon_file = [file for file in file_list if (('_GCS-' in file) and ('Wlan' in file))]\n",
    "    gcs_pd_file = [file for file in file_list if (('_GCS-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gcs_rx_file) > 0:\n",
    "        gcs_rx_df = pd.read_csv(gcs_rx_file[0])\n",
    "    else:\n",
    "        print(\"GCS RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_tx_file) > 0:\n",
    "        gcs_tx_df = pd.read_csv(gcs_tx_file[0])\n",
    "    else:\n",
    "        print(\"GCS TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_pd_file) > 0:\n",
    "        gcs_pd_df = pd.read_csv(gcs_pd_file[0])\n",
    "    else:\n",
    "        print(\"GCS PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_mon_file) > 0:\n",
    "        gcs_mon_df = pd.read_csv(gcs_mon_file[0]) # Mon file is optional\n",
    "        gcs_mon_df[\"Addr\"] = \"192.168.0.1\"\n",
    "    else: \n",
    "        gcs_mon_df = None\n",
    "\n",
    "    # Let's get the GW dfs ===============================================================\n",
    "    gw_rx_file = [file for file in file_list if (('_GW-' in file) and ('-Rx' in file))]\n",
    "    gw_tx_file = [file for file in file_list if (('_GW-' in file) and ('-Tx' in file))]\n",
    "    gw_mon_file = [file for file in file_list if (('_GW-' in file) and ('Wlan' in file))]\n",
    "    gw_pd_file = [file for file in file_list if (('_GW-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gw_rx_file) > 0:\n",
    "        gw_rx_df = pd.read_csv(gw_rx_file[0])\n",
    "    else:\n",
    "        print(\"GW RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_tx_file) > 0:\n",
    "        gw_tx_df = pd.read_csv(gw_tx_file[0])\n",
    "    else:\n",
    "        print(\"GW TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_pd_file) > 0:\n",
    "        gw_pd_df = pd.read_csv(gw_pd_file[0])\n",
    "    else:\n",
    "        print(\"GW PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_mon_file) > 0:\n",
    "        gw_mon_df = pd.read_csv(gw_mon_file[0]) # Mon file is optional\n",
    "        gw_mon_df[\"Addr\"] = \"192.168.0.2\"\n",
    "    else:\n",
    "        gw_mon_df = None\n",
    "\n",
    "    # Let's get the UAVs dfs ===============================================================\n",
    "    uavs_rx_df_list = []\n",
    "    uavs_tx_df_list = []\n",
    "    uavs_mon_df_list = []\n",
    "    uavs_pd_df_list = []\n",
    "    uav_rx_files = [file for file in file_list if (('_UAV-' in file) and ('-Rx' in file))]\n",
    "    uav_tx_files = [file for file in file_list if (('_UAV-' in file) and ('-Tx' in file))]\n",
    "    uav_mon_files = [file for file in file_list if (('_UAV-' in file) and ('Wlan' in file))]\n",
    "    uav_pd_files = [file for file in file_list if (('_UAV-' in file) and ('PacketDrop' in file))]\n",
    "    uav_rx_files.sort()\n",
    "    uav_tx_files.sort()\n",
    "    uav_mon_files.sort()\n",
    "    uav_pd_files.sort()\n",
    "    if len(uav_rx_files) > 0:\n",
    "        for uav_rx_file in uav_rx_files:\n",
    "            uavs_rx_df_list.append(pd.read_csv(uav_rx_file))\n",
    "    else:\n",
    "        print(\"UAV RX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_tx_files) > 0:\n",
    "        for uav_tx_file in uav_tx_files:\n",
    "            uavs_tx_df_list.append(pd.read_csv(uav_tx_file))\n",
    "    else:\n",
    "        print(\"UAV TX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_pd_files) > 0:\n",
    "        for uav_pd_file in uav_pd_files:\n",
    "            uavs_pd_df_list.append(pd.read_csv(uav_pd_file))\n",
    "    else:\n",
    "        print(\"UAV PD File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_mon_files) > 0: # UAV mon files are optional now\n",
    "        uav_member_index = 3\n",
    "        for uav_mon_file in uav_mon_files:\n",
    "            uav_mon_df = pd.read_csv(uav_mon_file)\n",
    "            uav_mon_df[\"Addr\"] = \"192.168.0.\" + str(uav_member_index)\n",
    "            uavs_mon_df_list.append(uav_mon_df)\n",
    "            uav_member_index += 1\n",
    "    else:\n",
    "        uavs_mon_df_list = []\n",
    "\n",
    "    rx_df_list = [gcs_rx_df, gw_rx_df] + uavs_rx_df_list\n",
    "    tx_df_list = [gcs_tx_df, gw_tx_df] + uavs_tx_df_list\n",
    "    pd_df_list = [gcs_pd_df, gw_pd_df] + uavs_pd_df_list\n",
    "    mon_df_list = [gcs_mon_df, gw_mon_df] + uavs_mon_df_list\n",
    "\n",
    "    # UNCOMMENT BELOW IF RSSI DATA WILL BE USED\n",
    "    for rx_df in rx_df_list:\n",
    "        rx_df[\"RSSI\"] = rssi_to_np(rx_df[\"RSSI\"])\n",
    "    for pd_df in pd_df_list:\n",
    "        pd_df[\"RSSI\"] = rssi_to_np(pd_df[\"RSSI\"])\n",
    "    for mon_df in mon_df_list:\n",
    "        if mon_df is not None:\n",
    "            mon_df[\"RSSI\"] = rssi_to_np(mon_df[\"RSSI\"])\n",
    "\n",
    "    return rx_df_list, tx_df_list, pd_df_list, mon_df_list\n",
    "\n",
    "def process_dropped_packets_v5(tx_df, rx_df_list, pd_df_list, tx_index, delay_threshold, sending_interval=40, NP=10000):\n",
    "    '''\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, fopr downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df_list: List of Rx DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    tx_index: Index of Tx in pd_df_list (e.g. for GCS, tx_index = 0)\n",
    "    delay_threshold: Delay threshold to consider if packet arrived too late\n",
    "    sending_interval: Mean sending interval (used to determine UAV speed in the simulation)\n",
    "    NP: Number of packets set for every 100m\n",
    "    Output: pkt_df: DF containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    uav_speed = 100 * 1000 / NP / sending_interval # This is for estimating the U2G Distance when queue overflow happens (refer Omnet ini file)\n",
    "    pkt_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Delay','Queueing_Time','Backoff_Time','U2G_Distance',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State'])\n",
    "    for index, row in tqdm(tx_df.iterrows()):\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "        dest_addr = row[\"Dest_Addr\"]\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "        rx_df = rx_df_list[rx_index]\n",
    "\n",
    "        # For each packet in gcs_tx_df, get the packet drops from GW and corresponding UAV\n",
    "        pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df_list[tx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        pkt_drops_gw = pd_df_list[1].loc[(pd_df_list[1][\"Packet_Name\"] == packetName)] # Packets dropped at the gateway UAV\n",
    "        if rx_index != 1: # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df_list[rx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw], ignore_index = True)\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at GW and Rx and Tx\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            queue_overflow = np.count_nonzero(drop_reasons == \"QUEUE_OVERFLOW\")\n",
    "            retry_limit_excd = np.count_nonzero(drop_reasons == \"RETRY_LIMIT_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons == \"INTERFACE_DOWN\")\n",
    "            num_drops = len(drop_reasons) # This is for counting drops due to incorrectly received only\n",
    "\n",
    "            # Update pkt_df \n",
    "            if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "                # If not received, add the data of failed packet\n",
    "                rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "                tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "                bytes = row[\"Bytes\"]\n",
    "                rssi = pkt_drops[\"RSSI\"].mean() # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "                u2g_sinr = max(pkt_drops[\"U2G_SINR\"].values)\n",
    "                u2g_ber = max(pkt_drops[\"U2G_BER\"].values)\n",
    "                delay = max(pkt_drops[\"Delay\"].values)\n",
    "                queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "                backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "                u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "                # Packet State Based on Failure Mode\n",
    "                if retry_limit_excd > 0:\n",
    "                    pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                    # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif queue_overflow > 0:\n",
    "                    pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                    # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif interface_down > 0:\n",
    "                    pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "                else:\n",
    "                    pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                    print(\"Packet Failure Mode Unknown\")\n",
    "                # Check for U2U Data\n",
    "                if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                    u2u_sinr = max(pkt_drops[\"U2U_SINR\"].values)\n",
    "                    u2u_ber = max(pkt_drops[\"U2U_BER\"].values)\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "\n",
    "                failed_pkt = pd.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = pd.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                # If packet successfully received, update the number of tries and the reason for failed attempt(s) to the received packet info\n",
    "                rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "                rcvd_pkt_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "                rcvd_pkt_df[\"Queue_Overflow\"] = queue_overflow\n",
    "                rcvd_pkt_df[\"Interface_Down\"] = interface_down\n",
    "                rcvd_pkt_df[\"Number_Dropped\"] = num_drops\n",
    "                if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "                else:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "                pkt_df = pd.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "\n",
    "        elif (packetName in rx_df[\"Packet_Name\"].values):\n",
    "            # The packet was received without any retries\n",
    "            rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "            rcvd_pkt_df[\"Incorrectly_Rcvd\"] = 0\n",
    "            rcvd_pkt_df[\"Queue_Overflow\"] = 0\n",
    "            rcvd_pkt_df[\"Interface_Down\"] = 0\n",
    "            rcvd_pkt_df[\"Number_Dropped\"] = 0\n",
    "            if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "            else:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "            pkt_df = pd.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "        \n",
    "        # else:\n",
    "        #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    pkt_df = pkt_df.sort_values(\"RxTime\")\n",
    "    pkt_df = pkt_df.reset_index()\n",
    "    return pkt_df\n",
    "\n",
    "def process_dropped_packets_dict(tx_df, rx_df_list, pd_df_list, tx_index, delay_threshold, sending_interval=40, NP=10000):\n",
    "    '''\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, fopr downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df_list: List of Rx DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    tx_index: Index of Tx in pd_df_list (e.g. for GCS, tx_index = 0)\n",
    "    delay_threshold: Delay threshold to consider if packet arrived too late\n",
    "    sending_interval: Mean sending interval (used to determine UAV speed in the simulation)\n",
    "    NP: Number of packets set for every 100m\n",
    "    Output: pkt_df: DF containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    uav_speed = 100 * 1000 / NP / sending_interval # This is for estimating the U2G Distance when queue overflow happens (refer Omnet ini file)\n",
    "    pkt_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Delay','Queueing_Time','Backoff_Time','U2G_Distance',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State'])\n",
    "    \n",
    "    tx_df_dict = tx_df.to_dict('records')\n",
    "    packet_names = tx_df_dict[0][\"Packet_Name\"]\n",
    "    for row in tqdm(tx_df_dict):\n",
    "        packetName = packet_names + \"-\" + str(row[\"Packet_Seq\"])\n",
    "        dest_addr = row[\"Dest_Addr\"]\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "        rx_df = rx_df_list[rx_index]\n",
    "\n",
    "        # For each packet in gcs_tx_df, get the packet drops from GW and corresponding UAV\n",
    "        pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df_list[tx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        pkt_drops_gw = pd_df_list[1].loc[(pd_df_list[1][\"Packet_Name\"] == packetName)] # Packets dropped at the gateway UAV\n",
    "        if rx_index != 1: # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df_list[rx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw], ignore_index = True)\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at GW and Rx and Tx\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            queue_overflow = np.count_nonzero(drop_reasons == \"QUEUE_OVERFLOW\")\n",
    "            retry_limit_excd = np.count_nonzero(drop_reasons == \"RETRY_LIMIT_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons == \"INTERFACE_DOWN\")\n",
    "            num_drops = len(drop_reasons) # This is for counting drops due to incorrectly received only\n",
    "\n",
    "            # Update pkt_df \n",
    "            if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "                # If not received, add the data of failed packet\n",
    "                rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "                tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "                bytes = row[\"Bytes\"]\n",
    "                rssi = pkt_drops[\"RSSI\"].mean() # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "                u2g_sinr = max(pkt_drops[\"U2G_SINR\"].values)\n",
    "                u2g_ber = max(pkt_drops[\"U2G_BER\"].values)\n",
    "                delay = max(pkt_drops[\"Delay\"].values)\n",
    "                queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "                backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "                u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "                # Packet State Based on Failure Mode\n",
    "                if retry_limit_excd > 0:\n",
    "                    pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                    # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif queue_overflow > 0:\n",
    "                    pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                    # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif interface_down > 0:\n",
    "                    pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "                else:\n",
    "                    pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                    print(\"Packet Failure Mode Unknown\")\n",
    "                # Check for U2U Data\n",
    "                if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                    u2u_sinr = max(pkt_drops[\"U2U_SINR\"].values)\n",
    "                    u2u_ber = max(pkt_drops[\"U2U_BER\"].values)\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "\n",
    "                failed_pkt = pd.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = pd.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                # If packet successfully received, update the number of tries and the reason for failed attempt(s) to the received packet info\n",
    "                rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "                rcvd_pkt_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "                rcvd_pkt_df[\"Queue_Overflow\"] = queue_overflow\n",
    "                rcvd_pkt_df[\"Interface_Down\"] = interface_down\n",
    "                rcvd_pkt_df[\"Number_Dropped\"] = num_drops\n",
    "                if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "                else:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "                pkt_df = pd.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "\n",
    "        elif (packetName in rx_df[\"Packet_Name\"].values):\n",
    "            # The packet was received without any retries\n",
    "            rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "            rcvd_pkt_df[\"Incorrectly_Rcvd\"] = 0\n",
    "            rcvd_pkt_df[\"Queue_Overflow\"] = 0\n",
    "            rcvd_pkt_df[\"Interface_Down\"] = 0\n",
    "            rcvd_pkt_df[\"Number_Dropped\"] = 0\n",
    "            if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "            else:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "            pkt_df = pd.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "        \n",
    "        # else:\n",
    "        #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    pkt_df = pkt_df.sort_values(\"RxTime\")\n",
    "    pkt_df = pkt_df.reset_index()\n",
    "    return pkt_df\n",
    "\n",
    "def process_dropped_packets_v6(tx_df, rx_df, pd_df_list, delay_threshold, sending_interval=40, NP=10000):\n",
    "    '''\n",
    "    Date: 2/2/2023\n",
    "    Update: Changed the algo to only process failed packets (found in Tx but missing from Rx), for packets sucessfully received, only update the retry count and the delay exceeded status\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, for downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df: Rx DF\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    delay_threshold: Delay threshold to consider if packet arrived too late\n",
    "    sending_interval: Mean sending interval (used to determine UAV speed in the simulation)\n",
    "    NP: Number of packets set for every 100m\n",
    "    Output: rx_df: Modified rx_df containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    uav_speed = 100 * 1000 / NP / sending_interval # This is for estimating the U2G Distance when queue overflow happens (refer Omnet ini file)\n",
    "    # First, update the status of packets in rx_df\n",
    "    if \"Unnamed: 16\" in rx_df.columns:\n",
    "        rx_df = rx_df.drop([\"Unnamed: 16\"], axis=1)\n",
    "    rx_df[\"Packet_State\"] = np.where(rx_df['Delay'] > delay_threshold , \"Delay_Exceeded\", \"Reliable\")\n",
    "\n",
    "    # First, get the list of packets missing from Rx DF but transmitted in Tx DF\n",
    "    packets_rcvd = rx_df[\"Packet_Name\"].values\n",
    "    tx_df[\"Packet_Seq\"] = tx_df[\"Packet_Seq\"].apply(str)\n",
    "    tx_df[\"Packet_Full_Name\"] = tx_df[\"Packet_Name\"] + \"-\" + tx_df[\"Packet_Seq\"]\n",
    "    tx_df_failed = tx_df.loc[~(tx_df[\"Packet_Full_Name\"].isin(packets_rcvd))]\n",
    "    tx_df_failed_dict = tx_df_failed.to_dict('records')\n",
    "    failed_pkt_list = [] # Using list to store failed packet instead of doing pd.concat for appending every packets. This should be much faster\n",
    "    # Only iterating through packets that failed to be received\n",
    "    for row in tqdm(tx_df_failed_dict):\n",
    "        packetName = row[\"Packet_Full_Name\"]\n",
    "        # Use packet name to find the src of packet (NOTE: This makes the naming of packets important)\n",
    "        packetType, packetSeq = packetName.split('-')\n",
    "        if packetType == \"CNCData\":\n",
    "            tx_index = 0\n",
    "        elif packetType == \"GatewayData\":\n",
    "            tx_index = 1\n",
    "        else:\n",
    "            tx_index = int(packetType.split(\"_\")[-1]) + 2 # If the packet is not CNCData or GatewayData, it should be UAVData\n",
    "        dest_addr = row[\"Dest_Addr\"]\n",
    "        src_addr = \"192.168.0.\" + str(tx_index+1)\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "\n",
    "        # For each packet in tx_df_failed, get the packet drops from GW and corresponding UAV\n",
    "        pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df_list[tx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        pkt_drops_gw = pd_df_list[1].loc[(pd_df_list[1][\"Packet_Name\"] == packetName)] # Packets dropped at the gateway UAV\n",
    "        if rx_index != 1: # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df_list[rx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = pd.concat([pkt_drops_tx, pkt_drops_gw], ignore_index = True)\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at GW and Rx and Tx\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            queue_overflow = np.count_nonzero(drop_reasons == \"QUEUE_OVERFLOW\")\n",
    "            retry_limit_excd = np.count_nonzero(drop_reasons == \"RETRY_LIMIT_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons == \"INTERFACE_DOWN\")\n",
    "\n",
    "            # If not received, add the data of failed packet\n",
    "            rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "            tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "            bytes = row[\"Bytes\"]\n",
    "            rssi = max(pkt_drops[\"RSSI\"].values) # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "            u2g_sinr = max(pkt_drops[\"U2G_SINR\"].values)\n",
    "            u2g_ber = max(pkt_drops[\"U2G_BER\"].values)\n",
    "            delay = max(pkt_drops[\"Delay\"].values)\n",
    "            queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "            backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "            u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "            # Packet State Based on Failure Mode\n",
    "            if retry_limit_excd > 0:\n",
    "                pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                if math.isnan(u2g_distance):\n",
    "                    u2g_distance = uav_speed * rx_time\n",
    "            elif queue_overflow > 0:\n",
    "                pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                if math.isnan(u2g_distance):\n",
    "                    u2g_distance = uav_speed * rx_time\n",
    "            elif interface_down > 0:\n",
    "                pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "            else:\n",
    "                pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                print(\"Packet Failure Mode Unknown\")\n",
    "            # Check for U2U Data\n",
    "            if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                u2u_sinr = max(pkt_drops[\"U2U_SINR\"].values)\n",
    "                u2u_ber = max(pkt_drops[\"U2U_BER\"].values)\n",
    "                hop_count = 2\n",
    "            else:\n",
    "                u2u_sinr = None\n",
    "                u2u_ber = None\n",
    "                hop_count = 1\n",
    "\n",
    "            failed_pkt = {'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                        'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Src_Addr': src_addr,'Dest_Addr': dest_addr,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,\n",
    "                        'U2G_Distance': u2g_distance,'Retry_Count': incorrect_rcvd,'Packet_State': pkt_state}\n",
    "            failed_pkt_list.append(failed_pkt)\n",
    "        \n",
    "        # else:\n",
    "        #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "    \n",
    "    failed_pkt_df = pd.DataFrame(failed_pkt_list)\n",
    "    rx_df = pd.concat([rx_df,failed_pkt_df], ignore_index = True)\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_throughput(df, timeDiv):\n",
    "    '''\n",
    "    Function to calculate throughput data for a DataFrame\n",
    "    timeDiv is the time division to use for calculating the throughput\n",
    "    '''\n",
    "    maxTime = math.ceil(float(df[\"RxTime\"].max()))\n",
    "    for i in range(math.ceil(maxTime / timeDiv)):\n",
    "        df_in_range = df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)) & (df[\"Packet_State\"].isin([\"Reliable\",\"Delay_Exceeded\"]))]\n",
    "        totalBytes = df_in_range[\"Bytes\"].sum()\n",
    "        throughput = totalBytes / timeDiv\n",
    "        df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)), \"Throughput\"] = throughput\n",
    "    return df\n",
    "\n",
    "@numba.jit\n",
    "def process_throughput_np(df_np, df_col_ind, timeDiv):\n",
    "    '''\n",
    "    Function to calculate throughput data for a DataFrame\n",
    "    timeDiv is the time division to use for calculating the throughput\n",
    "    NOTE: Assuming that df has been sorted based on \"RxTime\"\n",
    "    '''\n",
    "    np_arr_list = []\n",
    "    # df_np = df.to_numpy()\n",
    "    df_np = np.hstack((df_np,np.ones((df_np.shape[0],1)))) # Create column for throughput data\n",
    "    # df_col_ind= dict(zip(df.columns, list(range(0,len(df.columns)))))\n",
    "    df_col_ind[\"Throughput\"] = df_np.shape[1] - 1\n",
    "    maxTime = math.ceil(float(df_np[:,df_col_ind[\"RxTime\"]].max()))\n",
    "    for i in range(math.ceil(maxTime / timeDiv)):\n",
    "        bool_filter = (df_np[:,df_col_ind[\"RxTime\"]] >= (i*timeDiv)) & (df_np[:,df_col_ind[\"RxTime\"]] < ((i+1)*timeDiv)) & ((df_np[:,df_col_ind[\"Packet_State\"]] == \"Reliable\") | (df_np[:,df_col_ind[\"Packet_State\"]] == \"Delay_Exceeded\"))\n",
    "        if any(bool_filter):\n",
    "            rows_in_range = df_np[bool_filter,:]\n",
    "            totalBytes = rows_in_range[:,df_col_ind[\"Bytes\"]].sum()\n",
    "            throughput = totalBytes / timeDiv\n",
    "            rows_in_range_index = np.where((df_np[:,df_col_ind[\"RxTime\"]] >= (i*timeDiv)) & (df_np[:,df_col_ind[\"RxTime\"]] < ((i+1)*timeDiv)))[0]\n",
    "            df_np[rows_in_range_index[0]:rows_in_range_index[-1]+1, df_col_ind[\"Throughput\"]] = throughput # For df_np, from the first to the last index in rows_in_range_index, update the throughput colnm\n",
    "\n",
    "    df_cols = list(df_col_ind.keys())\n",
    "    df_new = pd.DataFrame(df_np, columns=df_cols)\n",
    "    return df_new\n",
    "\n",
    "# import cudf\n",
    "# def process_throughput_cudf(df, timeDiv):\n",
    "#     '''\n",
    "#     Function to calculate throughput data for a DataFrame\n",
    "#     timeDiv is the time division to use for calculating the throughput\n",
    "#     NOTE: IF USING CUDF, CANNOT USE MULTIPROCESSING!!!\n",
    "#     ALSO THIS FUNCTION IS NOT WORKING\n",
    "#     '''\n",
    "#     maxTime = math.ceil(float(df[\"RxTime\"].max()))\n",
    "#     cu_df = cudf.from_pandas(df)\n",
    "#     for i in range(math.ceil(maxTime / timeDiv)):\n",
    "#         df_in_range = cu_df.loc[(cu_df[\"RxTime\"] >= (i*timeDiv)) & (cu_df[\"RxTime\"] < ((i+1)*timeDiv)) & (cu_df[\"Packet_State\"].str.extract('(Reliable)').notna().values) & (cu_df[\"Packet_State\"].str.extract('(Delay_Exceeded)').notna().values)]\n",
    "#         totalBytes = df_in_range[\"Bytes\"].sum()\n",
    "#         throughput = totalBytes / timeDiv\n",
    "#         cu_df.loc[(cu_df[\"RxTime\"] >= (i*timeDiv)) & (cu_df[\"RxTime\"] < ((i+1)*timeDiv)), \"Throughput\"] = throughput\n",
    "#     return cu_df.to_pandas()\n",
    "\n",
    "def process_scenario(scenario, sim_root_path, delay_threshold, NP, save_path):\n",
    "    print(scenario)\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "    scenario_params = scenario.split('_')\n",
    "    num_member = int(scenario_params[0].split('-')[-1])\n",
    "    inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "    height = int(scenario_params[2].split('-')[-1]) \n",
    "    sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "    rx_df_list, tx_df_list, pd_df_list, mon_df_list = compile_micro_sim_data_v2(scenario_files)\n",
    "    \n",
    "    # Process the state of each packets sent in DL\n",
    "    start_dl_time = time.time()\n",
    "    dl_data = process_dropped_packets_v5(tx_df_list[0], rx_df_list, pd_df_list, 0, delay_threshold, sending_interval, NP)\n",
    "    if dl_data is not None:\n",
    "        dl_data[\"Height\"] = height\n",
    "        dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "        dl_data[\"Num_Members\"] = num_member\n",
    "        dl_data[\"Sending_Interval\"] = sending_interval\n",
    "        dl_data = process_throughput(dl_data, 1)\n",
    "        dl_df = pd.concat([dl_df, dl_data], ignore_index=True)\n",
    "        dl_df.to_csv(os.path.join(save_path,\"{}_downlink.csv\".format(scenario)), index=False)\n",
    "\n",
    "    # Process the state of each packets sent in DL\n",
    "    start_ul_time = time.time()\n",
    "    for i in range(1,len(rx_df_list)):\n",
    "        ul_data = process_dropped_packets_v5(tx_df_list[i], rx_df_list, pd_df_list, i, delay_threshold, sending_interval, NP)\n",
    "        if ul_data is not None:\n",
    "            ul_data[\"Height\"] = height\n",
    "            ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            ul_data[\"Num_Members\"] = num_member\n",
    "            ul_data[\"Sending_Interval\"] = sending_interval\n",
    "            ul_data = process_throughput(ul_data, 1)\n",
    "            ul_df = pd.concat([ul_df, ul_data], ignore_index=True)\n",
    "    if not ul_df.empty:\n",
    "        ul_df.to_csv(os.path.join(save_path,\"{}_uplink.csv\".format(scenario)), index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"DL Time: {}\".format(start_ul_time-start_dl_time))\n",
    "    print(\"UL Time: {}\".format(end_time-start_ul_time))\n",
    "\n",
    "def process_scenario_v2(scenario, sim_root_path, delay_threshold, NP, save_path):\n",
    "    print(scenario)\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "    scenario_params = scenario.split('_')\n",
    "    num_member = int(scenario_params[0].split('-')[-1])\n",
    "    inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "    height = int(scenario_params[2].split('-')[-1]) \n",
    "    sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "    rx_df_list, tx_df_list, pd_df_list, mon_df_list = compile_micro_sim_data_v2(scenario_files)\n",
    "\n",
    "    # Sort out which df is which\n",
    "    gcs_tx_df = tx_df_list[0]\n",
    "    gcs_rx_df = rx_df_list[0]\n",
    "    uavs_tx_df = pd.concat(tx_df_list[1:len(tx_df_list)], ignore_index=True)\n",
    "    uavs_rx_df = pd.concat(rx_df_list[1:len(rx_df_list)], ignore_index=True)\n",
    "    \n",
    "    # Process the state of each packets sent in DL\n",
    "    start_dl_time = time.time()\n",
    "    dl_df = process_dropped_packets_v6(gcs_tx_df, uavs_rx_df, pd_df_list, delay_threshold, sending_interval, NP)\n",
    "    if dl_df is not None:\n",
    "        start_throughput = time.time()\n",
    "        dl_df = process_throughput(dl_df,1)\n",
    "        # dl_df = process_throughput_np(dl_df.to_numpy(), dict(zip(dl_df.columns, list(range(0,len(dl_df.columns))))), 1)\n",
    "        end_throughput = time.time()\n",
    "        print(\"Process Throughput Time: {}\".format(end_throughput-start_throughput))\n",
    "        dl_df[\"Height\"] = height\n",
    "        dl_df[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "        dl_df[\"Num_Members\"] = num_member\n",
    "        dl_df[\"Sending_Interval\"] = sending_interval\n",
    "        dl_df.to_csv(os.path.join(save_path,\"{}_downlink.csv\".format(scenario)), index=False)\n",
    "\n",
    "    # Process the state of each packets sent in DL\n",
    "    start_ul_time = time.time()\n",
    "    ul_df = process_dropped_packets_v6(uavs_tx_df, gcs_rx_df, pd_df_list, delay_threshold, sending_interval, NP)\n",
    "    if ul_df is not None:\n",
    "        start_throughput = time.time()\n",
    "        ul_df = process_throughput(ul_df, 1)\n",
    "        # ul_df = process_throughput_np(ul_df.to_numpy(), dict(zip(ul_df.columns, list(range(0,len(ul_df.columns))))), 1)\n",
    "        end_throughput = time.time()\n",
    "        print(\"Process Throughput Time: {}\".format(end_throughput-start_throughput))\n",
    "        ul_df[\"Height\"] = height\n",
    "        ul_df[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "        ul_df[\"Num_Members\"] = num_member\n",
    "        ul_df[\"Sending_Interval\"] = sending_interval\n",
    "        ul_df.to_csv(os.path.join(save_path,\"{}_uplink.csv\".format(scenario)), index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"DL Time: {}\".format(start_ul_time-start_dl_time))\n",
    "    print(\"UL Time: {}\".format(end_time-start_ul_time))\n",
    "\n",
    "def process_sim_data_v2(sim_root_path, delay_threshold, save_path):\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + \"/*GCS-Tx.csv\")] # Get list of \"unique\" scenarios\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    NP = 1000 # The number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\n",
    "    # NP = int(input(\"Enter number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\"))\n",
    "    with Pool(2) as pool:\n",
    "        pool.starmap(process_scenario_v2, zip(scenario_list, repeat(sim_root_path), repeat(delay_threshold), repeat(NP), repeat(save_path)))\n",
    "    # process_scenario_v2(scenario_list[0],sim_root_path,delay_threshold,NP,save_path)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data and save to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the data\n",
    "sim_root_path = \"/home/research-student/omnetpp_sim_results/Testing\"\n",
    "delay_threshold = 0.04\n",
    "process_sim_data_v2(sim_root_path, delay_threshold=delay_threshold, save_path=sim_root_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001888275146484375\n"
     ]
    }
   ],
   "source": [
    "# Testing categorical data type\n",
    "import pandas as pd\n",
    "import time\n",
    "rx_df = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Testing/NumMember-7_InterUAVDistance-5_Height-24_Distance-0_PacketSize-24_SendingRate-233_GCS-Rx.csv\")\n",
    "rx_df[[\"Packet_Type\", \"Packet_Seq\"]] = rx_df.Packet_Name.str.split(\"-\",expand=True)\n",
    "rx_df[\"Packet_Type\"] = rx_df.Packet_Type.astype('category')\n",
    "rx_df[\"Packet_Seq\"] = rx_df.Packet_Seq.astype(\"uint32\")\n",
    "# print(rx_df.head())\n",
    "# print(rx_df.dtypes)\n",
    "# rx_df.memory_usage()\n",
    "\n",
    "# Compare timing performance\n",
    "start_t = time.time()\n",
    "rx_df.loc[(rx_df[\"Packet_Type\"] == \"UAVData_3\") & (rx_df[\"Packet_Seq\"] == 1)] # Elapsed time: 0.0016155242919921875\n",
    "# rx_df.loc[(rx_df[\"Packet_Name\"] == \"UAVData_3-0\")] # Elapsed time: 0.024063587188720703\n",
    "end_t = time.time()\n",
    "print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         486.934000\n",
      "1         445.416000\n",
      "2        1012.180000\n",
      "3         296.010000\n",
      "4         664.423000\n",
      "            ...     \n",
      "50057       0.687825\n",
      "50058            NaN\n",
      "50059            NaN\n",
      "50060            NaN\n",
      "50061            NaN\n",
      "Name: U2G_SINR, Length: 50062, dtype: float64\n",
      "0         486.933990\n",
      "1         445.415985\n",
      "2        1012.179993\n",
      "3         296.010010\n",
      "4         664.422974\n",
      "            ...     \n",
      "50057       0.687825\n",
      "50058            NaN\n",
      "50059            NaN\n",
      "50060            NaN\n",
      "50061            NaN\n",
      "Name: U2G_SINR, Length: 50062, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_v1 = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Testing_v1/NumMember-7_InterUAVDistance-5_Height-24_Distance-0_PacketSize-24_SendingRate-233_downlink.csv\")\n",
    "df_v2 = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Testing_v2/NumMember-7_InterUAVDistance-5_Height-24_Distance-0_PacketSize-24_SendingRate-233_downlink.csv\")\n",
    "df_v2.drop(columns=[\"Packet_Type\", \"Packet_Seq\"], inplace=True)\n",
    "# df_v1 == df_v2\n",
    "print(df_v1[\"U2G_SINR\"])\n",
    "print(df_v2[\"U2G_SINR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tx_df = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Testing/NumMember-7_InterUAVDistance-5_Height-24_Distance-0_PacketSize-24_SendingRate-233_GCS-Tx.csv\")\n",
    "tx_dict = tx_df.to_dict('records')\n",
    "tx_time = tx_df.to_dict()[\"Packet_Name\"].values()\n",
    "print(tx_dict[0][\"Packet_Name\"])\n",
    "for row in tx_dict:\n",
    "    print(row)\n",
    "    print(row[\"Bytes\"])\n",
    "    print(row[\"Packet_Seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tx_df = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Modulation_NumPkts_Test/Test_Np1000_BPSK_6-5Mbps/NumMember-3_InterUAVDistance-5_Height-108_Distance-0_PacketSize-921_SendingRate-809_GCS-Tx.csv\")\n",
    "# tx_df.head()\n",
    "tx_df[\"Packet_Seq\"] = tx_df[\"Packet_Seq\"].apply(str)\n",
    "tx_df[\"Packet_Full_Name\"] = tx_df[\"Packet_Name\"] + \"-\" + tx_df[\"Packet_Seq\"]\n",
    "tx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rx_df = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Modulation_NumPkts_Test/Test_Np1000_BPSK_6-5Mbps/NumMember-3_InterUAVDistance-5_Height-108_Distance-0_PacketSize-921_SendingRate-809_GCS-Rx.csv\")\n",
    "\n",
    "rx_df = rx_df.drop([\"Unnamed: 16\"], axis=1)\n",
    "rx_df[\"Packet_State\"] = np.where(rx_df['Delay'] > 0.003 , \"Delay_Exceeded\", \"Reliable\")\n",
    "rx_df.head()\n",
    "packet_name, packet_seq = rx_df[\"Packet_Name\"].values[3].split(\"-\")\n",
    "print(packet_name, packet_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rx_df = pd.read_csv(\"/home/research-student/omnetpp_sim_results/Modulation_NumPkts_Test/Test_Np1000_BPSK_6-5Mbps/NumMember-3_InterUAVDistance-5_Height-108_Distance-0_PacketSize-921_SendingRate-809_GCS-Rx.csv\")\n",
    "rx_np = rx_df.to_numpy()\n",
    "Column_Index_Dictionary = dict(zip(rx_df.columns, list(range(0,len(rx_df.columns)))))\n",
    "print(rx_np)\n",
    "print(Column_Index_Dictionary)\n",
    "mask = (rx_np[:,Column_Index_Dictionary[\"U2G_Distance\"]] > 1000)\n",
    "print(rx_np[mask,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
