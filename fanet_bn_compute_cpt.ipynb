{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import os, sys, glob, math, pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This function helps to calculate probability distribution, which goes into BBN (note, can handle up to 2 parents)\n",
    "def cpt_probs(df, child, parents):\n",
    "    try:\n",
    "        # dependencies_arr = [pd.Categorical(df[parent],categories=df[parent].cat.categories.tolist()) for parent in parents]\n",
    "        dependencies_arr = [df[parent] for parent in parents]\n",
    "        # cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()\n",
    "        cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index()\n",
    "        return cpt\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None \n",
    "\n",
    "def cpt_probs_freq(df, child, parents):\n",
    "    try:\n",
    "        # dependencies_arr = [pd.Categorical(df[parent],categories=df[parent].cat.categories.tolist()) for parent in parents]\n",
    "        dependencies_arr = [df[parent] for parent in parents]\n",
    "        # cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()\n",
    "        cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, dropna=False).sort_index()\n",
    "        return cpt\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None \n",
    "\n",
    "def euclidean_dist(row):\n",
    "    # Function to calc euclidean distance on every df row \n",
    "    euc_dist = math.sqrt(row[\"U2G_Distance\"]**2 - row[\"Height\"]**2)\n",
    "    return euc_dist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Training Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_df_8uav = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/Dataset_NP10000_BPSK_6-5Mbps_8UAVs_processed_downlink.h5\", '8_UAVs')\n",
    "dl_df_16uav = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/Dataset_NP10000_BPSK_6-5Mbps_16UAVs_processed_downlink.h5\", '16_UAVs')\n",
    "dl_df_24uav = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/Dataset_NP10000_BPSK_6-5Mbps_24UAVs_processed_downlink.h5\", '24_UAVs')\n",
    "dl_df_32uav = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/Dataset_NP10000_BPSK_6-5Mbps_32UAVs_processed_downlink.h5\", '32_UAVs')\n",
    "dl_df_40uav = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/Dataset_NP10000_BPSK_6-5Mbps_40UAVs_processed_downlink.h5\", '40_UAVs')\n",
    "dl_df = pd.concat([dl_df_8uav, dl_df_16uav, dl_df_24uav, dl_df_32uav, dl_df_40uav], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize the input layer. Change the df below to either DOWNLINK / UPLINK DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_threshold = 0.04\n",
    "df = dl_df # NOTE: Change this to either dl_df / ul_df\n",
    "\n",
    "df = df[df['U2G_SINR'].notna()] # Filter out rows with missing crucial information\n",
    "classes_df = pd.DataFrame() # Created an empty df to store classes data to reduce size of df that need to work with\n",
    "# First, discretise the values to classes\n",
    "h_dist_range = 500\n",
    "h_dist_num_classes = 100\n",
    "h_dist_labels = [str(num) for num in np.arange(0,h_dist_num_classes)+1]\n",
    "# h_dist_labels = ['vs','s','m','l','vl']\n",
    "height_labels = ['vs','s','m','l','vl']\n",
    "num_members_labels = ['vs','s','m','l','vl']\n",
    "sending_interval_labels = ['vs','s','m','l','vl']\n",
    "pkt_size_labels = ['vs','s','m','l','vl']\n",
    "sinr_labels = ['vs','s','m','l','vl']\n",
    "delay_labels = ['vs','s','m','l','vl']\n",
    "throughput_labels = ['s','m','l']\n",
    "queueing_labels = ['s','m','l']\n",
    "ber_labels = ['vs','s','m','l','vl']\n",
    "jitter_labels = ['s','m','l']\n",
    "# Independent vars\n",
    "h_dist_class_bnd = np.linspace(0, h_dist_range, h_dist_num_classes, endpoint=False).tolist()\n",
    "h_dist_class_bnd.append(h_dist_range+1)\n",
    "classes_df[\"H_Dist_Class\"] = pd.cut(df.U2G_H_Dist, h_dist_class_bnd, right=False, include_lowest=True, labels=h_dist_labels)\n",
    "# classes_df[\"H_Dist_Class\"] = pd.cut(df.U2G_H_Dist, [0,100,200,300,400,501], right=False, include_lowest=True, labels=h_dist_labels)\n",
    "classes_df[\"Height_Class\"] = pd.cut(df.Height, [1,25,49,73,97,121], right=False, include_lowest=True, labels=height_labels)\n",
    "classes_df[\"Num_Members_Class\"] = pd.cut(df.Num_Members, [2,8,16,24,32,40], right=False, include_lowest=True, labels=num_members_labels)\n",
    "# classes_df[\"Sending_Interval_Class\"] = pd.cut(df.Mean_Sending_Interval, [40,232,424,616,808,1001], right=True, include_lowest=True, labels=sending_interval_labels)\n",
    "# classes_df[\"Packet_Size_Class\"] = pd.cut(df.Bytes, [24,248,472,696,920,1145], right=True, include_lowest=True, labels=pkt_size_labels)\n",
    "classes_df[\"Sending_Interval_Class\"] = pd.cut(df.Mean_Sending_Interval, [40,232,424,616,808,1001], right=False, include_lowest=True, labels=sending_interval_labels)\n",
    "classes_df[\"Packet_Size_Class\"] = pd.cut(df.Bytes, [24,248,472,696,920,1145], right=False, include_lowest=True, labels=pkt_size_labels)\n",
    "# Second layer\n",
    "classes_df[\"SINR_Class\"], sinr_bins = pd.qcut(df.U2G_SINR, q=5, labels=sinr_labels, retbins=True)\n",
    "classes_df[\"Delay_Class\"], delay_bins = pd.qcut(df.Delay, q=5, labels=delay_labels, retbins=True)\n",
    "classes_df[\"Throughput_Class\"], throughput_bins = pd.qcut(df.Throughput, q=3, labels=throughput_labels, duplicates='drop', retbins=True)\n",
    "classes_df[\"Queueing_Time_Class\"], queueing_time_bins = pd.qcut(df.Queueing_Time, q=3, labels=queueing_labels, duplicates='drop', retbins=True)\n",
    "classes_df[\"BER_Class\"], ber_bins = pd.qcut(df.U2G_BER, q=5, labels=ber_labels, retbins=True)\n",
    "classes_df[\"Jitter_Class\"], jitter_bins = pd.qcut(df.Jitter, q=3, labels=jitter_labels, retbins=True)\n",
    "classes_df[\"Reliable\"] = (df[\"Packet_State\"] == \"Reliable\")\n",
    "classes_df[\"Delay_Exceeded\"] = (df[\"Delay\"] >= delay_threshold)\n",
    "classes_df[\"Retry_Count\"] = df[\"Retry_Count\"] #NOTE: Retry_Count is not necessarily the same as number of dropped packets\n",
    "classes_df[\"Incorrectly_Received\"] = df[\"Incorrectly_Received\"]\n",
    "classes_df[\"Queue_Overflow\"] = df[\"Queue_Overflow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classes_df to csv for examination\n",
    "data_type = \"Downlink\"\n",
    "classes_df.to_csv(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/classes_df_{}_hdist_{}_classes.h5\".format(data_type, h_dist_num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classes_df to hdf format for convenient loading\n",
    "data_type = \"Downlink\"\n",
    "classes_df.to_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/classes_df_{}_hdist_{}_classes.h5\".format(data_type, h_dist_num_classes), key='Downlink', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the qcut bin intervals for later use\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/sinr_bins_dl.npy\".format(data_type, h_dist_num_classes), sinr_bins)\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/delay_bins_dl.npy\".format(data_type, h_dist_num_classes), delay_bins)\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/throughput_bins_dl.npy\".format(data_type, h_dist_num_classes), throughput_bins)\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/queueing_time_bins_dl.npy\".format(data_type, h_dist_num_classes), queueing_time_bins)\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/ber_bins_dl.npy\".format(data_type, h_dist_num_classes), ber_bins)\n",
    "np.save(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/jitter_bins_dl.npy\".format(data_type, h_dist_num_classes), jitter_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes_df for later parts (if previous part not run)\n",
    "classes_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/classes_df_downlink.h5\", 'Downlink')\n",
    "\n",
    "delay_threshold = 0.04\n",
    "# First, discretise the values to classes\n",
    "h_dist_labels = ['vs','s','m','l','vl']\n",
    "height_labels = ['vs','s','m','l','vl']\n",
    "num_members_labels = ['vs','s','m','l','vl']\n",
    "# num_members_labels = ['vs','s','m','l']\n",
    "sending_interval_labels = ['vs','s','m','l','vl']\n",
    "pkt_size_labels = ['vs','s','m','l','vl']\n",
    "sinr_labels = ['vs','s','m','l','vl']\n",
    "delay_labels = ['vs','s','m','l','vl']\n",
    "throughput_labels = ['s','m','l']\n",
    "queueing_labels = ['s','m','l']\n",
    "ber_labels = ['vs','s','m','l','vl']\n",
    "jitter_labels = ['s','m','l']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Fully Connected BN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following computes the CPT of each node using the \"Unknown\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probabilities table for each second layer class\n",
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "sinr_cpt = cpt_probs(classes_df, child=\"SINR_Class\", parents=parents_1)\n",
    "delay_cpt = cpt_probs(classes_df, child=\"Delay_Class\", parents=parents_1)\n",
    "throughput_cpt = cpt_probs(classes_df, child=\"Throughput_Class\", parents=parents_1)\n",
    "queueing_cpt = cpt_probs(classes_df, child=\"Queueing_Time_Class\", parents=parents_1)\n",
    "ber_cpt = cpt_probs(classes_df, child=\"BER_Class\", parents=parents_1)\n",
    "jitter_cpt = cpt_probs(classes_df, child=\"Jitter_Class\", parents=parents_1)\n",
    "\n",
    "# parents_1_labels = [h_dist_labels,height_labels,num_members_labels,sending_interval_labels,pkt_size_labels]\n",
    "parents_1_labels = [h_dist_labels,height_labels,num_members_labels,sending_interval_labels,pkt_size_labels]\n",
    "sinr_cpt = sinr_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[sinr_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "delay_cpt = delay_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[delay_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "throughput_cpt = throughput_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[throughput_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "queueing_cpt = queueing_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[queueing_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "ber_cpt = ber_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[ber_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "jitter_cpt = jitter_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[jitter_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "\n",
    "parents_2 = [\"SINR_Class\", \"BER_Class\", \"Delay_Class\", \"Throughput_Class\", \"Queueing_Time_Class\", \"Jitter_Class\"]\n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_2)\n",
    "incorrect_rcvd_cpt[\"Unknown\"] = 0\n",
    "incorrect_rcvd_cpt.loc[(incorrect_rcvd_cpt==0).all(axis=1).values, \"Unknown\"] = 1\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=parents_2)\n",
    "delay_exceeded_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "delay_exceeded_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "delay_exceeded_cpt[\"Unknown\"] = 0\n",
    "delay_exceeded_cpt.loc[(delay_exceeded_cpt==0).all(axis=1).values, \"Unknown\"] = 1\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=parents_2)\n",
    "queue_overflow_cpt[\"Unknown\"] = 0\n",
    "queue_overflow_cpt.loc[(queue_overflow_cpt==0).all(axis=1).values, \"Unknown\"] = 1\n",
    "# TODO: TEMPORARY\n",
    "rel_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_2)\n",
    "rel_cpt[\"Unknown\"] = 0\n",
    "rel_cpt.loc[(rel_cpt==0).all(axis=1).values, \"Unknown\"] = 1\n",
    "# Add unknown \"U\" class for cases that are not seen in data\n",
    "parents_2_labels = [sinr_labels,delay_labels,throughput_labels,queueing_labels,ber_labels,jitter_labels]\n",
    "incorrect_rcvd_labels = incorrect_rcvd_cpt.columns.values\n",
    "delay_exceeded_labels = delay_exceeded_cpt.columns.values\n",
    "queue_overflow_labels = queue_overflow_cpt.columns.values\n",
    "incorrect_rcvd_cpt = incorrect_rcvd_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[incorrect_rcvd_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "delay_exceeded_cpt = delay_exceeded_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[delay_exceeded_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "queue_overflow_cpt = queue_overflow_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[queue_overflow_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "# TODO: TEMPORARY\n",
    "rel_labels = rel_cpt.columns.values\n",
    "rel_cpt = rel_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[rel_labels]\n",
    "\n",
    "parents_3 = [\"Incorrectly_Received\", \"Delay_Exceeded\", \"Queue_Overflow\"]\n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_3)\n",
    "reliability_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "reliability_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "reliability_cpt[\"Unknown\"] = 0\n",
    "reliability_cpt.loc[(reliability_cpt==0).all(axis=1).values, \"Unknown\"] = 1\n",
    "\n",
    "# TODO: Fix the below\n",
    "# parents_3_labels = [incorrect_rcvd_labels,delay_exceeded_labels,queue_overflow_labels]\n",
    "# reliability_labels = reliability_cpt.columns.values\n",
    "# reliability_cpt = reliability_cpt.reindex(pd.MultiIndex.from_product(parents_3_labels, names=parents_3))[reliability_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following computes the CPT WITHOUT using the \"Unknown\" class, but using pandas.fillna instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probabilities table for each second layer class\n",
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "sinr_cpt = cpt_probs(classes_df, child=\"SINR_Class\", parents=parents_1)\n",
    "delay_cpt = cpt_probs(classes_df, child=\"Delay_Class\", parents=parents_1)\n",
    "throughput_cpt = cpt_probs(classes_df, child=\"Throughput_Class\", parents=parents_1)\n",
    "queueing_cpt = cpt_probs(classes_df, child=\"Queueing_Time_Class\", parents=parents_1)\n",
    "ber_cpt = cpt_probs(classes_df, child=\"BER_Class\", parents=parents_1)\n",
    "jitter_cpt = cpt_probs(classes_df, child=\"Jitter_Class\", parents=parents_1)\n",
    "\n",
    "# parents_1_labels = [h_dist_labels,height_labels,num_members_labels,sending_interval_labels,pkt_size_labels]\n",
    "parents_1_labels = [h_dist_labels,height_labels,num_members_labels,sending_interval_labels,pkt_size_labels]\n",
    "sinr_cpt = sinr_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[sinr_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "delay_cpt = delay_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[delay_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "throughput_cpt = throughput_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[throughput_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "queueing_cpt = queueing_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[queueing_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "ber_cpt = ber_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[ber_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "jitter_cpt = jitter_cpt.reindex(pd.MultiIndex.from_product(parents_1_labels, names=parents_1))[jitter_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "\n",
    "parents_2 = [\"SINR_Class\", \"BER_Class\", \"Delay_Class\", \"Throughput_Class\", \"Queueing_Time_Class\", \"Jitter_Class\"]\n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_2)\n",
    "incorrect_rcvd_cpt.loc[(incorrect_rcvd_cpt==0).all(axis=1).values] = np.NaN\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=parents_2)\n",
    "delay_exceeded_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "delay_exceeded_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "delay_exceeded_cpt.loc[(delay_exceeded_cpt==0).all(axis=1).values] = np.NaN\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=parents_2)\n",
    "queue_overflow_cpt.loc[(queue_overflow_cpt==0).all(axis=1).values] = np.NaN\n",
    "# TODO: TEMPORARY ------------------------------------------\n",
    "# rel_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_2)\n",
    "# rel_cpt.loc[(rel_cpt==0).all(axis=1).values] = np.NaN\n",
    "# ----------------------------------------------------------\n",
    "parents_2_labels = [sinr_labels,delay_labels,throughput_labels,queueing_labels,ber_labels,jitter_labels]\n",
    "incorrect_rcvd_labels = incorrect_rcvd_cpt.columns.values\n",
    "delay_exceeded_labels = delay_exceeded_cpt.columns.values\n",
    "queue_overflow_labels = queue_overflow_cpt.columns.values\n",
    "incorrect_rcvd_cpt = incorrect_rcvd_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[incorrect_rcvd_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "delay_exceeded_cpt = delay_exceeded_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[delay_exceeded_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "queue_overflow_cpt = queue_overflow_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[queue_overflow_labels] # Rearrange rows and columns of cpt. This is important when building the Bayesian Network\n",
    "# TODO: TEMPORARY\n",
    "# rel_labels = rel_cpt.columns.values\n",
    "# rel_cpt = rel_cpt.reindex(pd.MultiIndex.from_product(parents_2_labels, names=parents_2))[rel_labels]\n",
    "\n",
    "# Use fillna to fill missing CPT rows -----------------------------------------------------------------\n",
    "# NOTE: It is important that the CPTs are reindexed first, as this affects how they are filled\n",
    "# Do forward fill first, then backward fill\n",
    "incorrect_rcvd_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "incorrect_rcvd_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "delay_exceeded_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "delay_exceeded_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "queue_overflow_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "queue_overflow_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# rel_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# rel_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "# Do backward fill first, then forward fill\n",
    "# incorrect_rcvd_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# incorrect_rcvd_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# delay_exceeded_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# delay_exceeded_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# queue_overflow_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# queue_overflow_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# rel_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# rel_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_3 = [\"Incorrectly_Received\", \"Delay_Exceeded\", \"Queue_Overflow\"]\n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_3)\n",
    "reliability_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "reliability_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "reliability_cpt.loc[(reliability_cpt==0).all(axis=1).values] = np.NaN\n",
    "\n",
    "# Use fillna to fill missing CPT rows -----------------------------------------------------------------\n",
    "# NOTE: It is important that the CPTs are reindexed first, as this affects how they are filled\n",
    "# Do forward fill first, then backward fill\n",
    "reliability_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "reliability_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "# Do backward fill first, then forward fill\n",
    "# reliability_cpt.fillna(method=\"bfill\", inplace=True)\n",
    "# reliability_cpt.fillna(method=\"ffill\", inplace=True)\n",
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save CPT Files as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "sinr_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/sinr_cpt.csv\".format(data_type))\n",
    "delay_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/delay_cpt.csv\".format(data_type))\n",
    "throughput_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/throughput_cpt.csv\".format(data_type))\n",
    "queueing_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/queueing_cpt.csv\".format(data_type))\n",
    "ber_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/ber_cpt.csv\".format(data_type))\n",
    "jitter_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/jitter_cpt.csv\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "incorrect_rcvd_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/incorrect_rcvd_cpt.csv\".format(data_type))\n",
    "delay_exceeded_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/delay_exceeded_cpt.csv\".format(data_type))\n",
    "queue_overflow_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/queue_overflow_cpt.csv\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "reliability_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}/reliability_cpt.csv\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/rel_cpt.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save CPT Files as Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "sinr_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/sinr_cpt.pkl\".format(data_type))\n",
    "delay_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/delay_cpt.pkl\".format(data_type))\n",
    "throughput_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/throughput_cpt.pkl\".format(data_type))\n",
    "queueing_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/queueing_cpt.pkl\".format(data_type))\n",
    "ber_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/ber_cpt.pkl\".format(data_type))\n",
    "jitter_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/jitter_cpt.pkl\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "incorrect_rcvd_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/incorrect_rcvd_cpt.pkl\".format(data_type))\n",
    "delay_exceeded_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/delay_exceeded_cpt.pkl\".format(data_type))\n",
    "queue_overflow_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/queue_overflow_cpt.pkl\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "reliability_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}/reliability_cpt.pkl\".format(data_type))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "reliability_cpt_non_normal = cpt_probs_freq(classes_df, child=\"Reliable\", parents=parents_1)\n",
    "reliability_cpt_non_normal.to_csv(\"/home/research-student/omnet-fanet/cpt/reliability_freq.csv\")\n",
    "reliability_cpt_non_normal.to_pickle(\"/home/research-student/omnet-fanet/cpt/reliability_freq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "reliability_cpt_non_normal = cpt_probs(classes_df, child=\"Reliable\", parents=parents_1)\n",
    "reliability_cpt_non_normal.to_csv(\"/home/research-student/omnet-fanet/cpt/reliability_basic.csv\")\n",
    "reliability_cpt_non_normal.to_pickle(\"/home/research-student/omnet-fanet/cpt/reliability_basic.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the 'basic' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes_df for later parts (if previous part not run)\n",
    "data_type = \"Downlink\"\n",
    "h_dist_num_classes = 25\n",
    "classes_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/classes_df_{}_hdist_{}_classes.h5\".format(data_type, h_dist_num_classes))\n",
    "\n",
    "delay_threshold = 0.04\n",
    "# First, discretise the values to classes\n",
    "h_dist_labels = ['vs','s','m','l','vl']\n",
    "height_labels = ['vs','s','m','l','vl']\n",
    "num_members_labels = ['vs','s','m','l','vl']\n",
    "sending_interval_labels = ['vs','s','m','l','vl']\n",
    "pkt_size_labels = ['vs','s','m','l','vl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_1)\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=parents_1)\n",
    "delay_exceeded_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "delay_exceeded_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=parents_1)\n",
    "\n",
    "parents_3 = [\"Incorrectly_Received\", \"Delay_Exceeded\", \"Queue_Overflow\"]\n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_3)\n",
    "reliability_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "reliability_cpt.rename(columns = {False:'False'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "data_type = \"Downlink\"\n",
    "incorrect_rcvd_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/incorrect_rcvd_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "delay_exceeded_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/delay_exceeded_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "queue_overflow_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/queue_overflow_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "reliability_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/reliability_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "\n",
    "# Save as pickle\n",
    "incorrect_rcvd_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/incorrect_rcvd_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "delay_exceeded_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/delay_exceeded_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "queue_overflow_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/queue_overflow_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "reliability_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_hdist_{}_classes/reliability_cpt.pkl\".format(data_type, h_dist_num_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed BN Incorrect Rcvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_trimmed = [\"H_Dist_Class\", \"Height_Class\"] \n",
    "incorrect_rcvd_trimmed_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_trimmed)\n",
    "data_type = \"Downlink\"\n",
    "incorrect_rcvd_trimmed_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic/incorrect_rcvd_trimmed_cpt.csv\".format(data_type))\n",
    "incorrect_rcvd_trimmed_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic/incorrect_rcvd_trimmed_cpt.pkl\".format(data_type))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Basic' BN model for single experiment (Single class for height, no. UAVs, sending interval and packet size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP50000_BPSK_6-5Mbps_8UAVs_additional_data_processed_downlink.h5\", '8_UAVs')\n",
    "# OPTIONAL: Use only a subset of the data.------------------------------------------------\n",
    "# # Let's split the dataset into 5 even sets\n",
    "# df_set_1 = dl_df.iloc[::5, :].copy()\n",
    "# df_set_2 = dl_df.iloc[1::5, :].copy()\n",
    "# df_set_3 = dl_df.iloc[2::5, :].copy()\n",
    "# df_set_4 = dl_df.iloc[3::5, :].copy()\n",
    "# df_set_5 = dl_df.iloc[4::5, :].copy()\n",
    "# dl_df = pd.concat([df_set_1, df_set_2, df_set_3, df_set_4]) # Use 80% of the data\n",
    "# # dl_df = pd.concat([df_set_1, df_set_3, df_set_5]) # Use 60% of the data\n",
    "# # dl_df = pd.concat([df_set_2, df_set_4]) # Use 60% of the data\n",
    "# # dl_df = df_set_3 # Use 20% of the data\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "delay_threshold = 0.04\n",
    "df = dl_df # NOTE: Change this to either dl_df / ul_df\n",
    "df = df[df['U2G_SINR'].notna()] # Filter out rows with missing crucial information\n",
    "classes_df = pd.DataFrame() # Created an empty df to store classes data to reduce size of df that need to work with\n",
    "# First, discretise the values to classes\n",
    "h_dist_range = 500\n",
    "h_dist_num_classes = 200\n",
    "h_dist_labels = [str(num) for num in np.arange(0,h_dist_num_classes)+1]\n",
    "# Independent vars\n",
    "h_dist_class_bnd = np.linspace(0, h_dist_range, h_dist_num_classes, endpoint=False).tolist()\n",
    "h_dist_class_bnd.append(h_dist_range+1)\n",
    "classes_df[\"H_Dist_Class\"] = pd.cut(df.U2G_H_Dist, h_dist_class_bnd, right=False, include_lowest=True, labels=h_dist_labels)\n",
    "classes_df[\"Reliable\"] = (df[\"Packet_State\"] == \"Reliable\")\n",
    "classes_df[\"Delay_Exceeded\"] = (df[\"Delay\"] >= delay_threshold)\n",
    "classes_df[\"Incorrectly_Received\"] = df[\"Incorrectly_Received\"]\n",
    "classes_df[\"Queue_Overflow\"] = df[\"Queue_Overflow\"]\n",
    "\n",
    "# Compute CPTs ---------------------------------------------------------------------------\n",
    "parents_1 = [\"H_Dist_Class\"] \n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_1)\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=parents_1)\n",
    "delay_exceeded_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "delay_exceeded_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=parents_1)\n",
    "\n",
    "parents_3 = [\"Incorrectly_Received\", \"Delay_Exceeded\", \"Queue_Overflow\"]\n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_3)\n",
    "reliability_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "reliability_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "\n",
    "# Save as CSV ----------------------------------------------------------------------------\n",
    "data_type = \"Downlink\"\n",
    "incorrect_rcvd_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/incorrect_rcvd_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "delay_exceeded_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/delay_exceeded_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "queue_overflow_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/queue_overflow_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "reliability_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/reliability_cpt.csv\".format(data_type, h_dist_num_classes))\n",
    "\n",
    "# Save as pickle\n",
    "incorrect_rcvd_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/incorrect_rcvd_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "delay_exceeded_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/delay_exceeded_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "queue_overflow_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/queue_overflow_cpt.pkl\".format(data_type, h_dist_num_classes))\n",
    "reliability_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_Basic_Exp1_hdist_{}_classes/reliability_cpt.pkl\".format(data_type, h_dist_num_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training v2 BN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes_df for later parts (if previous part not run)\n",
    "classes_df = pd.read_hdf(\"/media/research-student/One Touch/FANET Datasets/Dataset_NP10000_BPSK_6-5Mbps/classes_df_downlink.h5\", 'Downlink')\n",
    "\n",
    "delay_threshold = 0.04\n",
    "# First, discretise the values to classes\n",
    "h_dist_labels = ['vs','s','m','l','vl']\n",
    "height_labels = ['vs','s','m','l','vl']\n",
    "num_members_labels = ['vs','s','m','l','vl']\n",
    "sending_interval_labels = ['vs','s','m','l','vl']\n",
    "pkt_size_labels = ['vs','s','m','l','vl']\n",
    "sinr_labels = ['vs','s','m','l','vl']\n",
    "delay_labels = ['vs','s','m','l','vl']\n",
    "ber_labels = ['vs','s','m','l','vl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinr_cpt = cpt_probs(classes_df, child=\"SINR_Class\", parents=[\"H_Dist_Class\", \"Height_Class\"])\n",
    "ber_cpt = cpt_probs(classes_df, child=\"BER_Class\", parents=[\"SINR_Class\"])\n",
    "delay_cpt = cpt_probs(classes_df, child=\"Delay_Class\", parents=[\"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\", \"BER_Class\"])\n",
    "\n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=[\"BER_Class\"])\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=[\"Delay_Class\"])\n",
    "delay_exceeded_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "delay_exceeded_cpt.rename(columns = {False:'False'}, inplace = True)\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=[\"Delay_Class\"])\n",
    "\n",
    "parents_reliability = [\"Incorrectly_Received\", \"Delay_Exceeded\", \"Queue_Overflow\"]\n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_reliability)\n",
    "reliability_cpt.rename(columns = {True:'True'}, inplace = True)\n",
    "reliability_cpt.rename(columns = {False:'False'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "data_type = \"Downlink\"\n",
    "sinr_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/sinr_cpt.csv\".format(data_type))\n",
    "ber_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/ber_cpt.csv\".format(data_type))\n",
    "delay_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/delay_cpt.csv\".format(data_type))\n",
    "incorrect_rcvd_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/incorrect_rcvd_cpt.csv\".format(data_type))\n",
    "delay_exceeded_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/delay_exceeded_cpt.csv\".format(data_type))\n",
    "queue_overflow_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/queue_overflow_cpt.csv\".format(data_type))\n",
    "reliability_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/{}_v2/reliability_cpt.csv\".format(data_type))\n",
    "\n",
    "# Save as pickle\n",
    "sinr_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/sinr_cpt.pkl\".format(data_type))\n",
    "ber_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/ber_cpt.pkl\".format(data_type))\n",
    "delay_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/delay_cpt.pkl\".format(data_type))\n",
    "incorrect_rcvd_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/incorrect_rcvd_cpt.pkl\".format(data_type))\n",
    "delay_exceeded_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/delay_exceeded_cpt.pkl\".format(data_type))\n",
    "queue_overflow_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/queue_overflow_cpt.pkl\".format(data_type))\n",
    "reliability_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/{}_v2/reliability_cpt.pkl\".format(data_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
