{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries\n",
    "Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation \n",
    "import networkx as nx # for drawing graphs\n",
    "import matplotlib.pyplot as plt # for drawing graphs\n",
    "import os, sys, glob, math\n",
    "# for creating Bayesian Belief Networks (BBN)\n",
    "from pybbn.graph.dag import Bbn\n",
    "from pybbn.graph.edge import Edge, EdgeType\n",
    "from pybbn.graph.jointree import EvidenceBuilder\n",
    "from pybbn.graph.node import BbnNode\n",
    "from pybbn.graph.variable import Variable\n",
    "from pybbn.pptc.inferencecontroller import InferenceController\n",
    "\n",
    "def process_micro_sim(file_list):\n",
    "    '''\n",
    "    Function to process the CSV files generated by each micro-simulation\n",
    "    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)\n",
    "    Output: concatenates the raw data to UL and DL dataframes\n",
    "    '''\n",
    "    uavs_rx_df_list = [] # List to store all df for UAVs Rx app\n",
    "    uavs_tx_df_list = [] # List to store all df for UAVs Tx app\n",
    "    uavs_mon_df_list = [] # List to store all df for UAVs monitor mode captures\n",
    "    # Dtypes for different files\n",
    "    tx_dtype = {'TxTime': float, 'Packet_Name': str, 'Packet_Seq': int, 'Bytes': int, 'Dest_Addr': str, 'Dest_Port': int}\n",
    "    rx_dtype = {'RxTime': float, 'TxTime': float, 'Packet_Name': str, 'Bytes': int, 'RSSI': str, 'SINR': float, 'Src_Addr': str, 'Src_Port': int, 'Dest_Addr': str, 'Dest_Port': int,\t'Hop_Count': int, 'Delay': float, 'Distance': float}\n",
    "    mon_dtype = {'RxTime': float, 'PkCreationTime': object, 'Packet_Name': str, 'Bytes': int, 'RSSI': str, 'SINR': float, 'Delay': float, 'Distance': float, 'HasError': int}\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            if ('_GCS-' in file) and ('-Tx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is the GCS Tx file, recording the sent packets from GCS\n",
    "                gcs_tx_df = pd.read_csv(file)\n",
    "            elif ('_GW-' in file) and ('-Rx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is the gateway Rx file, let's get the information of packets received from GCS\n",
    "                gw_rx_df = pd.read_csv(file)\n",
    "                uavs_rx_df_list.append(gw_rx_df)\n",
    "            elif ('_UAV-' in file) and ('-Rx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is a UAV Rx file. To concatenate all such files into a single df\n",
    "                uav_rx_df = pd.read_csv(file)\n",
    "                # uav_cnc_data = uav_rx_df[\"CNCData\" in uav_rx_df[\"Packet_Name\"]] # Get the CNC Data received by this UAV\n",
    "                # uav_cnc_reliable = uav_cnc_data[uav_cnc_data[\"Delay\"] < delay_th] # Get the CNCData packets received reliably by this UAV (delay < 1ms)\n",
    "                uavs_rx_df_list.append(uav_rx_df) # Append to list for concatenation later\n",
    "            elif ('_GCS-' in file) and ('-Rx' in file):\n",
    "                # UPLINK\n",
    "                # This is a GCS Rx file, recording packets received from UAVs-\n",
    "                gcs_rx_df = pd.read_csv(file)\n",
    "            elif ('_GW-' in file) and ('-Tx' in file):\n",
    "                # UPLINK\n",
    "                # This is the gateway Tx file, recording packet transmissions to GCS from gateway\n",
    "                gw_tx_df = pd.read_csv(file)\n",
    "                uavs_tx_df_list.append(gw_tx_df) # Append to list for concatenation later\n",
    "            elif ('_UAV-' in file) and ('-Tx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is a UAV Rx file. To concatenate all such files into a single df\n",
    "                uav_tx_df = pd.read_csv(file)\n",
    "                uavs_tx_df_list.append(uav_tx_df) # Append to list for concatenation later\n",
    "            elif ('_GCS-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for GCS\n",
    "                gcs_mon_df = pd.read_csv(file)\n",
    "                gcs_mon_df[\"Addr\"] = \"192.168.0.1\"\n",
    "            elif ('_GW-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for gateway\n",
    "                gw_mon_df = pd.read_csv(file)\n",
    "                gw_mon_df[\"Addr\"] = \"192.168.0.2\"\n",
    "                uavs_mon_df_list.append(gw_mon_df)\n",
    "            elif ('_UAV-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for GCS\n",
    "                uav_mon_df = pd.read_csv(file)\n",
    "                uav_index = file.split(\"_\")[-1].split(\"-\")[1]\n",
    "                uav_mon_df[\"Addr\"] = \"192.168.0.{}\".format(int(uav_index) + 3)\n",
    "                uavs_mon_df_list.append(uav_mon_df)\n",
    "            else:\n",
    "                # This file type is not handled, pass \n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(file)\n",
    "            print(e)\n",
    "        \n",
    "    if uavs_rx_df_list:\n",
    "        uavs_rx_df = pd.concat(uavs_rx_df_list, ignore_index = True)\n",
    "    else:\n",
    "        uavs_rx_df = None\n",
    "\n",
    "    if uavs_tx_df_list:\n",
    "        uavs_tx_df = pd.concat(uavs_tx_df_list, ignore_index = True)\n",
    "    else:\n",
    "        uavs_tx_df = None\n",
    "\n",
    "    if uavs_mon_df_list:\n",
    "        uavs_mon_df = pd.concat(uavs_mon_df_list, ignore_index = True)\n",
    "    else:\n",
    "        uavs_mon_df = None\n",
    "\n",
    "    # The DL data is in uavs_rx_df\n",
    "    dl_df = uavs_rx_df\n",
    "    # The UL data is in gcs_rx_df\n",
    "    ul_df = gcs_rx_df\n",
    "\n",
    "    return dl_df, ul_df, gcs_tx_df, uavs_tx_df, gcs_mon_df, uavs_mon_df, gw_mon_df\n",
    "\n",
    "def process_missing_data(tx_df, rx_df, mon_df, mode='downlink'):\n",
    "    '''\n",
    "    This function is to fill in missing data in rx_df with data from mon_df\n",
    "    tx_df contains the list of all transmitted network packets (UL/DL)\n",
    "    rx_df should only contain the captures of packets received successfully (regardless of delay)\n",
    "    mon_df contains the monitor mode captures, and contains information of packets not received successfully\n",
    "    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.\n",
    "    '''\n",
    "    # Firstly, let's mark all the rows in rx_df as having been received correctly\n",
    "    rx_df[\"Has_Error\"] = 0\n",
    "    for index, row in tx_df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "\n",
    "        # Let's also use this function to do process_swarm_distance\n",
    "        # swarm_distances = gw_mon_df.loc[(gw_mon_df[\"Packet_Name\"] == packetName) & (gw_mon_df[\"Distance\"] != inter_uav_dist), \"Distance\"].values\n",
    "        # if swarm_distances.size > 0:\n",
    "        #     swarm_distance = swarm_distances[0]\n",
    "        # else:\n",
    "        #     swarm_distance = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName), \"Distance\"].values # If packet not found in mon_df, just use back original Distance data\n",
    "\n",
    "        # First, check if the packet is received successfully in rx_df\n",
    "        if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "            dest_addr = row[\"Dest_Addr\"]\n",
    "            # If not received, find the data in mon_df and add it to rx_df\n",
    "            # First choice: Try to find the packet from the intended node's monitor df, check if it failed at the last hop\n",
    "            if mode == 'downlink':\n",
    "                cap_pks = mon_df.loc[(mon_df[\"Packet_Name\"] == packetName) & (mon_df[\"Addr\"] == dest_addr) & (mon_df[\"HasError\"] == 1) & (mon_df[\"Distance\"] == '4')] # The magic number 4 here is the inter-UAV distance\n",
    "            elif mode == 'uplink':\n",
    "                cap_pks = mon_df.loc[(mon_df[\"Packet_Name\"] == packetName) & (mon_df[\"Addr\"] == dest_addr) & (mon_df[\"HasError\"] == 1)] # TODO: Discriminate whether packet is from member or GW\n",
    "            # If not there, check the gateway, maybe it failed there\n",
    "            if cap_pks.empty:\n",
    "                cap_pks = mon_df.loc[(mon_df[\"Packet_Name\"] == packetName) & (mon_df[\"Addr\"] == \"192.168.0.2\")]\n",
    "            # If it fails at the intended UAV or the GW, only we record the failed packet\n",
    "            if not cap_pks.empty:\n",
    "                # Find the packet with the max SINR in cap_pks and use it to fill the missing data\n",
    "                err_pk = cap_pks.loc[cap_pks[\"SINR\"].idxmax()]\n",
    "                err_pk_new_dict = {'RxTime': err_pk['RxTime'],'TxTime': err_pk['PkCreationTime'],'Packet_Name': err_pk['Packet_Name'],'Bytes': err_pk['Bytes'],'RSSI': err_pk['RSSI'],'SINR': err_pk['SINR'],'Src_Addr': \"-\",'Src_Port': \"-\",'Dest_Addr': row['Dest_Addr'],'Dest_Port': row['Dest_Port'],'Hop_Count': \"-\",'Delay': err_pk['Delay'],'Distance': err_pk['Distance'],'Has_Error': 1}\n",
    "                err_pk_new_df = pd.DataFrame([err_pk_new_dict])\n",
    "                rx_df = pd.concat([rx_df,err_pk_new_df], ignore_index = True)\n",
    "        # else:\n",
    "        #     rx_df.loc[(rx_df[\"Packet_Name\"] == packetName), \"Swarm_Distance\"] = swarm_distance\n",
    "\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_throughput(df, timeDiv):\n",
    "    '''\n",
    "    Function to calculate throughput data for a DataFrame\n",
    "    timeDiv is the time division to use for calculating the throughput\n",
    "    '''\n",
    "    maxTime = math.ceil(float(df[\"RxTime\"].max()))\n",
    "    for i in range(math.ceil(maxTime / timeDiv)):\n",
    "        df_in_range = df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)) & (df[\"Has_Error\"] == 0)]\n",
    "        totalBytes = df_in_range[\"Bytes\"].sum()\n",
    "        throughput = totalBytes / timeDiv\n",
    "        df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)), \"Throughput\"] = throughput\n",
    "    return df\n",
    "\n",
    "def process_swarm_distance(df, mon_df):\n",
    "    '''\n",
    "    Function to fill in the swarm distance from mon_df\n",
    "    For each packet in df, finds the packet with same name in mon_df but with distance != inter_uav_dist\n",
    "    Use mon_df = gw_mon_df for CNCData, and gcs_mon_df for UAVData\n",
    "    '''\n",
    "    for index, row in df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"]\n",
    "        inter_uav_distance = row[\"Inter_UAV_Distance\"]\n",
    "        swarm_distances = mon_df.loc[(mon_df[\"Packet_Name\"] == packetName) & (mon_df[\"Distance\"] != inter_uav_distance), \"Distance\"].values\n",
    "        if swarm_distances.size > 0:\n",
    "            swarm_distance = swarm_distances[0]\n",
    "        else:\n",
    "            swarm_distance = row[\"Distance\"] # If packet not found in mon_df, just use back original Distance data\n",
    "        df.loc[index, \"Swarm_Distance\"] = swarm_distance\n",
    "        height = row[\"Height\"] - 1\n",
    "        df.loc[index, \"Horizontal_Distance\"] = math.sqrt(swarm_distance**2 - height**2)\n",
    "    return df\n",
    "\n",
    "def process_sim_data(sim_root_path, delay_threshold):\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    # Get list of \"unique\" scenarios\n",
    "    scenario_list = [csv.split('/')[-1][0:-18] for csv in glob.glob(sim_root_path + \"/*[[0]]-Tx.csv\")]\n",
    "\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    # RxTime\tTxTime\tPacket_Name\tBytes\tRSSI\tSINR\tSrc_Addr\tSrc_Port\tDest_Addr\tDest_Port\tHop_Count\tDelay\tThroughput\tDistance\n",
    "\n",
    "    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','Src_Addr','Src_Port','Dest_Addr','Dest_Port','Hop_Count','Delay','Distance','Swarm_Distance','Horizontal_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval','Has_Error','Delay_Exceeded','Reliable']) # Downlink dataframe\n",
    "    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','Src_Addr','Src_Port','Dest_Addr','Dest_Port','Hop_Count','Delay','Distance','Swarm_Distance','Horizontal_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval','Has_Error','Delay_Exceeded','Reliable']) # Uplink dataframe\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    for scenario in scenario_list:\n",
    "        scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "        scenario_params = scenario.split('_')\n",
    "        num_member = int(scenario_params[0].split('-')[-1])\n",
    "        inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "        height = int(scenario_params[2].split('-')[-1])\n",
    "        swarm_hor_distance = int(scenario_params[3].split('-')[-1]) # Horizontal Swarm Distance\n",
    "        swarm_distance = math.sqrt(int(height)**2 + swarm_hor_distance**2)\n",
    "        packet_size = int(scenario_params[4].split('-')[-1])\n",
    "        sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "        dl_data, ul_data, dl_tx_df, ul_tx_df, gcs_mon_df, uavs_mon_df, gw_mon_df = process_micro_sim(scenario_files)\n",
    "        dl_data = process_missing_data(dl_tx_df, dl_data, uavs_mon_df, mode='downlink')\n",
    "        # ul_data = process_missing_data(ul_tx_df, ul_data, gcs_mon_df)\n",
    "        if dl_data is not None:\n",
    "            dl_data[\"Height\"] = height\n",
    "            # dl_data[\"Swarm_Distance\"] = swarm_distance\n",
    "            dl_data[\"Horizontal_Distance\"] = swarm_hor_distance\n",
    "            dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            dl_data[\"Num_Members\"] = num_member\n",
    "            # dl_data[\"Packet_Size\"] = packet_size\n",
    "            dl_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            dl_data[\"Delay_Exceeded\"] = 0\n",
    "            dl_data.loc[dl_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            dl_data[\"Reliable\"] = 0\n",
    "            dl_data.loc[(dl_data[\"Delay_Exceeded\"] == 0) & (dl_data[\"Has_Error\"] == 0), \"Reliable\"] = 1\n",
    "            dl_data = process_throughput(dl_data, 1)\n",
    "            dl_data = process_swarm_distance(dl_data, gw_mon_df)\n",
    "            dl_df = pd.concat([dl_df, dl_data], ignore_index=True)\n",
    "        if ul_data is not None:\n",
    "            ul_data[\"Height\"] = height\n",
    "            ul_data[\"Swarm_Distance\"] = swarm_distance\n",
    "            ul_data[\"Horizontal_Distance\"] = swarm_hor_distance\n",
    "            ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            ul_data[\"Num_Members\"] = num_member\n",
    "            # ul_data[\"Packet_Size\"] = packet_size\n",
    "            ul_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            # ul_data[\"Delay_Exceeded\"] = 0\n",
    "            # ul_data.loc[ul_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            # ul_data[\"Reliable\"] = 0\n",
    "            # ul_data.loc[(ul_data[\"Delay_Exceeded\"] == 0) & (ul_data[\"Has_Error\"] == 0), \"Reliable\"] = 1\n",
    "            ul_df = pd.concat([ul_df, ul_data], ignore_index=True)\n",
    "    \n",
    "    return dl_df, ul_df\n",
    "\n",
    "# This function helps to calculate probability distribution, which goes into BBN (note, can handle up to 2 parents)\n",
    "def cpt_probs(df, child, parents):\n",
    "    try:\n",
    "        # dependencies_arr = [pd.Categorical(df[parent],categories=df[parent].cat.categories.tolist()) for parent in parents]\n",
    "        dependencies_arr = [df[parent] for parent in parents]\n",
    "        cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()\n",
    "        return cpt\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None \n",
    "\n",
    "# Define a function for printing marginal probabilities\n",
    "def print_probs(join_tree):\n",
    "    for node in join_tree.get_bbn_nodes():\n",
    "        potential = join_tree.get_bbn_potential(node)\n",
    "        print(\"Node:\", node)\n",
    "        print(\"Values:\")\n",
    "        print(potential)\n",
    "        print('----------------')\n",
    "\n",
    "# To add evidence of events that happened so probability distribution can be recalculated\n",
    "def evidence(join_tree, nod, cat, val):\n",
    "    ev = EvidenceBuilder() \\\n",
    "    .with_node(join_tree.get_bbn_node_by_name(nod)) \\\n",
    "    .with_evidence(cat, val) \\\n",
    "    .build()\n",
    "    join_tree.set_observation(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000003?line=1'>2</a>\u001b[0m sim_root_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/research-student/omnetpp_sim_results/FANET_Corr2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000003?line=2'>3</a>\u001b[0m delay_threshold \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000003?line=3'>4</a>\u001b[0m dl_df2, ul_df2 \u001b[39m=\u001b[39m process_sim_data(sim_root_path, delay_threshold\u001b[39m=\u001b[39;49mdelay_threshold)\n",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb Cell 2'\u001b[0m in \u001b[0;36mprocess_sim_data\u001b[0;34m(sim_root_path, delay_threshold)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=192'>193</a>\u001b[0m sending_interval \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(scenario_params[\u001b[39m5\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=193'>194</a>\u001b[0m dl_data, ul_data, dl_tx_df, ul_tx_df, gcs_mon_df, uavs_mon_df, gw_mon_df \u001b[39m=\u001b[39m process_micro_sim(scenario_files)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=194'>195</a>\u001b[0m dl_data \u001b[39m=\u001b[39m process_missing_data(dl_tx_df, dl_data, uavs_mon_df, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdownlink\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=195'>196</a>\u001b[0m \u001b[39m# ul_data = process_missing_data(ul_tx_df, ul_data, gcs_mon_df)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=196'>197</a>\u001b[0m \u001b[39mif\u001b[39;00m dl_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb Cell 2'\u001b[0m in \u001b[0;36mprocess_missing_data\u001b[0;34m(tx_df, rx_df, mon_df, mode)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=122'>123</a>\u001b[0m \u001b[39m# If not there, check the gateway, maybe it failed there\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=123'>124</a>\u001b[0m \u001b[39mif\u001b[39;00m cap_pks\u001b[39m.\u001b[39mempty:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=124'>125</a>\u001b[0m     cap_pks \u001b[39m=\u001b[39m mon_df\u001b[39m.\u001b[39mloc[(mon_df[\u001b[39m\"\u001b[39;49m\u001b[39mPacket_Name\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m packetName) \u001b[39m&\u001b[39m (mon_df[\u001b[39m\"\u001b[39m\u001b[39mAddr\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m192.168.0.2\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=125'>126</a>\u001b[0m \u001b[39m# If it fails at the intended UAV or the GW, only we record the failed packet\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=126'>127</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cap_pks\u001b[39m.\u001b[39mempty:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000001?line=127'>128</a>\u001b[0m     \u001b[39m# Find the packet with the max SINR in cap_pks and use it to fill the missing data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5620\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   5622\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 5623\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   5625\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    282\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's get the data\n",
    "sim_root_path = \"/home/research-student/omnetpp_sim_results/Test\"\n",
    "delay_threshold = 1\n",
    "dl_df, ul_df = process_sim_data(sim_root_path, delay_threshold=delay_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF to CSV\n",
    "dl_df.to_csv(os.path.join(sim_root_path,\"FANET_downlink_raw.csv\"), index=False)\n",
    "ul_df.to_csv(os.path.join(sim_root_path,\"FANET_uplink_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, discretise the values to classes\n",
    "dl_df[\"H_Dist_Class\"] = pd.cut(dl_df.Horizontal_Distance, bins=5, labels=['vs','s','m','l','vl'])\n",
    "dl_df[\"Height_Class\"] = pd.cut(dl_df.Height, bins=3, labels=['s','m','l'])\n",
    "dl_df[\"Num_Members_Class\"] = pd.cut(dl_df.Num_Members, bins=3, labels=['s','m','l'])\n",
    "dl_df[\"Sending_Interval_Class\"] = pd.cut(dl_df.Sending_Interval, bins=3, labels=['s','m','l'])\n",
    "dl_df[\"Packet_Size_Class\"] = pd.cut(dl_df.Bytes, bins=3, labels=['s','m','l'])\n",
    "\n",
    "dl_df[\"SINR_Class\"] = pd.qcut(dl_df.SINR, q=3, labels=['s','m','l'])\n",
    "dl_df[\"Delay_Class\"] = pd.qcut(dl_df.Delay, q=3, labels=['s','m','l'])\n",
    "dl_df[\"Throughput_Class\"] = pd.qcut(dl_df.Throughput, q=2, labels=['s','l'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretising for single class\n",
    "dl_df[\"H_Dist_Class\"] = 'vs'\n",
    "dl_df[\"Height_Class\"] = 's'\n",
    "dl_df[\"Num_Members_Class\"] = 's'\n",
    "dl_df[\"Sending_Interval_Class\"] = 's'\n",
    "dl_df[\"Packet_Size_Class\"] = 's'\n",
    "\n",
    "dl_df[\"SINR_Class\"] = pd.qcut(dl_df.SINR, q=3, labels=['s','m','l'])\n",
    "dl_df[\"Delay_Class\"] = pd.qcut(dl_df.Delay, q=3, labels=['s','m','l'])\n",
    "dl_df[\"Throughput_Class\"] = pd.qcut(dl_df.Throughput, q=3, labels=['s','l'], duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probabilities table for each second layer class\n",
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"]\n",
    "sinr_cpt = cpt_probs(dl_df, child=\"SINR_Class\", parents=parents_1)\n",
    "delay_cpt = cpt_probs(dl_df, child=\"Delay_Class\", parents=parents_1)\n",
    "throughput_cpt = cpt_probs(dl_df, child=\"Throughput_Class\", parents=parents_1)\n",
    "parents_2 = [\"SINR_Class\", \"Delay_Class\", \"Throughput_Class\"]\n",
    "reliability_cpt = cpt_probs(dl_df, child=\"Reliable\", parents=parents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nodes by using our earlier function to automatically calculate probabilities\n",
    "# H_Dist = BbnNode(Variable(0, 'H_Dist', ['vs','s','m','l','vl']), [0.2,0.2,0.2,0.2,0.2])\n",
    "# Height = BbnNode(Variable(1, 'Height', ['s','m','l']), [1/3, 1/3, 1/3] )\n",
    "# Num_Members = BbnNode(Variable(2, 'Num_Members', ['s','m','l']), [1/3, 1/3, 1/3])\n",
    "# Sending_Interval = BbnNode(Variable(3, 'Sending_Interval', ['s','m','l']), [1/3, 1/3, 1/3])\n",
    "# Packet_Size = BbnNode(Variable(4, 'Packet_Size', ['s','m','l']), [1/3, 1/3, 1/3])\n",
    "# SINR = BbnNode(Variable(5, 'SINR', ['s','m','l']), sinr_cpt)\n",
    "# Delay = BbnNode(Variable(6, 'Delay', ['s','m','l']), delay_cpt)\n",
    "# Throughput = BbnNode(Variable(7, 'Throughput', ['s','l']), throughput_cpt)\n",
    "# Reliability = BbnNode(Variable(8, \"Reliability\", ['0', '1']), reliability_cpt)\n",
    "\n",
    "H_Dist = BbnNode(Variable(0, 'H_Dist', ['vs']), [1])\n",
    "Height = BbnNode(Variable(1, 'Height', ['s']), [1] )\n",
    "Num_Members = BbnNode(Variable(2, 'Num_Members', ['s']), [1])\n",
    "Sending_Interval = BbnNode(Variable(3, 'Sending_Interval', ['s']), [1])\n",
    "Packet_Size = BbnNode(Variable(4, 'Packet_Size', ['s']), [1])\n",
    "SINR = BbnNode(Variable(5, 'SINR', ['s','m','l']), sinr_cpt)\n",
    "Delay = BbnNode(Variable(6, 'Delay', ['s','m','l']), delay_cpt)\n",
    "Throughput = BbnNode(Variable(7, 'Throughput', ['s','l']), throughput_cpt)\n",
    "Reliability = BbnNode(Variable(8, \"Reliability\", ['0', '1']), reliability_cpt)\n",
    "\n",
    "# Create Network\n",
    "bbn = Bbn() \\\n",
    "    .add_node(H_Dist) \\\n",
    "    .add_node(Height) \\\n",
    "    .add_node(Num_Members) \\\n",
    "    .add_node(Sending_Interval) \\\n",
    "    .add_node(Packet_Size) \\\n",
    "    .add_node(SINR) \\\n",
    "    .add_node(Delay) \\\n",
    "    .add_node(Throughput) \\\n",
    "    .add_node(Reliability) \\\n",
    "    .add_edge(Edge(H_Dist, SINR, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Height, SINR, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Num_Members, SINR, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Sending_Interval, SINR, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Packet_Size, SINR, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(H_Dist, Delay, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Height, Delay, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Num_Members, Delay, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Sending_Interval, Delay, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Packet_Size, Delay, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(H_Dist, Throughput, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Height, Throughput, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Num_Members, Throughput, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Sending_Interval, Throughput, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Packet_Size, Throughput, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(SINR, Reliability, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Delay, Reliability, EdgeType.DIRECTED)) \\\n",
    "    .add_edge(Edge(Throughput, Reliability, EdgeType.DIRECTED)) \\\n",
    "\n",
    "\n",
    "# Convert the BBN to a join tree\n",
    "join_tree = InferenceController.apply(bbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_bn_train.ipynb#ch0000008?line=0'>1</a>\u001b[0m print_probs(join_tree)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_probs' is not defined"
     ]
    }
   ],
   "source": [
    "print_probs(join_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 1|Height|s\n",
      "Values:\n",
      "1=s|1.00000\n",
      "----------------\n",
      "Node: 2|Num_Members|s\n",
      "Values:\n",
      "2=s|1.00000\n",
      "----------------\n",
      "Node: 3|Sending_Interval|s\n",
      "Values:\n",
      "3=s|1.00000\n",
      "----------------\n",
      "Node: 4|Packet_Size|s\n",
      "Values:\n",
      "4=s|1.00000\n",
      "----------------\n",
      "Node: 5|SINR|s,m,l\n",
      "Values:\n",
      "5=s|0.32546\n",
      "5=m|0.33757\n",
      "5=l|0.33697\n",
      "----------------\n",
      "Node: 6|Delay|s,m,l\n",
      "Values:\n",
      "6=s|0.35639\n",
      "6=m|0.35241\n",
      "6=l|0.29119\n",
      "----------------\n",
      "Node: 7|Throughput|s,l\n",
      "Values:\n",
      "7=s|0.90959\n",
      "7=l|0.09041\n",
      "----------------\n",
      "Node: 0|H_Dist|vs\n",
      "Values:\n",
      "0=vs|1.00000\n",
      "----------------\n",
      "Node: 8|Reliability|0,1\n",
      "Values:\n",
      "8=0|0.00000\n",
      "8=1|1.00000\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Inferencing with evidence and printing probabilities\n",
    "# evidence(join_tree, \"H_Dist\", 'm', 1.0)\n",
    "\n",
    "evidence(join_tree, \"Height\", 's', 1.0)\n",
    "evidence(join_tree, \"Num_Members\", 's', 1.0)\n",
    "evidence(join_tree, \"Sending_Interval\", 's', 1.0)\n",
    "evidence(join_tree, \"Packet_Size\", 's', 1.0)\n",
    "evidence(join_tree, \"Reliability\", '1', 1.0)\n",
    "print_probs(join_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view data / variables\n",
    "sinr_cpt\n",
    "dependencies_arr = [dl_df[parent] for parent in parents_1]\n",
    "pd.crosstab(dependencies_arr, dl_df[\"SINR_Class\"], rownames=parents_1, colnames=[\"SINR_Class\"], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_df[\"H_Dist_Class\"].cat.categories.tolist()\n",
    "pd.Categorical(dl_df[\"H_Dist_Class\"], categories=dl_df[\"H_Dist_Class\"].cat.categories.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
