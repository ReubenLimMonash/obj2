{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import os, sys, glob, math\n",
    "import time\n",
    "\n",
    "def rssi_to_np(rssi):\n",
    "    # Function to convert rssi data from string (e.g. \"435 pW\") to exp (435e-12)\n",
    "    rssi_num = np.zeros(rssi.shape)\n",
    "    index = 0\n",
    "    rssi_iter = rssi.to_pandas()\n",
    "    for r in rssi_iter:\n",
    "        num = r[0:-2]\n",
    "        expn = r[-2:]\n",
    "        # print(num)\n",
    "        # print(expn)\n",
    "        if expn == \" W\":\n",
    "            # print(num)\n",
    "            # print(index)\n",
    "            rssi_num[index] = float(num)\n",
    "        elif expn == \"mW\":\n",
    "            rssi_num[index] = float(num) * 1e-3\n",
    "        elif expn == \"uW\":\n",
    "            rssi_num[index] = float(num) * 1e-6\n",
    "        elif expn == \"nW\":\n",
    "            rssi_num[index] = float(num) * 1e-9\n",
    "        elif expn == \"pW\":\n",
    "            rssi_num[index] = float(num) * 1e-12\n",
    "        else:\n",
    "            print(expn)\n",
    "            raise ValueError(\"Unhandled unit prefix\")\n",
    "        index += 1\n",
    "    return rssi_num\n",
    "\n",
    "def compile_micro_sim_data(file_list):\n",
    "    '''\n",
    "    Function to compile data from the CSV files generated by each micro-simulation\n",
    "    Update: To specifically return the rx_df, tx_df, mon_df and pd_df in lists, so that specific dfs can be accessed (instead of aggregating UAV dfs)\n",
    "    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)\n",
    "    Output: concatenates the raw data to UL and DL dataframes\n",
    "    '''\n",
    "\n",
    "    # Let's get the GCS dfs ===============================================================\n",
    "    gcs_rx_file = [file for file in file_list if (('_GCS-' in file) and ('-Rx' in file))]\n",
    "    gcs_tx_file = [file for file in file_list if (('_GCS-' in file) and ('-Tx' in file))]\n",
    "    gcs_mon_file = [file for file in file_list if (('_GCS-' in file) and ('Wlan' in file))]\n",
    "    gcs_pd_file = [file for file in file_list if (('_GCS-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gcs_rx_file) > 0:\n",
    "        gcs_rx_df = cudf.read_csv(gcs_rx_file[0])\n",
    "    else:\n",
    "        print(\"GCS RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_tx_file) > 0:\n",
    "        gcs_tx_df = cudf.read_csv(gcs_tx_file[0])\n",
    "    else:\n",
    "        print(\"GCS TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_pd_file) > 0:\n",
    "        gcs_pd_df = cudf.read_csv(gcs_pd_file[0])\n",
    "    else:\n",
    "        print(\"GCS PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_mon_file) > 0:\n",
    "        gcs_mon_df = cudf.read_csv(gcs_mon_file[0]) # Mon file is optional\n",
    "        gcs_mon_df[\"Addr\"] = \"192.168.0.1\"\n",
    "    else: \n",
    "        gcs_mon_df = None\n",
    "\n",
    "    # Let's get the GW dfs ===============================================================\n",
    "    gw_rx_file = [file for file in file_list if (('_GW-' in file) and ('-Rx' in file))]\n",
    "    gw_tx_file = [file for file in file_list if (('_GW-' in file) and ('-Tx' in file))]\n",
    "    gw_mon_file = [file for file in file_list if (('_GW-' in file) and ('Wlan' in file))]\n",
    "    gw_pd_file = [file for file in file_list if (('_GW-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gw_rx_file) > 0:\n",
    "        gw_rx_df = cudf.read_csv(gw_rx_file[0])\n",
    "    else:\n",
    "        print(\"GW RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_tx_file) > 0:\n",
    "        gw_tx_df = cudf.read_csv(gw_tx_file[0])\n",
    "    else:\n",
    "        print(\"GW TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_pd_file) > 0:\n",
    "        gw_pd_df = cudf.read_csv(gw_pd_file[0])\n",
    "    else:\n",
    "        print(\"GW PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_mon_file) > 0:\n",
    "        gw_mon_df = cudf.read_csv(gw_mon_file[0]) # Mon file is optional\n",
    "        gw_mon_df[\"Addr\"] = \"192.168.0.2\"\n",
    "    else:\n",
    "        gw_mon_df = None\n",
    "\n",
    "    # Let's get the UAVs dfs ===============================================================\n",
    "    uavs_rx_df_list = []\n",
    "    uavs_tx_df_list = []\n",
    "    uavs_mon_df_list = []\n",
    "    uavs_pd_df_list = []\n",
    "    uav_rx_files = [file for file in file_list if (('_UAV-' in file) and ('-Rx' in file))]\n",
    "    uav_tx_files = [file for file in file_list if (('_UAV-' in file) and ('-Tx' in file))]\n",
    "    uav_mon_files = [file for file in file_list if (('_UAV-' in file) and ('Wlan' in file))]\n",
    "    uav_pd_files = [file for file in file_list if (('_UAV-' in file) and ('PacketDrop' in file))]\n",
    "    uav_rx_files.sort()\n",
    "    uav_tx_files.sort()\n",
    "    uav_mon_files.sort()\n",
    "    uav_pd_files.sort()\n",
    "    if len(uav_rx_files) > 0:\n",
    "        for uav_rx_file in uav_rx_files:\n",
    "            uavs_rx_df_list.append(cudf.read_csv(uav_rx_file))\n",
    "    else:\n",
    "        print(\"UAV RX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_tx_files) > 0:\n",
    "        for uav_tx_file in uav_tx_files:\n",
    "            uavs_tx_df_list.append(cudf.read_csv(uav_tx_file))\n",
    "    else:\n",
    "        print(\"UAV TX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_pd_files) > 0:\n",
    "        for uav_pd_file in uav_pd_files:\n",
    "            uavs_pd_df_list.append(cudf.read_csv(uav_pd_file))\n",
    "    else:\n",
    "        print(\"UAV PD File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_mon_files) > 0: # UAV mon files are optional now\n",
    "        uav_member_index = 3\n",
    "        for uav_mon_file in uav_mon_files:\n",
    "            uav_mon_df = cudf.read_csv(uav_mon_file)\n",
    "            uav_mon_df[\"Addr\"] = \"192.168.0.\" + str(uav_member_index)\n",
    "            uavs_mon_df_list.append(uav_mon_df)\n",
    "            uav_member_index += 1\n",
    "    else:\n",
    "        uavs_mon_df_list = []\n",
    "\n",
    "    rx_df_list = [gcs_rx_df, gw_rx_df] + uavs_rx_df_list\n",
    "    tx_df_list = [gcs_tx_df, gw_tx_df] + uavs_tx_df_list\n",
    "    pd_df_list = [gcs_pd_df, gw_pd_df] + uavs_pd_df_list\n",
    "    mon_df_list = [gcs_mon_df, gw_mon_df] + uavs_mon_df_list\n",
    "\n",
    "    # UNCOMMENT BELOW IF RSSI DATA WILL BE USED\n",
    "    for rx_df in rx_df_list:\n",
    "        rx_df[\"RSSI\"] = rssi_to_np(rx_df[\"RSSI\"])\n",
    "    for pd_df in pd_df_list:\n",
    "        pd_df[\"RSSI\"] = rssi_to_np(pd_df[\"RSSI\"])\n",
    "    for mon_df in mon_df_list:\n",
    "        if mon_df is not None:\n",
    "            mon_df[\"RSSI\"] = rssi_to_np(mon_df[\"RSSI\"])\n",
    "\n",
    "    return rx_df_list, tx_df_list, pd_df_list, mon_df_list\n",
    "\n",
    "def process_dropped_packets(tx_df, rx_df_list, pd_df_list, tx_index, delay_threshold, sending_interval=40, NP=10000):\n",
    "    '''\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, fopr downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df_list: List of Rx DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    tx_index: Index of Tx in pd_df_list (e.g. for GCS, tx_index = 0)\n",
    "    delay_threshold: Delay threshold to consider if packet arrived too late\n",
    "    sending_interval: Mean sending interval (used to determine UAV speed in the simulation)\n",
    "    NP: Number of packets set for every 100m\n",
    "    Output: pkt_df: DF containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    uav_speed = 100 * 1000 / NP / sending_interval # This is for estimating the U2G Distance when queue overflow happens (refer Omnet ini file)\n",
    "    pkt_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Delay','Queueing_Time','Backoff_Time','U2G_Distance',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State'])\n",
    "    for index, row in tx_df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "        dest_addr = row[\"Dest_Addr\"]\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "        rx_df = rx_df_list[rx_index]\n",
    "\n",
    "        # For each packet in gcs_tx_df, get the packet drops from GW and corresponding UAV\n",
    "        pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df_list[tx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        pkt_drops_gw = pd_df_list[1].loc[(pd_df_list[1][\"Packet_Name\"] == packetName)] # Packets dropped at the gateway UAV\n",
    "        if rx_index != 1: # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df_list[rx_index][\"Packet_Name\"] == packetName)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = cudf.concat([pkt_drops_tx, pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = cudf.concat([pkt_drops_tx, pkt_drops_gw], ignore_index = True)\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at GW and Rx\n",
    "            drop_reasons_tx = pkt_drops_tx[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at Tx\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            queue_overflow = np.count_nonzero(drop_reasons == \"QUEUE_OVERFLOW\")\n",
    "            retry_limit_excd = np.count_nonzero(drop_reasons == \"RETRY_LIMIT_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons == \"INTERFACE_DOWN\")\n",
    "            num_drops = len(drop_reasons) # This is for counting drops due to incorrectly received only\n",
    "\n",
    "            # Update pkt_df \n",
    "            if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "                # If not received, add the data of failed packet\n",
    "                rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "                tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "                bytes = row[\"Bytes\"]\n",
    "                rssi = pkt_drops[\"RSSI\"].mean() # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "                u2g_sinr = max(pkt_drops[\"U2G_SINR\"].values)\n",
    "                u2g_ber = max(pkt_drops[\"U2G_BER\"].values)\n",
    "                delay = max(pkt_drops[\"Delay\"].values)\n",
    "                queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "                backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "                u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "                # Packet State Based on Failure Mode\n",
    "                if retry_limit_excd > 0:\n",
    "                    pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                    # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif queue_overflow > 0:\n",
    "                    pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                    # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif interface_down > 0:\n",
    "                    pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "                else:\n",
    "                    pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                    print(\"Packet Failure Mode Unknown\")\n",
    "                # Check for U2U Data\n",
    "                if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                    u2u_sinr = max(pkt_drops[\"U2U_SINR\"].values)\n",
    "                    u2u_ber = max(pkt_drops[\"U2U_BER\"].values)\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "\n",
    "                failed_pkt = cudf.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = cudf.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                # If packet successfully received, update the number of tries and the reason for failed attempt(s) to the received packet info\n",
    "                rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "                rcvd_pkt_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "                rcvd_pkt_df[\"Queue_Overflow\"] = queue_overflow\n",
    "                rcvd_pkt_df[\"Interface_Down\"] = interface_down\n",
    "                rcvd_pkt_df[\"Number_Dropped\"] = num_drops\n",
    "                if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "                else:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "                pkt_df = cudf.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "\n",
    "        elif (packetName in rx_df[\"Packet_Name\"].values):\n",
    "            # The packet was received without any retries\n",
    "            rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"] == packetName)].copy()\n",
    "            rcvd_pkt_df[\"Incorrectly_Rcvd\"] = 0\n",
    "            rcvd_pkt_df[\"Queue_Overflow\"] = 0\n",
    "            rcvd_pkt_df[\"Interface_Down\"] = 0\n",
    "            rcvd_pkt_df[\"Number_Dropped\"] = 0\n",
    "            if rcvd_pkt_df[\"Delay\"].values > delay_threshold:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "            else:\n",
    "                rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "            pkt_df = cudf.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "        \n",
    "        # else:\n",
    "        #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    pkt_df = pkt_df.sort_values(\"RxTime\")\n",
    "    pkt_df = pkt_df.reset_index()\n",
    "    return pkt_df\n",
    "\n",
    "def process_dropped_packets_loop(tx_df, rx_df_list, pd_df_list, tx_index, delay_threshold, sending_interval=40, NP=10000):\n",
    "    '''\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, fopr downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df_list: List of Rx DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    tx_index: Index of Tx in pd_df_list (e.g. for GCS, tx_index = 0)\n",
    "    delay_threshold: Delay threshold to consider if packet arrived too late\n",
    "    sending_interval: Mean sending interval (used to determine UAV speed in the simulation)\n",
    "    NP: Number of packets set for every 100m\n",
    "    Output: pkt_df: DF containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    uav_speed = 100 * 1000 / NP / sending_interval # This is for estimating the U2G Distance when queue overflow happens (refer Omnet ini file)\n",
    "    pkt_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Delay','Queueing_Time','Backoff_Time','U2G_Distance',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State'])\n",
    "    packet_names = tx_df[\"Packet_Name\"].to_pandas().values[0] # Assuming that the packet name values within a Tx file are all the same\n",
    "    packet_seqs = tx_df[\"Packet_Seq\"].to_pandas().values\n",
    "    dest_addresses = tx_df[\"Dest_Addr\"].to_pandas().values\n",
    "    packet_sizes = tx_df[\"Bytes\"].values\n",
    "    for i in range(len(packet_seqs)):\n",
    "        # print(i)\n",
    "        dest_addr = dest_addresses[i]\n",
    "        packet_name = packet_names + \"-\" + str(packet_seqs[i])\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "        rx_df = rx_df_list[rx_index]\n",
    "        # For each packet in gcs_tx_df, get the packet drops from GW and corresponding UAV\n",
    "        if not pd_df_list[tx_index].empty:\n",
    "            pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df_list[tx_index][\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().values)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        if not pd_df_list[1].empty:\n",
    "            pkt_drops_gw = pd_df_list[1].loc[(pd_df_list[1][\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().values)] # Packets dropped at the gateway UAV\n",
    "        if (rx_index != 1) and (not pd_df_list[rx_index].empty): # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df_list[rx_index][\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().values)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = cudf.concat([pkt_drops_tx, pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = cudf.concat([pkt_drops_tx, pkt_drops_gw], ignore_index = True)\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            queue_overflow = pkt_drops[\"Packet_Drop_Reason\"].str.count(\"QUEUE_OVERFLOW\").sum()\n",
    "            incorrect_rcvd = 0\n",
    "            retry_limit_excd = 0\n",
    "            interface_down = 0\n",
    "            if queue_overflow == 0: # We know that if pkt dropped due to queue overflow, there won't be other packet drop types\n",
    "                incorrect_rcvd = pkt_drops[\"Packet_Drop_Reason\"].str.count(\"INCORRECTLY_RECEIVED\").sum()\n",
    "                retry_limit_excd = pkt_drops[\"Packet_Drop_Reason\"].str.count(\"RETRY_LIMIT_REACHED\").sum()\n",
    "                interface_down = pkt_drops[\"Packet_Drop_Reason\"].str.count(\"INTERFACE_DOWN\").sum()\n",
    "            num_drops = incorrect_rcvd # This is for counting drops due to incorrectly received only\n",
    "\n",
    "            # Update pkt_df \n",
    "            # If no packet received in rx_df, but there's packet drop recorded, add packet drop info\n",
    "            if rx_df.empty:\n",
    "                rx_time = pkt_drops[\"RxTime\"].max()\n",
    "                tx_time = pkt_drops[\"TxTime\"].min()\n",
    "                bytes = int(packet_sizes[i])\n",
    "                rssi = pkt_drops[\"RSSI\"].max() # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "                u2g_sinr = pkt_drops[\"U2G_SINR\"].max()\n",
    "                u2g_ber = pkt_drops[\"U2G_BER\"].max()\n",
    "                delay = pkt_drops[\"Delay\"].max()\n",
    "                queueing_time = pkt_drops[\"Queueing_Time\"].max()\n",
    "                backoff_time = pkt_drops[\"Backoff_Time\"].max()\n",
    "                u2g_distance = pkt_drops[\"U2G_Distance\"].max()\n",
    "                # Packet State Based on Failure Mode\n",
    "                if retry_limit_excd > 0:\n",
    "                    pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                    # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif queue_overflow > 0:\n",
    "                    pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                    # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif interface_down > 0:\n",
    "                    pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "                else:\n",
    "                    pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                    print(\"Packet Failure Mode Unknown\")\n",
    "                # Check for U2U Data\n",
    "                if (pkt_drops[\"U2U_SINR\"].any()): # There may not always be a U2U communication\n",
    "                    u2u_sinr = pkt_drops[\"U2U_SINR\"].max()\n",
    "                    u2u_ber = pkt_drops[\"U2U_BER\"].max()\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "\n",
    "                failed_pkt = cudf.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packet_name,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = cudf.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "            # If rx_df not empty but packet not received, add the data of failed packet\n",
    "            elif not (rx_df[\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().any().values):  \n",
    "                rx_time = pkt_drops[\"RxTime\"].max()\n",
    "                tx_time = pkt_drops[\"TxTime\"].min()\n",
    "                bytes = int(packet_sizes[i])\n",
    "                rssi = pkt_drops[\"RSSI\"].max() # This should be taking the max RSSI, but since it is not used, leaving it as mean for now\n",
    "                u2g_sinr = pkt_drops[\"U2G_SINR\"].max()\n",
    "                u2g_ber = pkt_drops[\"U2G_BER\"].max()\n",
    "                delay = pkt_drops[\"Delay\"].max()\n",
    "                queueing_time = pkt_drops[\"Queueing_Time\"].max()\n",
    "                backoff_time = pkt_drops[\"Backoff_Time\"].max()\n",
    "                u2g_distance = pkt_drops[\"U2G_Distance\"].max()\n",
    "                # Packet State Based on Failure Mode\n",
    "                if retry_limit_excd > 0:\n",
    "                    pkt_state = \"RETRY_LIMIT_REACHED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                    # If packet was dropped due to retry limit reach at the GW, then there may not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif queue_overflow > 0:\n",
    "                    pkt_state = \"QUEUE_OVERFLOW\" # The packet failed due to queue buffer overflow\n",
    "                    # If packet was dropped due to queue overflow, then there will not be any U2G distance recorded. But knowing the speed, we can compute it\n",
    "                    if math.isnan(u2g_distance):\n",
    "                        u2g_distance = uav_speed * rx_time\n",
    "                elif interface_down > 0:\n",
    "                    pkt_state = \"INTERFACE_DOWN\" # The packet failed due to interface down\n",
    "                else:\n",
    "                    pkt_state = \"FAILED\" # Unaccounted fail reason\n",
    "                    print(\"Packet Failure Mode Unknown\")\n",
    "                # Check for U2U Data\n",
    "                if (pkt_drops[\"U2U_SINR\"].any()): # There may not always be a U2U communication\n",
    "                    u2u_sinr = pkt_drops[\"U2U_SINR\"].max()\n",
    "                    u2u_ber = pkt_drops[\"U2U_BER\"].max()\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "\n",
    "                failed_pkt = cudf.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packet_name,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                            'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                            'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = cudf.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                # If packet successfully received, update the number of tries and the reason for failed attempt(s) to the received packet info\n",
    "                rcvd_pkt_df = rx_df.loc[((rx_df[\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().values))].copy()\n",
    "                rcvd_pkt_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "                rcvd_pkt_df[\"Queue_Overflow\"] = queue_overflow\n",
    "                rcvd_pkt_df[\"Interface_Down\"] = interface_down\n",
    "                rcvd_pkt_df[\"Number_Dropped\"] = num_drops\n",
    "                if rcvd_pkt_df[\"Delay\"].values[0] > delay_threshold:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "                else:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "                pkt_df = cudf.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "\n",
    "        # If no packet drop recorded, check that it is received\n",
    "        elif not rx_df.empty:\n",
    "            if (rx_df[\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().any().values):\n",
    "                # The packet was received without any drops\n",
    "                rcvd_pkt_df = rx_df.loc[(rx_df[\"Packet_Name\"].str.extract('({})'.format(packet_name)).notna().values)].copy()\n",
    "                rcvd_pkt_df[\"Incorrectly_Rcvd\"] = 0\n",
    "                rcvd_pkt_df[\"Queue_Overflow\"] = 0\n",
    "                rcvd_pkt_df[\"Interface_Down\"] = 0\n",
    "                rcvd_pkt_df[\"Number_Dropped\"] = 0\n",
    "                if rcvd_pkt_df[\"Delay\"].values[0] > delay_threshold:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"DELAY_EXCEEDED\"\n",
    "                else:\n",
    "                    rcvd_pkt_df[\"Packet_State\"] = \"RELIABLE\"\n",
    "                pkt_df = cudf.concat([pkt_df,rcvd_pkt_df], ignore_index = True)\n",
    "            # else:\n",
    "            #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "        # else:\n",
    "        #     print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    pkt_df = pkt_df.sort_values(\"RxTime\")\n",
    "    pkt_df = pkt_df.reset_index()\n",
    "    return pkt_df\n",
    "\n",
    "def process_throughput(df, timeDiv):\n",
    "    '''\n",
    "    Function to calculate throughput data for a DataFrame\n",
    "    timeDiv is the time division to use for calculating the throughput\n",
    "    '''\n",
    "    # maxTime = df[\"RxTime\"].max()\n",
    "    # if not math.isnan(maxTime):\n",
    "    print(df[\"RxTime\"].max())\n",
    "    maxTime = math.ceil(float(df[\"RxTime\"].max()))\n",
    "    for i in range(math.ceil(maxTime / timeDiv)):\n",
    "        df_in_range = df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)) & (df[\"Packet_State\"] == \"RECEIVED\")]\n",
    "        totalBytes = df_in_range[\"Bytes\"].sum()\n",
    "        throughput = totalBytes / timeDiv\n",
    "        df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)), \"Throughput\"] = throughput\n",
    "    # else:\n",
    "    #     df[\"Throughput\"] = 0\n",
    "    return df\n",
    "\n",
    "def process_sim_data(sim_root_path, delay_threshold, NP):\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + \"/*GCS-Tx.csv\")] # Get list of \"unique\" scenarios\n",
    "\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    # NP = 10000 # The number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\n",
    "    # NP = input(\"Enter number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\")\n",
    "    for scenario in scenario_list:\n",
    "        scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "        scenario_params = scenario.split('_')\n",
    "        num_member = int(scenario_params[0].split('-')[-1])\n",
    "        inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "        height = int(scenario_params[2].split('-')[-1]) \n",
    "        sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "        rx_df_list, tx_df_list, pd_df_list, mon_df_list = compile_micro_sim_data(scenario_files)\n",
    "        \n",
    "        # Process the state of each packets sent in DL\n",
    "        start_dl_time = time.time()\n",
    "        dl_data = process_dropped_packets(tx_df_list[0], rx_df_list, pd_df_list, 0, delay_threshold, sending_interval, NP)\n",
    "        if dl_data is not None:\n",
    "            dl_data[\"Height\"] = height\n",
    "            dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            dl_data[\"Num_Members\"] = num_member\n",
    "            dl_data[\"Sending_Interval\"] = sending_interval\n",
    "            dl_data = process_throughput(dl_data, 1)\n",
    "            dl_df = cudf.concat([dl_df, dl_data], ignore_index=True)\n",
    "\n",
    "        # Process the state of each packets sent in DL\n",
    "        start_ul_time = time.time()\n",
    "        for i in range(1,len(rx_df_list)):\n",
    "            ul_data = process_dropped_packets(tx_df_list[i], rx_df_list, pd_df_list, i, delay_threshold, sending_interval, NP)\n",
    "            if ul_data is not None:\n",
    "                ul_data[\"Height\"] = height\n",
    "                ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "                ul_data[\"Num_Members\"] = num_member\n",
    "                ul_data[\"Sending_Interval\"] = sending_interval\n",
    "                ul_data = process_throughput(ul_data, 1)\n",
    "                ul_df = cudf.concat([ul_df, ul_data], ignore_index=True)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"DL Time: {}\".format(start_ul_time-start_dl_time))\n",
    "        print(\"UL Time: {}\".format(end_time-start_ul_time))\n",
    "    \n",
    "    return dl_df, ul_df\n",
    "\n",
    "def process_sim_data_save_files(sim_root_path, save_path, delay_threshold, NP):\n",
    "    '''\n",
    "    29/1/2023\n",
    "    Stores the individual processed DF of each scenario in its own CSV file under save_path\n",
    "    '''\n",
    "\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + \"/*GCS-Tx.csv\")] # Get list of \"unique\" scenarios\n",
    "\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = cudf.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER','Hop_Count','Throughput',\n",
    "                                    'Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance','Num_Members','Sending_Interval',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    # NP = 10000 # The number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\n",
    "    # NP = input(\"Enter number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\")\n",
    "    for scenario in scenario_list:\n",
    "        scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "        scenario_params = scenario.split('_')\n",
    "        num_member = int(scenario_params[0].split('-')[-1])\n",
    "        inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "        height = int(scenario_params[2].split('-')[-1]) \n",
    "        sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "        rx_df_list, tx_df_list, pd_df_list, mon_df_list = compile_micro_sim_data(scenario_files)\n",
    "        print(scenario)\n",
    "        # Process the state of each packets sent in DL\n",
    "        start_dl_time = time.time()\n",
    "        dl_data = process_dropped_packets_loop(tx_df_list[0], rx_df_list, pd_df_list, 0, delay_threshold, sending_interval, NP)\n",
    "        if dl_data is not None:\n",
    "            dl_data[\"Height\"] = height\n",
    "            dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            dl_data[\"Num_Members\"] = num_member\n",
    "            dl_data[\"Sending_Interval\"] = sending_interval\n",
    "            dl_data = process_throughput(dl_data, 1)\n",
    "            dl_df = cudf.concat([dl_df, dl_data], ignore_index=True)\n",
    "            dl_df.to_csv(os.path.join(save_path,\"{}_downlink.csv\".format(scenario)), index=False)\n",
    "\n",
    "        # Process the state of each packets sent in DL\n",
    "        start_ul_time = time.time()\n",
    "        for i in range(1,len(rx_df_list)):\n",
    "            ul_data = process_dropped_packets_loop(tx_df_list[i], rx_df_list, pd_df_list, i, delay_threshold, sending_interval, NP)\n",
    "            if ul_data is not None:\n",
    "                ul_data[\"Height\"] = height \n",
    "                ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "                ul_data[\"Num_Members\"] = num_member\n",
    "                ul_data[\"Sending_Interval\"] = sending_interval\n",
    "                ul_data = process_throughput(ul_data, 1)\n",
    "                ul_df = cudf.concat([ul_df, ul_data], ignore_index=True)\n",
    "        if not ul_df.empty:\n",
    "            ul_df.to_csv(os.path.join(save_path,\"{}_uplink.csv\".format(scenario)), index=False)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(scenario)\n",
    "        print(\"DL Time: {}\".format(start_ul_time-start_dl_time))\n",
    "        print(\"UL Time: {}\".format(end_time-start_ul_time))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumMember-7_InterUAVDistance-5_Height-24_Distance-0_PacketSize-24_SendingRate-40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m delay_threshold \u001b[39m=\u001b[39m \u001b[39m0.04\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m NP \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m# Number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m process_sim_data_save_files(sim_root_path, sim_root_path, delay_threshold\u001b[39m=\u001b[39;49mdelay_threshold, NP\u001b[39m=\u001b[39;49mNP)\n",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb Cell 2\u001b[0m in \u001b[0;36mprocess_sim_data_save_files\u001b[0;34m(sim_root_path, save_path, delay_threshold, NP)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=540'>541</a>\u001b[0m \u001b[39m# Process the state of each packets sent in DL\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=541'>542</a>\u001b[0m start_dl_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=542'>543</a>\u001b[0m dl_data \u001b[39m=\u001b[39m process_dropped_packets_loop(tx_df_list[\u001b[39m0\u001b[39;49m], rx_df_list, pd_df_list, \u001b[39m0\u001b[39;49m, delay_threshold, sending_interval, NP)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=543'>544</a>\u001b[0m \u001b[39mif\u001b[39;00m dl_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=544'>545</a>\u001b[0m     dl_data[\u001b[39m\"\u001b[39m\u001b[39mHeight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m height\n",
      "\u001b[1;32m/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb Cell 2\u001b[0m in \u001b[0;36mprocess_dropped_packets_loop\u001b[0;34m(tx_df, rx_df_list, pd_df_list, tx_index, delay_threshold, sending_interval, NP)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=402'>403</a>\u001b[0m     pkt_df \u001b[39m=\u001b[39m cudf\u001b[39m.\u001b[39mconcat([pkt_df,failed_pkt], ignore_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=404'>405</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=405'>406</a>\u001b[0m     \u001b[39m# If packet successfully received, update the number of tries and the reason for failed attempt(s) to the received packet info\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=406'>407</a>\u001b[0m     rcvd_pkt_df \u001b[39m=\u001b[39m rx_df\u001b[39m.\u001b[39;49mloc[((rx_df[\u001b[39m\"\u001b[39;49m\u001b[39mPacket_Name\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mextract(\u001b[39m'\u001b[39;49m\u001b[39m(\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(packet_name))\u001b[39m.\u001b[39;49mnotna()\u001b[39m.\u001b[39;49mvalues))]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=407'>408</a>\u001b[0m     rcvd_pkt_df[\u001b[39m\"\u001b[39m\u001b[39mIncorrectly_Rcvd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m incorrect_rcvd\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/research-student/omnet-fanet/data-processing-scripts/fanet_data_preprocessing_cudf.ipynb#W1sZmlsZQ%3D%3D?line=408'>409</a>\u001b[0m     rcvd_pkt_df[\u001b[39m\"\u001b[39m\u001b[39mQueue_Overflow\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m queue_overflow\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/site-packages/cudf/core/dataframe.py:144\u001b[0m, in \u001b[0;36m_DataFrameIndexer.__getitem__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    143\u001b[0m     arg \u001b[39m=\u001b[39m (arg, \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 144\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_arg(arg)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/site-packages/cudf/core/dataframe.py:284\u001b[0m, in \u001b[0;36m_DataFrameLocIndexer._getitem_tuple_arg\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    281\u001b[0m tmp_arg \u001b[39m=\u001b[39m (as_column(tmp_arg[\u001b[39m0\u001b[39m]), tmp_arg[\u001b[39m1\u001b[39m])\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m is_bool_dtype(tmp_arg[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 284\u001b[0m     df \u001b[39m=\u001b[39m columns_df\u001b[39m.\u001b[39;49m_apply_boolean_mask(tmp_arg[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     tmp_col_name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid4())\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/site-packages/cudf/core/indexed_frame.py:2750\u001b[0m, in \u001b[0;36mIndexedFrame._apply_boolean_mask\u001b[0;34m(self, boolean_mask)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_bool_dtype(boolean_mask\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   2747\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mboolean_mask is not boolean type.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_columns_like_self(\n\u001b[0;32m-> 2750\u001b[0m     libcudf\u001b[39m.\u001b[39;49mstream_compaction\u001b[39m.\u001b[39;49mapply_boolean_mask(\n\u001b[1;32m   2751\u001b[0m         \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index\u001b[39m.\u001b[39;49m_columns \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_columns), boolean_mask\n\u001b[1;32m   2752\u001b[0m     ),\n\u001b[1;32m   2753\u001b[0m     column_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_names,\n\u001b[1;32m   2754\u001b[0m     index_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index\u001b[39m.\u001b[39mnames,\n\u001b[1;32m   2755\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32mstream_compaction.pyx:104\u001b[0m, in \u001b[0;36mcudf._lib.stream_compaction.apply_boolean_mask\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mutils.pyx:243\u001b[0m, in \u001b[0;36mcudf._lib.utils.columns_from_unique_ptr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcolumn.pyx:483\u001b[0m, in \u001b[0;36mcudf._lib.column.Column.from_unique_ptr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-22.12/lib/python3.8/site-packages/cudf/core/column/column.py:1351\u001b[0m, in \u001b[0;36mbuild_column\u001b[0;34m(data, dtype, size, mask, offset, null_count, children)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[39mif\u001b[39;00m _is_non_decimal_numeric_dtype(dtype):\n\u001b[1;32m   1350\u001b[0m     \u001b[39massert\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m     \u001b[39mreturn\u001b[39;00m cudf\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39mcolumn\u001b[39m.\u001b[39mNumericalColumn(\n\u001b[1;32m   1352\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m   1353\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1354\u001b[0m         mask\u001b[39m=\u001b[39mmask,\n\u001b[1;32m   1355\u001b[0m         size\u001b[39m=\u001b[39msize,\n\u001b[1;32m   1356\u001b[0m         offset\u001b[39m=\u001b[39moffset,\n\u001b[1;32m   1357\u001b[0m         null_count\u001b[39m=\u001b[39mnull_count,\n\u001b[1;32m   1358\u001b[0m     )\n\u001b[1;32m   1359\u001b[0m \u001b[39mif\u001b[39;00m is_categorical_dtype(dtype):\n\u001b[1;32m   1360\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(children) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_root_path = \"/home/research-student/omnetpp_sim_results/Testing\"\n",
    "delay_threshold = 0.04\n",
    "NP = 1000 # Number of packets set in the simulation for each 100m (refer to OMNeT++ ini sim file)\n",
    "process_sim_data_save_files(sim_root_path, sim_root_path, delay_threshold=delay_threshold, NP=NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "False\n",
      "Empty DataFrame\n",
      "Columns: [RxTime, TxTime, Packet_Name, Bytes, RSSI, U2G_SINR, U2U_SINR, U2G_BER, U2U_BER, Src_Addr, Dest_Addr, Hop_Count, Delay, Queueing_Time, Backoff_Time, U2G_Distance, Unnamed: 16]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "tx_df = cudf.read_csv(\"/home/research-student/omnetpp_sim_results/Testing/NumMember-3_InterUAVDistance-5_Height-50_Distance-0_PacketSize-249_SendingRate-233_GCS-Tx.csv\")\n",
    "pkt = tx_df.loc[(tx_df[\"Packet_Seq\"]==2473)]\n",
    "packet_sizes = tx_df['Bytes'].values\n",
    "print(int(packet_sizes[2473]))\n",
    "\n",
    "uav_2_rx_df = cudf.read_csv(\"/home/research-student/omnetpp_sim_results/Testing/NumMember-3_InterUAVDistance-5_Height-50_Distance-0_PacketSize-249_SendingRate-233_UAV-2-Rx.csv\")\n",
    "pkt_rcvd = uav_2_rx_df.loc[(uav_2_rx_df[\"Packet_Name\"].str.extract('({})'.format('CNCData-2473')).notna().values)]\n",
    "print(uav_2_rx_df[\"Packet_Name\"].str.extract('({})'.format('CNCData-2473')).notna().empty)\n",
    "print(pkt_rcvd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b91d162001b74e2486487353b6410b0f764056372f730fbe993a2ad06d40082"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
