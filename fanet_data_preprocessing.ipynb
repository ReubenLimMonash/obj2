{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import networkx as nx # for drawing graphs\n",
    "import matplotlib.pyplot as plt # for drawing graphs\n",
    "import os, sys, glob, math\n",
    "# for creating Bayesian Belief Networks (BBN)\n",
    "from pybbn.graph.dag import Bbn\n",
    "from pybbn.graph.edge import Edge, EdgeType\n",
    "from pybbn.graph.jointree import EvidenceBuilder\n",
    "from pybbn.graph.node import BbnNode\n",
    "from pybbn.graph.variable import Variable\n",
    "from pybbn.pptc.inferencecontroller import InferenceController\n",
    "\n",
    "def rssi_to_np(rssi):\n",
    "    # Function to convert rssi data from string (e.g. \"435 pW\") to exp (435e-12)\n",
    "    rssi_num = np.zeros(rssi.shape)\n",
    "    index = 0\n",
    "    for r in rssi:\n",
    "        num = r[0:-2]\n",
    "        expn = r[-2:]\n",
    "        # print(num)\n",
    "        # print(expn)\n",
    "        if expn == \" W\":\n",
    "            # print(num)\n",
    "            # print(index)\n",
    "            rssi_num[index] = float(num)\n",
    "        elif expn == \"mW\":\n",
    "            rssi_num[index] = float(num) * 1e-3\n",
    "        elif expn == \"uW\":\n",
    "            rssi_num[index] = float(num) * 1e-6\n",
    "        elif expn == \"nW\":\n",
    "            rssi_num[index] = float(num) * 1e-9\n",
    "        elif expn == \"pW\":\n",
    "            rssi_num[index] = float(num) * 1e-12\n",
    "        else:\n",
    "            print(expn)\n",
    "            raise ValueError(\"Unhandled unit prefix\")\n",
    "        index += 1\n",
    "    return rssi_num\n",
    "\n",
    "def compile_micro_sim_data(file_list):\n",
    "    '''\n",
    "    Function to compile data from the CSV files generated by each micro-simulation\n",
    "    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)\n",
    "    Output: concatenates the raw data to UL and DL dataframes\n",
    "    '''\n",
    "    uavs_rx_df = pd.DataFrame() \n",
    "    gcs_rx_df = pd.DataFrame()  \n",
    "    gcs_tx_df = pd.DataFrame()  \n",
    "    uavs_tx_df = pd.DataFrame()  \n",
    "    gcs_mon_df = pd.DataFrame() \n",
    "    uavs_mon_df = pd.DataFrame()  \n",
    "    gcs_pd_df = pd.DataFrame()  \n",
    "    uavs_pd_df = pd.DataFrame() \n",
    "\n",
    "    uavs_rx_df_list = [] # List to store all df for UAVs Rx app\n",
    "    uavs_tx_df_list = [] # List to store all df for UAVs Tx app\n",
    "    uavs_mon_df_list = [] # List to store all df for UAVs monitor mode captures\n",
    "    uavs_pd_df_list = [] # List to store all df for UAVs packet drop captures\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            if ('_GCS-' in file) and ('-Tx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is the GCS Tx file, recording the sent packets from GCS\n",
    "                gcs_tx_df = pd.read_csv(file)\n",
    "            elif ('_GW-' in file) and ('-Rx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is the gateway Rx file, let's get the information of packets received from GCS\n",
    "                gw_rx_df = pd.read_csv(file)\n",
    "                uavs_rx_df_list.append(gw_rx_df)\n",
    "            elif ('_UAV-' in file) and ('-Rx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is a UAV Rx file. To concatenate all such files into a single df\n",
    "                uav_rx_df = pd.read_csv(file)\n",
    "                # uav_cnc_data = uav_rx_df[\"CNCData\" in uav_rx_df[\"Packet_Name\"]] # Get the CNC Data received by this UAV\n",
    "                # uav_cnc_reliable = uav_cnc_data[uav_cnc_data[\"Delay\"] < delay_th] # Get the CNCData packets received reliably by this UAV (delay < 1ms)\n",
    "                uavs_rx_df_list.append(uav_rx_df) # Append to list for concatenation later\n",
    "            elif ('_GCS-' in file) and ('-Rx' in file):\n",
    "                # UPLINK\n",
    "                # This is a GCS Rx file, recording packets received from UAVs-\n",
    "                gcs_rx_df = pd.read_csv(file)\n",
    "            elif ('_GW-' in file) and ('-Tx' in file):\n",
    "                # UPLINK\n",
    "                # This is the gateway Tx file, recording packet transmissions to GCS from gateway\n",
    "                gw_tx_df = pd.read_csv(file)\n",
    "                uavs_tx_df_list.append(gw_tx_df) # Append to list for concatenation later\n",
    "            elif ('_UAV-' in file) and ('-Tx' in file):\n",
    "                # DOWNLINK\n",
    "                # This is a UAV Rx file. To concatenate all such files into a single df\n",
    "                uav_tx_df = pd.read_csv(file)\n",
    "                uavs_tx_df_list.append(uav_tx_df) # Append to list for concatenation later\n",
    "            elif ('_GCS-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for GCS\n",
    "                gcs_mon_df = pd.read_csv(file)\n",
    "                gcs_mon_df[\"Addr\"] = \"192.168.0.1\"\n",
    "            elif ('_GW-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for gateway\n",
    "                gw_mon_df = pd.read_csv(file)\n",
    "                gw_mon_df[\"Addr\"] = \"192.168.0.2\"\n",
    "                uavs_mon_df_list.append(gw_mon_df)\n",
    "            elif ('_UAV-' in file) and ('Wlan' in file):\n",
    "                # Monitor mode file for GCS\n",
    "                uav_mon_df = pd.read_csv(file)\n",
    "                uav_index = file.split(\"_\")[-1].split(\"-\")[1]\n",
    "                uav_mon_df[\"Addr\"] = \"192.168.0.{}\".format(int(uav_index) + 3)\n",
    "                uavs_mon_df_list.append(uav_mon_df)\n",
    "            elif ('_GCS-' in file) and ('PacketDrop' in file):\n",
    "                # Packet Drop file for GCS\n",
    "                gcs_pd_df = pd.read_csv(file)\n",
    "            elif ('_GW-' in file) and ('PacketDrop' in file):\n",
    "                # Packet Drop file for gateway\n",
    "                gw_pd_df = pd.read_csv(file)\n",
    "                uavs_pd_df_list.append(gw_pd_df)\n",
    "            elif ('_UAV-' in file) and ('PacketDrop' in file):\n",
    "                # Packet Drop file for GCS\n",
    "                uav_pd_df = pd.read_csv(file)\n",
    "                uav_index = file.split(\"_\")[-1].split(\"-\")[1]\n",
    "                uavs_pd_df_list.append(uav_pd_df)\n",
    "            else:\n",
    "                # This file type is not handled, pass \n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(file)\n",
    "            print(e)\n",
    "        \n",
    "    try:\n",
    "        uavs_rx_df = pd.concat(uavs_rx_df_list, ignore_index = True)\n",
    "        uavs_tx_df = pd.concat(uavs_tx_df_list, ignore_index = True)\n",
    "        uavs_mon_df = pd.concat(uavs_mon_df_list, ignore_index = True)\n",
    "        uavs_pd_df = pd.concat(uavs_pd_df_list, ignore_index = True)\n",
    "    except:\n",
    "        print(\"Check if any of the following files are missing\")\n",
    "        print(file_list)\n",
    "\n",
    "    if len(gcs_rx_df.columns) == 0 or len(gcs_tx_df.columns) == 0 or len(gcs_mon_df.columns) == 0 or len(gcs_pd_df.columns) == 0:\n",
    "        print(\"A GCS file is missing\")\n",
    "        print(file_list)\n",
    "\n",
    "\n",
    "    return uavs_rx_df, gcs_rx_df, gcs_tx_df, uavs_tx_df, gcs_mon_df, uavs_mon_df, gcs_pd_df, uavs_pd_df\n",
    "\n",
    "def compile_micro_sim_data_v2(file_list):\n",
    "    '''\n",
    "    Function to compile data from the CSV files generated by each micro-simulation\n",
    "    Update: To specifically return the rx_df, tx_df, mon_df and pd_df in lists, so that specific dfs can be accessed (instead of aggregating UAV dfs)\n",
    "    Input: file_list - List of simulation files belonging to a certain scenario (micro-sim)\n",
    "    Output: concatenates the raw data to UL and DL dataframes\n",
    "    '''\n",
    "\n",
    "    # Let's get the GCS dfs ===============================================================\n",
    "    gcs_rx_file = [file for file in file_list if (('_GCS-' in file) and ('-Rx' in file))]\n",
    "    gcs_tx_file = [file for file in file_list if (('_GCS-' in file) and ('-Tx' in file))]\n",
    "    gcs_mon_file = [file for file in file_list if (('_GCS-' in file) and ('Wlan' in file))]\n",
    "    gcs_pd_file = [file for file in file_list if (('_GCS-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gcs_rx_file) > 0:\n",
    "        gcs_rx_df = pd.read_csv(gcs_rx_file[0])\n",
    "    else:\n",
    "        print(\"GCS RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_tx_file) > 0:\n",
    "        gcs_tx_df = pd.read_csv(gcs_tx_file[0])\n",
    "    else:\n",
    "        print(\"GCS TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_pd_file) > 0:\n",
    "        gcs_pd_df = pd.read_csv(gcs_pd_file[0])\n",
    "    else:\n",
    "        print(\"GCS PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gcs_mon_file) > 0:\n",
    "        gcs_mon_df = pd.read_csv(gcs_mon_file[0]) # Mon file is optional\n",
    "        gcs_mon_df[\"Addr\"] = \"192.168.0.1\"\n",
    "    else: \n",
    "        gcs_mon_df = None\n",
    "\n",
    "    # Let's get the GW dfs ===============================================================\n",
    "    gw_rx_file = [file for file in file_list if (('_GW-' in file) and ('-Rx' in file))]\n",
    "    gw_tx_file = [file for file in file_list if (('_GW-' in file) and ('-Tx' in file))]\n",
    "    gw_mon_file = [file for file in file_list if (('_GW-' in file) and ('Wlan' in file))]\n",
    "    gw_pd_file = [file for file in file_list if (('_GW-' in file) and ('PacketDrop' in file))]\n",
    "    if len(gw_rx_file) > 0:\n",
    "        gw_rx_df = pd.read_csv(gw_rx_file[0])\n",
    "    else:\n",
    "        print(\"GW RX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_tx_file) > 0:\n",
    "        gw_tx_df = pd.read_csv(gw_tx_file[0])\n",
    "    else:\n",
    "        print(\"GW TX File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_pd_file) > 0:\n",
    "        gw_pd_df = pd.read_csv(gw_pd_file[0])\n",
    "    else:\n",
    "        print(\"GW PD File Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(gw_mon_file) > 0:\n",
    "        gw_mon_df = pd.read_csv(gw_mon_file[0]) # Mon file is optional\n",
    "        gw_mon_df[\"Addr\"] = \"192.168.0.2\"\n",
    "    else:\n",
    "        gw_mon_df = None\n",
    "\n",
    "    # Let's get the UAVs dfs ===============================================================\n",
    "    uavs_rx_df_list = []\n",
    "    uavs_tx_df_list = []\n",
    "    uavs_mon_df_list = []\n",
    "    uavs_pd_df_list = []\n",
    "    uav_rx_files = [file for file in file_list if (('_UAV-' in file) and ('-Rx' in file))]\n",
    "    uav_tx_files = [file for file in file_list if (('_UAV-' in file) and ('-Tx' in file))]\n",
    "    uav_mon_files = [file for file in file_list if (('_UAV-' in file) and ('Wlan' in file))]\n",
    "    uav_pd_files = [file for file in file_list if (('_UAV-' in file) and ('PacketDrop' in file))]\n",
    "    uav_rx_files.sort()\n",
    "    uav_tx_files.sort()\n",
    "    uav_mon_files.sort()\n",
    "    uav_pd_files.sort()\n",
    "    if len(uav_rx_files) > 0:\n",
    "        for uav_rx_file in uav_rx_files:\n",
    "            uavs_rx_df_list.append(pd.read_csv(uav_rx_file))\n",
    "    else:\n",
    "        print(\"UAV RX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_tx_files) > 0:\n",
    "        for uav_tx_file in uav_tx_files:\n",
    "            uavs_tx_df_list.append(pd.read_csv(uav_tx_file))\n",
    "    else:\n",
    "        print(\"UAV TX File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_pd_files) > 0:\n",
    "        for uav_pd_file in uav_pd_files:\n",
    "            uavs_pd_df_list.append(pd.read_csv(uav_pd_file))\n",
    "    else:\n",
    "        print(\"UAV PD File(s) Missing\")\n",
    "        print(file_list[0])\n",
    "    if len(uav_mon_files) > 0: # UAV mon files are optional now\n",
    "        uav_member_index = 3\n",
    "        for uav_mon_file in uav_mon_files:\n",
    "            uav_mon_df = pd.read_csv(uav_mon_file)\n",
    "            uav_mon_df[\"Addr\"] = \"192.168.0.\" + str(uav_member_index)\n",
    "            uavs_mon_df_list.append(uav_mon_df)\n",
    "            uav_member_index += 1\n",
    "    else:\n",
    "        uavs_mon_df_list = []\n",
    "\n",
    "    rx_df_list = [gcs_rx_df, gw_rx_df] + uavs_rx_df_list\n",
    "    tx_df_list = [gcs_tx_df, gw_tx_df] + uavs_tx_df_list\n",
    "    pd_df_list = [gcs_pd_df, gw_pd_df] + uavs_pd_df_list\n",
    "    mon_df_list = [gcs_mon_df, gw_mon_df] + uavs_mon_df_list\n",
    "\n",
    "    # UNCOMMENT BELOW IF RSSI DATA WILL BE USED\n",
    "    # for rx_df in rx_df_list:\n",
    "    #     rx_df[\"RSSI\"] = rssi_to_np(rx_df[\"RSSI\"])\n",
    "    # for tx_df in tx_df_list:\n",
    "    #     tx_df[\"RSSI\"] = rssi_to_np(tx_df[\"RSSI\"])\n",
    "    # for pd_df in pd_df_list:\n",
    "    #     pd_df[\"RSSI\"] = rssi_to_np(pd_df[\"RSSI\"])\n",
    "    # for mon_df in mon_df_list:\n",
    "    #     mon_df[\"RSSI\"] = rssi_to_np(mon_df[\"RSSI\"])\n",
    "\n",
    "    return rx_df_list, tx_df_list, pd_df_list, mon_df_list\n",
    "\n",
    "def process_dropped_packets_v1(tx_df, rx_df, mon_df, pd_df):\n",
    "    '''\n",
    "    This function is to fill in missing data in rx_df with data from mon_df for dropped packets that are not recorded in rx_df\n",
    "    tx_df contains the list of all transmitted network packets (UL/DL)\n",
    "    rx_df should only contain the captures of packets received successfully (regardless of delay)\n",
    "    mon_df contains the monitor mode captures recorded on the Rx side, and contains information of packets not received successfully\n",
    "    pd_df contains the packet drop recorded with reason, recorded on Rx side\n",
    "    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.\n",
    "\n",
    "    VERSION 1: Cross-check packets dropped by comparing Tx df and Rx df,  then get packet drop reason from pd_df and match with packets in mon_df\n",
    "    '''\n",
    "    # Firstly, let's mark all the rows in rx_df as having been received correctly\n",
    "    rx_df[\"Packet_Drop_Reason\"] = \"None\"\n",
    "    for index, row in tx_df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "\n",
    "        # First, check if the packet is received successfully in rx_df\n",
    "        if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "            dest_addr = row[\"Dest_Addr\"]\n",
    "            # If not received, find the packet drop reason\n",
    "\n",
    "            # FOR PACKETS RCVD INCORRECTLY\n",
    "            packet_rcvd_incorrectly = pd_df.loc[(pd_df[\"Packet_Name\"] == packetName) & (pd_df[\"Packet_Drop_Reason\"] == \"INCORRECTLY_RECEIVED\")] # Packets of this name that dropped due to errors\n",
    "            # Get the information on each packet dropped from monitor dataframe, using the unique Rx time to find the corresponding packets in mon_df\n",
    "            rx_time_dropped = packet_rcvd_incorrectly[\"RxTime\"].values\n",
    "            err_pks_mon = mon_df.loc[(mon_df[\"Packet_Name\"] == packetName) & (mon_df[\"RxTime\"].isin(rx_time_dropped))] \n",
    "            err_pks_mon.rename(columns={\"PkCreationTime\": \"TxTime\"})\n",
    "            err_pks_mon[\"Src_Addr\"] = \"-\" # TODO\n",
    "            err_pks_mon[\"Src_Port\"] = \"-\" # TODO\n",
    "            err_pks_mon[\"Dest_Addr\"] = row[\"Dest_Addr\"]\n",
    "            err_pks_mon[\"Dest_Port\"] = row[\"Dest_Port\"]\n",
    "            err_pks_mon[\"Packet_Drop_Reason\"] = \"INCORRECTLY_RECEIVED\"\n",
    "            rx_df = pd.concat([rx_df,err_pks_mon], ignore_index = True)\n",
    "\n",
    "            # TODO: Include other packet drop reasons\n",
    "\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_dropped_packets_v2(rx_df, mon_df, pd_df):\n",
    "    '''\n",
    "    This function is to fill in missing data in rx_df with data from mon_df for dropped packets that are not recorded in rx_df\n",
    "    rx_df should only contain the captures of packets received successfully (regardless of delay)\n",
    "    mon_df contains the monitor mode captures recorded on the Rx side, and contains information of packets not received successfully\n",
    "    pd_df contains the packet drop recorded with reason, recorded on Rx side\n",
    "    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.\n",
    "\n",
    "    VERSION 2: Just match the packets in pd_df with the ones in mon_df, using the common unique RxTime. This should handle all \n",
    "    '''\n",
    "    # Firstly, let's mark all the rows in rx_df as having been received correctly\n",
    "    rx_df[\"Packet_Drop_Reason\"] = \"None\"\n",
    "\n",
    "    # TODO: Check for duplicate RxTime in mon_df before using this method?\n",
    "\n",
    "    # Get packets that Rx received fromn Tx but was dropped (due to incorrectly received / hop limit etc, not due to retry limit / ARP / routing)\n",
    "    packet_rcvd_dropped = pd_df.loc[(pd_df[\"Packet_Drop_Reason\"].isin([\"INCORRECTLY_RECEIVED\"]))] # Add to the list the packet drop reasons to include\n",
    "    packet_rcvd_dropped = packet_rcvd_dropped.sort_values(\"RxTime\")\n",
    "    rx_time_dropped = packet_rcvd_dropped[\"RxTime\"].values\n",
    "    pks_dropped_mon = mon_df.loc[(mon_df[\"RxTime\"].isin(rx_time_dropped))] # THIS ASSUMPTION IS WRONG!!!\n",
    "    pks_dropped_mon = pks_dropped_mon.sort_values(\"RxTime\")\n",
    "    pks_dropped_mon.rename(columns={\"PkCreationTime\": \"TxTime\"})\n",
    "    pks_dropped_mon[\"Src_Addr\"] = \"-\" \n",
    "    pks_dropped_mon[\"Src_Port\"] = \"-\" \n",
    "    pks_dropped_mon[\"Dest_Addr\"] = \"-\" \n",
    "    pks_dropped_mon[\"Dest_Port\"] = \"-\" \n",
    "    pks_dropped_mon[\"Packet_Drop_Reason\"] = packet_rcvd_dropped[\"Packet_Drop_Reason\"] \n",
    "    rx_df = pd.concat([rx_df,pks_dropped_mon], ignore_index = True)\n",
    "\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_dropped_packets_v3(rx_df, pd_df):\n",
    "    '''\n",
    "    This function is to fill in missing data in rx_df with data from mon_df for dropped packets that are not recorded in rx_df\n",
    "    rx_df should only contain the captures of packets received successfully (regardless of delay)\n",
    "    mon_df contains the monitor mode captures recorded on the Rx side, and contains information of packets not received successfully\n",
    "    pd_df contains the packet drop recorded with reason, recorded on Rx side\n",
    "    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.\n",
    "\n",
    "    VERSION 3: Takes the packets from pd_df that was INCORRECTLY_RECEIVED, and puts them in rx_df\n",
    "    '''\n",
    "    # Firstly, let's mark all the rows in rx_df as having been received correctly\n",
    "    rx_df[\"Packet_Drop_Reason\"] = \"None\"\n",
    "\n",
    "    # Get packets that Rx received fromn Tx but was dropped (due to incorrectly received / hop limit etc, not due to retry limit / ARP / routing)\n",
    "    packet_rcvd_dropped = pd_df.loc[(pd_df[\"Packet_Drop_Reason\"].isin([\"INCORRECTLY_RECEIVED\"]))] # Add to the list the packet drop reasons to include\n",
    "    # packet_rcvd_dropped = packet_rcvd_dropped.sort_values(\"RxTime\")\n",
    "    packet_rcvd_dropped[\"Src_Addr\"] = \"-\" \n",
    "    packet_rcvd_dropped[\"Src_Port\"] = \"-\" \n",
    "    packet_rcvd_dropped[\"Dest_Addr\"] = \"-\" \n",
    "    packet_rcvd_dropped[\"Dest_Port\"] = \"-\" \n",
    "    packet_rcvd_dropped[\"Hop_Count\"] = \"-\" \n",
    "    rx_df = pd.concat([rx_df,packet_rcvd_dropped], ignore_index = True)\n",
    "\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_dropped_packets_v4(tx_df, rx_df, pd_df):\n",
    "    '''\n",
    "    This function is to fill in missing data in rx_df with data from mon_df for dropped packets that are not recorded in rx_df\n",
    "    tx_df contains the list of all transmitted network packets (UL/DL)\n",
    "    rx_df should only contain the captures of packets received successfully (regardless of delay)\n",
    "    pd_df contains the packet drop recorded with reason, recorded on Rx side\n",
    "    DON'T MIX UL AND DL DATA TOGETHER IN THIS FUNCTION, EVALUATE THEM SEPARATELY.\n",
    "\n",
    "    VERSION 4: For each packet transmitted (in tx_df), get the number of tries and the packet drop reason(s) from pd_df. Update the data in rx_df.\n",
    "    '''\n",
    "\n",
    "    # First, let's delete the columns src_addr, src_port, dest_addr, dest_port from rx_df\n",
    "    del rx_df[\"Src_Addr\"]\n",
    "    del rx_df[\"Src_Port\"]\n",
    "    del rx_df[\"Dest_Addr\"]\n",
    "    del rx_df[\"Dest_Port\"]\n",
    "\n",
    "    for index, row in tx_df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "\n",
    "        # For each packet in tx_df, get the packet drops\n",
    "        pkt_drops = pd_df.loc[(pd_df[\"Packet_Name\"] == packetName)]\n",
    "        if not pkt_drops.empty:\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            arp_fail = np.count_nonzero(drop_reasons == \"ADDRESS_RESOLUTION_FAILED\") # TODO: Check whether this is stored on tx_pd_df or rx_pd_df\n",
    "            queue_overflow = np.count_nonzero(drop_reasons == \"QUEUE_OVERFLOW\")\n",
    "            hop_limit = np.count_nonzero(drop_reasons == \"HOP_LIMIT_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons == \"INTERFACE_DOWN\")\n",
    "            other_drop = np.count_nonzero(drop_reasons == \"OTHER_PACKET_DROP\")\n",
    "            num_drops = len(drop_reasons)\n",
    "\n",
    "            # Update rx_df \n",
    "            if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "                # If not received, add the data of failed packet\n",
    "                rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "                tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "                bytes = row[\"Bytes\"]\n",
    "                rssi = pkt_drops[\"RSSI\"].mean()\n",
    "                sinr = pkt_drops[\"SINR\"].mean()\n",
    "                u2g_sinr = pkt_drops[\"U2G_SINR\"].mean()\n",
    "                ber = pkt_drops[\"BER\"].mean()\n",
    "                u2g_ber = pkt_drops[\"U2G_BER\"].mean()\n",
    "                delay = max(pkt_drops[\"Delay\"].values)\n",
    "                queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "                backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "                distance = max(pkt_drops[\"Distance\"].values)\n",
    "                u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "                pkt_state = \"FAILED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                    u2u_sinr = pkt_drops[\"U2U_SINR\"].mean()\n",
    "                    u2u_ber = pkt_drops[\"U2U_BER\"].mean()\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    hop_count = 1\n",
    "                failed_pkt = pd.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'SINR': sinr,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'BER': ber,'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'Distance': distance,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'ARP_Fail': arp_fail,'Queue_Overflow': queue_overflow,'Hop_Limit_Reached': hop_limit,'Interface_Down': interface_down,'Other_Dropped': other_drop,'Number_Dropped': num_drops,\n",
    "                              'Packet_State': pkt_state}])\n",
    "                rx_df = pd.concat([rx_df,failed_pkt], ignore_index = True)\n",
    "            else:\n",
    "                # If packet successfully received, update the number of tries and the reason for failed attempt(s)\n",
    "                rx_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "                rx_df[\"ARP_Fail\"] = arp_fail\n",
    "                rx_df[\"Queue_Overflow\"] = queue_overflow\n",
    "                rx_df[\"Hop_Limit_Reached\"] = hop_limit\n",
    "                rx_df[\"Interface_Down\"] = interface_down\n",
    "                rx_df[\"Other_Dropped\"] = other_drop\n",
    "                rx_df[\"Number_Dropped\"] = num_drops\n",
    "                rx_df[\"Packet_State\"] = \"RECEIVED\"\n",
    "\n",
    "        elif (packetName in rx_df[\"Packet_Name\"].values):\n",
    "            # The packet was received without any retries\n",
    "            rx_df[\"Incorrectly_Rcvd\"] = 0\n",
    "            rx_df[\"ARP_Fail\"] = 0\n",
    "            rx_df[\"Queue_Overflow\"] = 0\n",
    "            rx_df[\"Hop_Limit_Reached\"] = 0\n",
    "            rx_df[\"Interface_Down\"] = 0\n",
    "            rx_df[\"Other_Dropped\"] = 0\n",
    "            rx_df[\"Number_Dropped\"] = 0\n",
    "            rx_df[\"Packet_State\"] = \"RECEIVED\"\n",
    "        \n",
    "        else:\n",
    "            print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "def process_dropped_packets_DL(tx_df, rx_df_list, pd_df_list, tx_index):\n",
    "    '''\n",
    "    This function is to compile packet information from the tx, rx and pd dataframes, fopr downlink comm. (GCS to UAVs)\n",
    "    tx_df: Tx DF \n",
    "    rx_df_list: List of Rx DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    pd_df_list: List of packet drop DFs, first one is for GCS, second for GW, subsequent DFs in the list for UAV 1, 2, ...\n",
    "    tx_index: Index of Tx in pd_df_list (e.g. for GCS, tx_index = 0)\n",
    "    Output: pkt_df: DF containing info on packets from tx_df received and dropped \n",
    "    '''\n",
    "    pkt_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Delay','Queueing_Time','Backoff_Time','U2G_Distance',\n",
    "                                    'Incorrectly_Rcvd','Queue_Overflow','Interface_Down','Number_Dropped','Packet_State'])\n",
    "    for index, row in tx_df.iterrows():\n",
    "        packetName = row[\"Packet_Name\"] + \"-\" + str(row[\"Packet_Seq\"])\n",
    "        dest_addr = row[\"Dest_Addr\"]\n",
    "        rx_index = int(dest_addr.split(\".\")[-1]) - 1\n",
    "\n",
    "        # For each packet in gcs_tx_df, get the packet drops from GW and corresponding UAV\n",
    "        pkt_drops_tx = pd_df_list[tx_index].loc[(pd_df[\"Packet_Name\"] == packetName)] # Packets dropped at the transmitter, to catch QUEUE_OVERFLOW and INTERFACE_DOWN\n",
    "        pkt_drops_gw = pd_df_list[1].loc[(pd_df[\"Packet_Name\"] == packetName)] # Packets dropped at the gateway UAV\n",
    "        if rx_index != 1: # If not the GW, include packet drops at receiver. Else no need, cos GW is Rx\n",
    "            pkt_drops_rx = pd_df_list[rx_index].loc[(pd_df[\"Packet_Name\"] == packetName)] # Packets dropped at the receiver (GCS / UAV)\n",
    "            pkt_drops = pd.concat([pkt_drops_gw, pkt_drops_rx], ignore_index = True)\n",
    "        else:\n",
    "            pkt_drops = pkt_drops_gw\n",
    "\n",
    "        if not pkt_drops.empty: # Find the packet drops for this particular packet\n",
    "            drop_reasons = pkt_drops[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at GW and Rx\n",
    "            drop_reasons_tx = pkt_drops_tx[\"Packet_Drop_Reason\"].values # List of pkt drop reasons at Tx\n",
    "            # Count the occurences of each failure modes for a particular packet\n",
    "            incorrect_rcvd = np.count_nonzero(drop_reasons == \"INCORRECTLY_RECEIVED\")\n",
    "            queue_overflow = np.count_nonzero(drop_reasons_tx == \"QUEUE_OVERFLOW\")\n",
    "            retry_limit_excd = np.count_nonzero(drop_reasons_tx == \"RETRY_LIMI_REACHED\")\n",
    "            interface_down = np.count_nonzero(drop_reasons_tx == \"INTERFACE_DOWN\")\n",
    "            num_drops = len(drop_reasons) # This is for counting drops due to incorrectly received only\n",
    "\n",
    "            # Update pkt_df \n",
    "            rx_df = rx_df_list[rx_index]\n",
    "            if (packetName not in rx_df[\"Packet_Name\"].values):\n",
    "                # If not received, add the data of failed packet\n",
    "                rx_time = max(pkt_drops[\"RxTime\"].values)\n",
    "                tx_time = min(pkt_drops[\"TxTime\"].values)\n",
    "                bytes = row[\"Bytes\"]\n",
    "                rssi = pkt_drops[\"RSSI\"].mean()\n",
    "                # sinr = pkt_drops[\"SINR\"].mean()\n",
    "                u2g_sinr = pkt_drops[\"U2G_SINR\"].mean()\n",
    "                # ber = pkt_drops[\"BER\"].mean()\n",
    "                u2g_ber = pkt_drops[\"U2G_BER\"].mean()\n",
    "                delay = max(pkt_drops[\"Delay\"].values)\n",
    "                queueing_time = max(pkt_drops[\"Queueing_Time\"].values)\n",
    "                backoff_time = max(pkt_drops[\"Backoff_Time\"].values)\n",
    "                # distance = max(pkt_drops[\"Distance\"].values)\n",
    "                u2g_distance = max(pkt_drops[\"U2G_Distance\"].values)\n",
    "                pkt_state = \"FAILED\" # The packet failed to be received (RETRY_LIMIT_EXCEEDED)\n",
    "                if (len(pkt_drops[\"U2U_SINR\"].values) > 0): # There may not always be a U2U communication\n",
    "                    u2u_sinr = pkt_drops[\"U2U_SINR\"].mean()\n",
    "                    u2u_ber = pkt_drops[\"U2U_BER\"].mean()\n",
    "                    hop_count = 2\n",
    "                else:\n",
    "                    u2u_sinr = None\n",
    "                    u2u_ber = None\n",
    "                    hop_count = 1\n",
    "                failed_pkt = pd.DataFrame([{'RxTime': rx_time,'TxTime': tx_time,'Packet_Name': packetName,'Bytes': bytes,'RSSI': rssi,'U2G_SINR': u2g_sinr,'U2U_SINR': u2u_sinr,\n",
    "                              'U2G_BER': u2g_ber,'U2U_BER': u2u_ber,'Hop_Count': hop_count,'Delay': delay,'Queueing_Time': queueing_time,'Backoff_Time': backoff_time,'U2G_Distance': u2g_distance,\n",
    "                              'Incorrectly_Rcvd': incorrect_rcvd,'Queue_Overflow': queue_overflow,'Interface_Down': interface_down,'Number_Dropped': num_drops,'Packet_State': pkt_state}])\n",
    "                pkt_df = pd.concat([pkt_df,failed_pkt], ignore_index = True)\n",
    "\n",
    "    #         else:\n",
    "    #             # If packet successfully received, update the number of tries and the reason for failed attempt(s)\n",
    "    #             rx_df[\"Incorrectly_Rcvd\"] = incorrect_rcvd\n",
    "    #             rx_df[\"ARP_Fail\"] = arp_fail\n",
    "    #             rx_df[\"Queue_Overflow\"] = queue_overflow\n",
    "    #             rx_df[\"Hop_Limit_Reached\"] = hop_limit\n",
    "    #             rx_df[\"Interface_Down\"] = interface_down\n",
    "    #             rx_df[\"Other_Dropped\"] = other_drop\n",
    "    #             rx_df[\"Number_Dropped\"] = num_drops\n",
    "    #             rx_df[\"Packet_State\"] = \"RECEIVED\"\n",
    "\n",
    "    #     elif (packetName in rx_df[\"Packet_Name\"].values):\n",
    "    #         # The packet was received without any retries\n",
    "    #         rx_df[\"Incorrectly_Rcvd\"] = 0\n",
    "    #         rx_df[\"ARP_Fail\"] = 0\n",
    "    #         rx_df[\"Queue_Overflow\"] = 0\n",
    "    #         rx_df[\"Hop_Limit_Reached\"] = 0\n",
    "    #         rx_df[\"Interface_Down\"] = 0\n",
    "    #         rx_df[\"Other_Dropped\"] = 0\n",
    "    #         rx_df[\"Number_Dropped\"] = 0\n",
    "    #         rx_df[\"Packet_State\"] = \"RECEIVED\"\n",
    "        \n",
    "    #     else:\n",
    "    #         print(\"No packet drop recorded and packet not found in rx_df for packet: {}. This should not happen\".format(packetName))\n",
    "\n",
    "    # rx_df = rx_df.sort_values(\"RxTime\")\n",
    "    # rx_df = rx_df.reset_index()\n",
    "    return rx_df\n",
    "\n",
    "\n",
    "def process_throughput(df, timeDiv):\n",
    "    '''\n",
    "    Function to calculate throughput data for a DataFrame\n",
    "    timeDiv is the time division to use for calculating the throughput\n",
    "    '''\n",
    "    maxTime = math.ceil(float(df[\"RxTime\"].max()))\n",
    "    for i in range(math.ceil(maxTime / timeDiv)):\n",
    "        df_in_range = df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)) & (df[\"Packet_State\"] == \"RECEIVED\")]\n",
    "        totalBytes = df_in_range[\"Bytes\"].sum()\n",
    "        throughput = totalBytes / timeDiv\n",
    "        df.loc[(df[\"RxTime\"] >= (i*timeDiv)) & (df[\"RxTime\"] < ((i+1)*timeDiv)), \"Throughput\"] = throughput\n",
    "    return df\n",
    "\n",
    "def process_sim_data(sim_root_path, delay_threshold):\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + \"/*GCS-Tx.csv\")] # Get list of \"unique\" scenarios\n",
    "\n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','U2G_SINR','U2U_SINR','BER','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','Distance','U2G_Distance','Height','Inter_UAV_Distance',\n",
    "                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','ARP_Fail','Queue_Overflow','Hop_Limit_Reached',\n",
    "                                    'Interface_Down','Other_Dropped','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','SINR','U2G_SINR','U2U_SINR','BER','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','Distance','U2G_Distance','Height','Inter_UAV_Distance',\n",
    "                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','ARP_Fail','Queue_Overflow','Hop_Limit_Reached',\n",
    "                                    'Interface_Down','Other_Dropped','Number_Dropped','Packet_State']) # Uplink dataframe\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    for scenario in scenario_list:\n",
    "        scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "        scenario_params = scenario.split('_')\n",
    "        num_member = int(scenario_params[0].split('-')[-1])\n",
    "        inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "        height = int(scenario_params[2].split('-')[-1])\n",
    "        # swarm_hor_distance = int(scenario_params[3].split('-')[-1]) # Horizontal Swarm Distance\n",
    "        # swarm_distance = math.sqrt(int(height)**2 + swarm_hor_distance**2)\n",
    "        # packet_size = int(scenario_params[4].split('-')[-1])\n",
    "        sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "        dl_data, ul_data, dl_tx_df, ul_tx_df, gcs_mon_df, uavs_mon_df, gcs_pd_df, uavs_pd_df = compile_micro_sim_data(scenario_files)\n",
    "        # Convert the RSSI data to np\n",
    "        dl_data[\"RSSI\"] = rssi_to_np(dl_data[\"RSSI\"])\n",
    "        ul_data[\"RSSI\"] = rssi_to_np(ul_data[\"RSSI\"])\n",
    "        gcs_pd_df[\"RSSI\"] = rssi_to_np(gcs_pd_df[\"RSSI\"])\n",
    "        uavs_pd_df[\"RSSI\"] = rssi_to_np(uavs_pd_df[\"RSSI\"])\n",
    "        # gcs_mon_df[\"RSSI\"] = rssi_to_np(gcs_mon_df[\"RSSI\"])\n",
    "        # uavs_mon_df[\"RSSI\"] = rssi_to_np(uavs_mon_df[\"RSSI\"])\n",
    "        # Process the failed packets data into the main dataframe\n",
    "        dl_data = process_dropped_packets_v4(dl_tx_df, dl_data, uavs_pd_df)\n",
    "        ul_data = process_dropped_packets_v4(ul_tx_df, ul_data, gcs_pd_df)\n",
    "        if dl_data is not None:\n",
    "            dl_data[\"Height\"] = height\n",
    "            dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            dl_data[\"Num_Members\"] = num_member\n",
    "            dl_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            dl_data[\"Delay_Exceeded\"] = 0\n",
    "            dl_data.loc[dl_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            dl_data[\"Reliable\"] = 0\n",
    "            dl_data.loc[(dl_data[\"Delay_Exceeded\"] == 0) & (dl_data[\"Packet_State\"] == \"RECEIVED\"), \"Reliable\"] = 1\n",
    "            dl_data = process_throughput(dl_data, 1)\n",
    "            dl_df = pd.concat([dl_df, dl_data], ignore_index=True)\n",
    "        if ul_data is not None:\n",
    "            ul_data[\"Height\"] = height\n",
    "            ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            ul_data[\"Num_Members\"] = num_member\n",
    "            ul_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            ul_data[\"Delay_Exceeded\"] = 0\n",
    "            ul_data.loc[ul_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            ul_data[\"Reliable\"] = 0\n",
    "            ul_data.loc[(ul_data[\"Delay_Exceeded\"] == 0) & (ul_data[\"Packet_State\"] == 'RECEIVED'), \"Reliable\"] = 1\n",
    "            ul_data = process_throughput(ul_data, 1)\n",
    "            ul_df = pd.concat([ul_df, ul_data], ignore_index=True)\n",
    "    \n",
    "    return dl_df, ul_df\n",
    "\n",
    "def process_sim_data_v2(sim_root_path, delay_threshold):\n",
    "    # Concatenates all UL & DL results from sim_root_path into a single df\n",
    "    scenario_list = [csv.split('/')[-1][0:-11] for csv in glob.glob(sim_root_path + \"/*GCS-Tx.csv\")] # Get list of \"unique\" scenarios\n",
    "        num_member \n",
    "    # Dataframes to store UL & DL raw data\n",
    "    dl_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance',\n",
    "                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','Queue_Overflow',\n",
    "                                    'Interface_Down','Number_Dropped','Packet_State']) # Downlink dataframe\n",
    "    ul_df = pd.DataFrame(columns = ['RxTime','TxTime','Packet_Name','Bytes','RSSI','U2G_SINR','U2U_SINR','U2G_BER','U2U_BER',\n",
    "                                    'Hop_Count','Throughput','Delay','Queueing_Time','Backoff_Time','U2G_Distance','Height','Inter_UAV_Distance',\n",
    "                                    'Num_Members','Sending_Interval','Delay_Exceeded','Reliable','Incorrectly_Rcvd','Queue_Overflow',\n",
    "                                    'Interface_Down','Number_Dropped','Packet_State']) # Uplink dataframe\n",
    "\n",
    "    # For each scenario, extract the UL and DL raw data\n",
    "    for scenario in scenario_list:\n",
    "        scenario_files = glob.glob(sim_root_path + \"/{}_*.csv\".format(scenario)) # Get list of csv files belonging to this scenario\n",
    "        scenario_params = scenario.split('_')\n",
    "        num_member = int(scenario_params[0].split('-')[-1])\n",
    "        inter_uav_distance = int(scenario_params[1].split('-')[-1])\n",
    "        height = int(scenario_params[2].split('-')[-1]) \n",
    "        sending_interval = int(scenario_params[5].split('-')[-1])\n",
    "        rx_df_list, tx_df_list, pd_df_list, mon_df_list = compile_micro_sim_data_v2(scenario_files)\n",
    "        # Process the failed packets data into the main dataframe\n",
    "        dl_data = process_dropped_packets_v4(dl_tx_df, dl_data, uavs_pd_df)\n",
    "        ul_data = process_dropped_packets_v4(ul_tx_df, ul_data, gcs_pd_df)\n",
    "        if dl_data is not None:\n",
    "            dl_data[\"Height\"] = height\n",
    "            dl_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            dl_data[\"Num_Members\"] = num_member\n",
    "            dl_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            dl_data[\"Delay_Exceeded\"] = 0\n",
    "            dl_data.loc[dl_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            dl_data[\"Reliable\"] = 0\n",
    "            dl_data.loc[(dl_data[\"Delay_Exceeded\"] == 0) & (dl_data[\"Packet_State\"] == \"RECEIVED\"), \"Reliable\"] = 1\n",
    "            dl_data = process_throughput(dl_data, 1)\n",
    "            dl_df = pd.concat([dl_df, dl_data], ignore_index=True)\n",
    "        if ul_data is not None:\n",
    "            ul_data[\"Height\"] = height\n",
    "            ul_data[\"Inter_UAV_Distance\"] = inter_uav_distance\n",
    "            ul_data[\"Num_Members\"] = num_member\n",
    "            ul_data[\"Sending_Interval\"] = sending_interval\n",
    "            # Fill in reliability data\n",
    "            ul_data[\"Delay_Exceeded\"] = 0\n",
    "            ul_data.loc[ul_data[\"Delay\"] > delay_threshold, \"Delay_Exceeded\"] = 1\n",
    "            ul_data[\"Reliable\"] = 0\n",
    "            ul_data.loc[(ul_data[\"Delay_Exceeded\"] == 0) & (ul_data[\"Packet_State\"] == 'RECEIVED'), \"Reliable\"] = 1\n",
    "            ul_data = process_throughput(ul_data, 1)\n",
    "            ul_df = pd.concat([ul_df, ul_data], ignore_index=True)\n",
    "    \n",
    "    return dl_df, ul_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data and save to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No packet drop recorded and packet not found in rx_df for packet: UAVData_0-9117. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: UAVData_0-9482. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: UAVData_0-9644. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-7575. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-7996. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-8368. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-8454. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-9211. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-9587. This should not happen\n",
      "No packet drop recorded and packet not found in rx_df for packet: GatewayData-9916. This should not happen\n"
     ]
    }
   ],
   "source": [
    "# Let's get the data\n",
    "sim_root_path = \"/home/research-student/omnetpp_sim_results/Test2\"\n",
    "delay_threshold = 1\n",
    "dl_df, ul_df = process_sim_data(sim_root_path, delay_threshold=delay_threshold)\n",
    "# Save DF to CSV\n",
    "dl_df.to_csv(os.path.join(sim_root_path,\"FANET_downlink_raw.csv\"), index=False)\n",
    "ul_df.to_csv(os.path.join(sim_root_path,\"FANET_uplink_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/research-student/omnetpp_sim_results/Testing/NumMember-3_InterUAVDistance-5_Height-50_Distance-0_PacketSize-24_SendingRate-40_UAV-0-Rx.csv', '/home/research-student/omnetpp_sim_results/Testing/NumMember-3_InterUAVDistance-5_Height-50_Distance-0_PacketSize-24_SendingRate-40_UAV-1-Rx.csv', '/home/research-student/omnetpp_sim_results/Testing/NumMember-3_InterUAVDistance-5_Height-50_Distance-0_PacketSize-24_SendingRate-40_UAV-2-Rx.csv']\n"
     ]
    }
   ],
   "source": [
    "sim_root_path = \"/home/research-student/omnetpp_sim_results/Testing\"\n",
    "delay_threshold = 1\n",
    "rx_df_list, tx_df_list, pd_df_list, mon_df_list = process_sim_data_v2(sim_root_path, delay_threshold=delay_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
