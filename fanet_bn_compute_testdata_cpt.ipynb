{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the CPT File for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd # for data manipulation \n",
    "import numpy as np\n",
    "import os, sys, glob, math, pickle\n",
    "import cudf \n",
    "from tqdm import tqdm\n",
    "\n",
    "# This function helps to calculate probability distribution, which goes into BBN (note, can handle up to 2 parents)\n",
    "def cpt_probs(df, child, parents):\n",
    "    try:\n",
    "        # dependencies_arr = [pd.Categorical(df[parent],categories=df[parent].cat.categories.tolist()) for parent in parents]\n",
    "        dependencies_arr = [df[parent] for parent in parents]\n",
    "        # cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()\n",
    "        cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index()\n",
    "        return cpt\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None \n",
    "\n",
    "def cpt_probs_freq(df, child, parents):\n",
    "    try:\n",
    "        # dependencies_arr = [pd.Categorical(df[parent],categories=df[parent].cat.categories.tolist()) for parent in parents]\n",
    "        dependencies_arr = [df[parent] for parent in parents]\n",
    "        # cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, normalize='index', dropna=False).sort_index().to_numpy().reshape(-1).tolist()\n",
    "        cpt = pd.crosstab(dependencies_arr, df[child], rownames=parents, colnames=[child], margins=False, dropna=False).sort_index()\n",
    "        return cpt\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"Downlink\"\n",
    "\n",
    "if data_type == \"Downlink\":\n",
    "    df = pd.read_hdf(\"/home/research-student/omnetpp_sim_results/Test_Dataset_BPSK_6-5Mbps/Taguchi_Test_Cases_downlink.h5\", data_type)\n",
    "elif data_type == \"Uplink\":\n",
    "    df = pd.read_hdf(\"/home/research-student/omnetpp_sim_results/Test_Dataset_BPSK_6-5Mbps/Taguchi_Test_Cases_uplink.h5\", data_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Bin Intervals from NPY Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinr_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/sinr_bins_dl.npy\")\n",
    "ber_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/ber_bins_dl.npy\")\n",
    "delay_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/delay_bins_dl.npy\")\n",
    "queueing_time_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/queueing_time_bins_dl.npy\")\n",
    "throughput_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/throughput_bins_dl.npy\")\n",
    "jitter_bins = np.load(\"/home/research-student/omnet-fanet/cpt/Downlink/jitter_bins_dl.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute CPT for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_threshold = 0.04\n",
    "\n",
    "df = df[df['U2G_SINR'].notna()] # Filter out rows with missing crucial information\n",
    "classes_df = pd.DataFrame() # Created an empty df to store classes data to reduce size of df that need to work with\n",
    "# First, discretise the values to classes\n",
    "h_dist_labels = ['vs','s','m','l','vl']\n",
    "height_labels = ['vs','s','m','l','vl']\n",
    "num_members_labels = ['vs','s','m','l','vl']\n",
    "sending_interval_labels = ['vs','s','m','l','vl']\n",
    "pkt_size_labels = ['vs','s','m','l','vl']\n",
    "sinr_labels = ['vs','s','m','l','vl']\n",
    "delay_labels = ['vs','s','m','l','vl']\n",
    "throughput_labels = ['s','m','l']\n",
    "queueing_labels = ['s','m','l']\n",
    "ber_labels = ['vs','s','m','l','vl']\n",
    "jitter_labels = ['s','m','l']\n",
    "\n",
    "# Independent vars\n",
    "classes_df[\"H_Dist_Class\"] = pd.cut(df.U2G_H_Dist, [0,100,200,300,400,501], right=False, include_lowest=True, labels=h_dist_labels)\n",
    "classes_df[\"Height_Class\"] = pd.cut(df.Height, [1,25,49,73,97,121], right=False, include_lowest=True, labels=height_labels)\n",
    "classes_df[\"Num_Members_Class\"] = pd.cut(df.Num_Members, [2,8,16,24,32,40], right=False, include_lowest=True, labels=num_members_labels)\n",
    "classes_df[\"Sending_Interval_Class\"] = pd.cut(df.Mean_Sending_Interval, [40,232,424,616,808,1000], right=False, include_lowest=True, labels=sending_interval_labels)\n",
    "classes_df[\"Packet_Size_Class\"] = pd.cut(df.Bytes, [24,248,472,696,920,1144], right=False, include_lowest=True, labels=pkt_size_labels)\n",
    "# Second layer\n",
    "classes_df[\"SINR_Class\"] = pd.cut(df.U2G_SINR, sinr_bins, right=False, include_lowest=True, labels=sinr_labels)\n",
    "classes_df[\"Delay_Class\"] = pd.cut(df.Delay, delay_bins, right=False, include_lowest=True, labels=delay_labels)\n",
    "classes_df[\"Throughput_Class\"] = pd.cut(df.Throughput, throughput_bins, right=False, include_lowest=True, labels=throughput_labels)\n",
    "classes_df[\"Queueing_Time_Class\"] = pd.cut(df.Queueing_Time, queueing_time_bins, right=False, include_lowest=True, labels=queueing_labels)\n",
    "classes_df[\"BER_Class\"] = pd.cut(df.U2G_BER, ber_bins, right=False, include_lowest=True, labels=ber_labels)\n",
    "classes_df[\"Jitter_Class\"] = pd.cut(df.Jitter, jitter_bins, right=False, include_lowest=True, labels=jitter_labels)\n",
    "# Output vars\n",
    "classes_df[\"Reliable\"] = (df[\"Packet_State\"] == \"Reliable\")\n",
    "classes_df[\"Delay_Exceeded\"] = (df[\"Delay\"] >= delay_threshold)\n",
    "classes_df[\"Incorrectly_Received\"] = df[\"Incorrectly_Received\"]\n",
    "classes_df[\"Queue_Overflow\"] = df[\"Queue_Overflow\"]\n",
    "\n",
    "# Calculate the conditional probabilities table for each output layer class\n",
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "reliability_cpt = cpt_probs(classes_df, child=\"Reliable\", parents=parents_1)\n",
    "incorrect_rcvd_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_1)\n",
    "delay_exceeded_cpt = cpt_probs(classes_df, child=\"Delay_Exceeded\", parents=parents_1)\n",
    "queue_overflow_cpt = cpt_probs(classes_df, child=\"Queue_Overflow\", parents=parents_1)\n",
    "\n",
    "# Calculate the conditional probabilities table for each second layer class\n",
    "parents_1 = [\"H_Dist_Class\", \"Height_Class\", \"Num_Members_Class\", \"Sending_Interval_Class\", \"Packet_Size_Class\"] \n",
    "sinr_cpt = cpt_probs(classes_df, child=\"SINR_Class\", parents=parents_1)\n",
    "ber_cpt = cpt_probs(classes_df, child=\"BER_Class\", parents=parents_1)\n",
    "delay_cpt = cpt_probs(classes_df, child=\"Delay_Class\", parents=parents_1)\n",
    "queueing_time_cpt = cpt_probs(classes_df, child=\"Queueing_Time_Class\", parents=parents_1)\n",
    "throughput_cpt = cpt_probs(classes_df, child=\"Throughput_Class\", parents=parents_1)\n",
    "jitter_cpt = cpt_probs(classes_df, child=\"Jitter_Class\", parents=parents_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_cpt_freq = cpt_probs_freq(classes_df, child=\"Reliable\", parents=parents_1)\n",
    "reliability_cpt_freq.loc[(reliability_cpt_freq==0).all(axis=1).values] = np.NaN\n",
    "reliability_cpt_freq.dropna(axis=0, how='all', inplace=True)\n",
    "reliability_cpt_freq.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_reliability_{}_cpt_freq.csv\".format(data_type,data_type))\n",
    "reliability_cpt_freq.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_reliability_{}_cpt_freq.pkl\".format(data_type,data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinr_cptr_freq = cpt_probs_freq(classes_df, child=\"SINR_Class\", parents=parents_1)\n",
    "sinr_cptr_freq.loc[(sinr_cptr_freq==0).all(axis=1).values] = np.NaN\n",
    "sinr_cptr_freq.dropna(axis=0, how='all', inplace=True)\n",
    "sinr_cptr_freq.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_sinr_{}_cpt_freq.csv\".format(data_type,data_type))\n",
    "sinr_cptr_freq.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_sinr_{}_cpt_freq.pkl\".format(data_type,data_type))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty rows\n",
    "# Output layers\n",
    "reliability_cpt.loc[(reliability_cpt==0).all(axis=1).values] = np.NaN\n",
    "reliability_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "incorrect_rcvd_cpt.loc[(incorrect_rcvd_cpt==0).all(axis=1).values] = np.NaN\n",
    "incorrect_rcvd_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "delay_exceeded_cpt.loc[(delay_exceeded_cpt==0).all(axis=1).values] = np.NaN\n",
    "delay_exceeded_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "queue_overflow_cpt.loc[(queue_overflow_cpt==0).all(axis=1).values] = np.NaN\n",
    "queue_overflow_cpt.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty rows\n",
    "# Second layers\n",
    "sinr_cpt.loc[(sinr_cpt==0).all(axis=1).values] = np.NaN\n",
    "sinr_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "ber_cpt.loc[(ber_cpt==0).all(axis=1).values] = np.NaN\n",
    "ber_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "delay_cpt.loc[(delay_cpt==0).all(axis=1).values] = np.NaN\n",
    "delay_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "queueing_time_cpt.loc[(queueing_time_cpt==0).all(axis=1).values] = np.NaN\n",
    "queueing_time_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "throughput_cpt.loc[(throughput_cpt==0).all(axis=1).values] = np.NaN\n",
    "throughput_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "jitter_cpt.loc[(jitter_cpt==0).all(axis=1).values] = np.NaN\n",
    "jitter_cpt.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Test Data CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As CSV files\n",
    "reliability_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_reliability_{}_cpt.csv\".format(data_type,data_type))\n",
    "incorrect_rcvd_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_incorrect_rcvd_{}_cpt.csv\".format(data_type,data_type))\n",
    "delay_exceeded_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_delay_exceeded_{}_cpt.csv\".format(data_type,data_type))\n",
    "queue_overflow_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_queue_overflow_{}_cpt.csv\".format(data_type,data_type))\n",
    "sinr_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_sinr_{}_cpt.csv\".format(data_type,data_type))\n",
    "ber_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_ber_{}_cpt.csv\".format(data_type,data_type))\n",
    "delay_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_delay_{}_cpt.csv\".format(data_type,data_type))\n",
    "queueing_time_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_queueing_time_{}_cpt.csv\".format(data_type,data_type))\n",
    "throughput_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_throughput_{}_cpt.csv\".format(data_type,data_type))\n",
    "jitter_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_jitter_{}_cpt.csv\".format(data_type,data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As pickle files\n",
    "reliability_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_reliability_{}_cpt.pkl\".format(data_type,data_type))\n",
    "incorrect_rcvd_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_incorrect_rcvd_{}_cpt.pkl\".format(data_type,data_type))\n",
    "delay_exceeded_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_delay_exceeded_{}_cpt.pkl\".format(data_type,data_type))\n",
    "queue_overflow_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_queue_overflow_{}_cpt.pkl\".format(data_type,data_type))\n",
    "sinr_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_sinr_{}_cpt.pkl\".format(data_type,data_type))\n",
    "ber_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_ber_{}_cpt.pkl\".format(data_type,data_type))\n",
    "delay_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_delay_{}_cpt.pkl\".format(data_type,data_type))\n",
    "queueing_time_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_queueing_time_{}_cpt.pkl\".format(data_type,data_type))\n",
    "throughput_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_throughput_{}_cpt.pkl\".format(data_type,data_type))\n",
    "jitter_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_jitter_{}_cpt.pkl\".format(data_type,data_type))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_trimmed = [\"H_Dist_Class\", \"Height_Class\"] \n",
    "incorrect_rcvd_trimmed_cpt = cpt_probs(classes_df, child=\"Incorrectly_Received\", parents=parents_trimmed)\n",
    "incorrect_rcvd_trimmed_cpt.loc[(incorrect_rcvd_trimmed_cpt==0).all(axis=1).values] = np.NaN\n",
    "incorrect_rcvd_trimmed_cpt.dropna(axis=0, how='all', inplace=True)\n",
    "incorrect_rcvd_trimmed_cpt.to_csv(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_incorrect_rcvd_trimmed_{}_cpt.csv\".format(data_type,data_type))\n",
    "incorrect_rcvd_trimmed_cpt.to_pickle(\"/home/research-student/omnet-fanet/cpt/Test_Data/{}/test_data_incorrect_rcvd_trimmed_{}_cpt.pkl\".format(data_type,data_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b91d162001b74e2486487353b6410b0f764056372f730fbe993a2ad06d40082"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
